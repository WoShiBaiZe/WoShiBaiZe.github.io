<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ztree数据格式]]></title>
    <url>%2F2020%2F08%2F16%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200816%2F</url>
    <content type="text"><![CDATA[ztree数据格式 1.ztree官网 2.ztree的两种数据格式 标准的 JSON 数据需要嵌套表示节点的父子包含关系 123456var nodes = [ &#123;name: "父节点1", children: [ &#123;name: "子节点1"&#125;, &#123;name: "子节点2"&#125; ]&#125;]; 简单模式的 JSON 数据需要使用 id / pId 表示节点的父子包含关系 12345var nodes = [ &#123;id:1, pId:0, name: "父节点1"&#125;, &#123;id:11, pId:1, name: "子节点1"&#125;, &#123;id:12, pId:1, name: "子节点2"&#125;]; 3.Java后台实现 3.1 标准的JSON数据格式- 省市区联动 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117//controller@PostMapping(value = "/getCity")@ApiOperation(httpMethod = "POST",value = "查看地址")public R&lt;List&lt;TreeNode&gt;&gt; getCity()&#123; logger.info("getCity - 获取地址"); List&lt;TreeNode&gt; treeNodeList = addressService.getCity(); return new R&lt;&gt;(treeNodeList);&#125;//service@Override@Cacheable(cacheNames = "",keyGenerator = "")public List&lt;TreeNode&gt; getCity()&#123; List&lt;Address&gt; address = addressMapper.selectList(new EntityWrapper&lt;&gt;()); List&lt;TreeNode&gt; treeNodeList = buildGroupTree(addresses); return treeNodeList;&#125;//utilsprivate List&lt;TreeNode&gt; bulidGroupList(List&lt;Address&gt; addressesList)&#123; List&lt;TreeNode&gt; list = Lists.newArrayList(); TreeNode node; for(Address group : addressesList)&#123; node = new TreeNode(); node.setId(group.getId()); node.setPid(group.getPid); node.setNodeCode(group.getAdCode()); node.setNodeName(group.getName()); list.add(node); &#125; return RecursionTreeUtil.getChildTreeNodes(list,xxxxxL);&#125;public class RecursionTreeUtil&#123; public static List&lt;TreeNode&gt; getChildTreeNodes(List&lt;TreeNode&gt; list,Long parentId)&#123; List&lt;TreeNode&gt; returnList = new ArrayList&lt;&gt;(); for(TreeNode treeNode : list)&#123; if(treeNode.getPid() == null)&#123; continue; &#125; if(Objects.equals(treeNode.getPid(),parentId))&#123; recursion(list,treeNode); returnList.add(treeNode); &#125; &#125; &#125;&#125;private static void recursionFn(List&lt;TreeNode&gt; list,TreeNode node)&#123; List&lt;TreeNode&gt; childList = getChildlist(list,node); if(PublicUtil.isEmpty(childList))&#123; return; &#125; node.setChildren(childList); for(TreeNode tChild : childList)&#123; recursionFn(list, tChild); &#125;&#125;public class PublicUtil &#123; public static boolean isEmpty(Object pObj) &#123; if (pObj == null) &#123; return true; &#125; if (pObj == "") &#123; return true; &#125; if (pObj instanceof String) &#123; return ((String) pObj).length() == 0; &#125; else if (pObj instanceof Collection) &#123; return ((Collection) pObj).isEmpty(); &#125; else if (pObj instanceof Map) &#123; return ((Map) pObj).size() == 0; &#125; return false; &#125; public static boolean isNotEmpty(Object pObj) &#123; if (pObj == null) &#123; return false; &#125; if (pObj == "") &#123; return false; &#125; if (pObj instanceof String) &#123; return ((String) pObj).length() != 0; &#125; else if (pObj instanceof Collection) &#123; return !((Collection) pObj).isEmpty(); &#125; else if (pObj instanceof Map) &#123; return ((Map) pObj).size() != 0; &#125; return true; &#125; public static boolean isEquals(Integer i1,Integer i2) &#123; if(i1 == null &amp;&amp; i2 == null)&#123; return true ; &#125; if(i1 != null &amp;&amp; i2 != null)&#123; return i1.equals(i2); &#125; return false; &#125;&#125;//iDaoList&lt;T&gt; selectList(@Param("ew") Wrapper&lt;T&gt; wrapper);//entity@Datapublic class TreeNode implements Serializable&#123; private String nodeCode; private String nodeName; private Long id; private Long pid; private List&lt;TreeNode&gt; childeren;&#125; 3.2 简单模式的 JSON 数据 123456789101112131415161718192021222324252627282930313233343536数据结构：var nodes = [ &#123;id:1, pId:0, name: "父节点1"&#125;, &#123;id:11, pId:1, name: "子节点1"&#125;, &#123;id:12, pId:1, name: "子节点2"&#125;];// 获取简单JSON数据public static List&lt;Map&lt;String, Object&gt;&gt; getStandardJSON() &#123; // 根据不同框架获取对应的List数据 List&lt;Map&lt;String, Object&gt;&gt; queryList = query.find(); List&lt;Map&lt;String, Object&gt;&gt; list = Lists.newArrayList(); treeList = getChild(queryList.get(0).get("id") , queryList , list ); return list;&#125;public static List&lt;Map&lt;String, Object&gt;&gt; getChild(String id, List&lt;Map&lt;String, Object&gt;&gt; allList, List&lt;Map&lt;String, Object&gt;&gt; simpleList) &#123; // 子节点 List&lt;Map&lt;String, Object&gt;&gt; childList = Lists.newArrayList(); for (Map&lt;String, Object&gt; map : allList) &#123; // 遍历所有节点，将父节点id与传过来的id比较 if (!ParamValidUtils.isEmpty(map.get("parent_id"))) &#123; if (map.get("parent_id").toString().equals(id)) &#123; simpleList.add(map); childList.add(map); &#125; &#125; &#125; // 把子节点的子节点再循环一遍 for (Map&lt;String, Object&gt; map : childList) &#123; getChild(map.get("id").toString(), allList, simpleList); &#125; // 递归退出条件 if (childList.size() == 0) &#123; return simpleList; &#125; return simpleList;]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百万数据导出]]></title>
    <url>%2F2020%2F08%2F14%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200814%2F</url>
    <content type="text"><![CDATA[百万数据导出 背景：因为客户需要5年系统维护，我们根据现有数据增长量，预测客户数据可能达到100w左右，同时，根据用户要求，可以导出数据库所有数据，现有的开发测试数据仅有9w左右，而且网上一些不负责任的博客，经过尝试，都不符合要求，导出的表有20多列字段，出现各种问题，所以最终自己实现。实现结果还算满意，需求符合了，在规定时间内返回结果了，但是，还是有很多值得提升的点，因为一些个人原因，只能后续 闲暇时候再研究了，应该不会再遇到这种导出100w左右的需求了，事情也不能说的太绝对了，特此记录一下。最终50w数据3.9分钟，100w数据13分钟。 1.导数据 1因为本身数据库中没有那么多数据，又要根据业务需要，所以我们没有采用批量生成方法，而是把现有数据重复导入，关闭主键ID，使用ID可以重复，使用navicat 将数据导出到excel中，再次导入，重复操作，最终数据达到100多w。注：不要使用生成sql，一条条插入，会怀疑人生，同事亲身试验，卡到爆 2.整理导出功能思路 1相信大家都做过导出功能，我们一开始设置每次也就只有1w条左右，没有发现问题，那时数据也没有那么多，只有几千条，但是，数据一多就会发现问题，第一：导出OOM，第二：效率低下，导出功能实现其实也很简单，就是查询，写入excel（这是我们的需求） 3.写查询 1更改现有查询sql，并且将查询数量从原先的1w改为100w，有意思的事情就发生了，有请求超时问题，超出存放范围溢出问题等等，最后我使用了多线程分段查询解决了查询慢的问题，但是，数据要合并，每次查询哪个线程快慢无法决定，所以使用了CopyOnWriteArrayList，写时复制底层使用了lock锁，读数据时候可以多线程，但是，写的时候保证每次只有一个线程在写，废话太多了，直接上代码吧 1234567891011121314151617181920212223242526final CountDownLatch latch = new CountDownLatch(10);CopyOnWriteArrayList&lt;&gt; arr = new CopyOnWriteArrayList&lt;&gt;();for(int i=1;i&lt;=10;i++)&#123; Page&lt;XX&gt; page = new Page&lt;&gt;(i,pageSize/10); new Thread(()-&gt;&#123; Date xxx =null; try &#123; if(StringUtils.isEmpty(xx) == false)&#123; xxx = DateUtils.formatDate(xx); &#125; //调用查询接口 arr.add(service.select(page,xxx....)); &#125;catch(Exception e)&#123; e.printStack(); &#125; latch.countDown(); System.out.println("剩下" + latch.getCount()+"个未完成"); &#125;).start();&#125; //等待线程收集齐数据try &#123; latch.await();&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; 4.写入Excel 1使用POI，只要注意OOM内存溢出问题就可以了，这里省略，使用XSSFWorkbook就可以了 5.优化思考 1任务虽然完成了，对于测试过程中也发现一些问题，查询慢，查询返回不回结果的问题解决了，但是，最大的问题又出现了，写入excel特别慢，因为只是使用了一个sheet存放100w数据，我现在的优化想法是使用多线程查询出的结果，直接用多线程再次写入每个sheet，同时进行，不阻塞数据，应该会有很大效率提升，因为暂时没有需求，加之近期又主动离职，暂时只能这样了，后续有实现，再次记录]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据排序]]></title>
    <url>%2F2020%2F08%2F13%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200813%2F</url>
    <content type="text"><![CDATA[排序（指定字段升序排列后返回） 123list.sort((s1, s2) -&gt; &#123; return s1.getSumaryDate().compareTo(s2.getSumaryDate());&#125;); 降序-字符串反转排序 12345678910111213141516171819202122232425// 方法1public static String reverse1(String str)&#123; return new StringBuffer(str).reverse().toString();&#125; // 方法2public static String reverse3(String s)&#123; char[] array = s.toCharArray(); String reverse = ""; for (int i = array.length - 1; i &gt;= 0; i--)&#123; reverse += array[i]; &#125; return reverse; &#125; //方法3 public static String reverse2(String s)&#123; int length = s.length(); String reverse = ""; for (int i = 0; i &lt; length; i++)&#123; //在新字符串前面添加读取字符，实现翻转 reverse = s.charAt(i) + reverse; &#125; return reverse; &#125; 降序-List反转 1234567891011121314151617181920212223242526272829303132333435363738394041//方法一：使用Collections.reverse(list)方法反转//方法二：自己迭代list实现反转import java.util.ArrayList;import java.util.Collections;import java.util.List;public class Test &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; list.add(i + " "); &#125; Test test = new Test(); test.print(list); //反转 test.reverseList1(list); test.reverseList2(list); test.print(list); &#125; public void reverseList1(List&lt;String&gt; list) &#123; Collections.reverse(list); &#125; public void reverseList2(List&lt;String&gt; list) &#123; List&lt;String&gt; tmpList = new ArrayList&lt;&gt;(); for (int i = list.size() - 1; i &gt;= 0; i--) &#123; tmpList.add(list.get(i)); &#125; list.clear(); list.addAll(tmpList); &#125; public void print(List&lt;String&gt; list) &#123; for (int i = 0; i &lt; list.size(); i++) &#123; System.out.print((list.get(i))); &#125; System.out.println(); &#125;&#125; 除此之外还有JDK8新特性Stream流 sql语句排序，order by … desc/asc等]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webService学习]]></title>
    <url>%2F2020%2F08%2F13%2F%E5%85%B6%E5%AE%83%2Fwebservice%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[webService学习 1.webService 概述 webservice 跨平台 跨编程语言 远程调用技术 服务端 (服务的提供者) java webservice 客户端 (服务的消费者) java 调用webservice 2.webService 三个要素 2.1 SOAP（Simple Object Access protocol） 简单对象的访问协议 webservice 底层传输协议 SOAP = HTTP 协议 + XML（W3C 标准规范） 格式数据 2.2 WSDL (web service description language) webserivce的服务使用说明书 2.3 UUDI 是一种目录服务（地址: 注册UUDI 目录）—–&gt;商业化道路 资源共享促进全球经济合作 3.webService 第一个程序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748webService 服务端开发使用jdk开发webService 的方式 Java API for XML Web Services JAX-WS java 开发的webService 服务1.安装jdk 服务 在1.6版本之后 配置换进变量2.开发服务 服务必须存在接口 动态代理技术 //天气查询服务 @WebService //注解 修饰范围 在类上 作用：用来标识这个类|接口是一个webService接口|类 public interface WeatherWebService&#123; public String queryWeatherByCity(String cityName); &#125; 3.开发服务实现类 @WebService WeatherServiceImpl implements WeatherWebService&#123; public String queryWeatherByCity(String cityName)&#123; return &quot;天气不好，注意身体。。。。。&quot;; &#125; &#125; 4.发布服务 Endpoint.published(&quot;服务地址&quot;,服务实现类对象);5.测试是否发布成功 浏览器访问 服务地址?wsdl webService 客户端开发1.根据服务地址查看wsdl使用说明书 自下往上查看2.根据wsdl地址生成客户端调用代码 wsimport -s . -p com.xxx.client wsdl地址3.将生成客户端代码拷贝当前项目4.调用 创建服务视图对象 通过服务视图对象获取服务的核心类对象 服务核心对象的调用方法 第一种调用方式 基于服务视图对象的调用 WeatherServiceImpl weatherServiceImpl = new WeatherServiceImpl(); WeatherServiceImpl weatherServicePortType = weatherServiceImpl.getWeatherServiceImplPort(); String name = weatherServicePortType.queryWeratherByCity(&quot;北京&quot;);第二种调用方式 标准客户端调用方式 通过jdk提供的通用服务对象进行调用 参数1：wsdl地址 参数2：wsdl命名空间对象 QName QName = new QName(&quot;目标命名空间targetName&quot;,&quot;服务视图名&quot;); Service service = Service.create(new URL(&quot;url?wsdl&quot;),QName); WeatherServiceImpl portType = service.getPort(WeatherServiceImpl.class); String name = portType.queryWeatherByCity(&quot;天津&quot;); 4.ApacheCXF 4.1 使用CXF框架发布webservice 引入CXF jar包 123456&lt;!-- https://mvnrepository.com/artifact/org.apache.cxf/cxf-spring-boot-starter-jaxws --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-spring-boot-starter-jaxws&lt;/artifactId&gt; &lt;version&gt;3.2.8&lt;/version&gt;&lt;/dependency&gt; 开发服务接口类 @Webservice注解 配置]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[excel宏-sheet合并]]></title>
    <url>%2F2020%2F08%2F13%2F%E5%85%B6%E5%AE%83%2Fexcel%E5%AE%8F-sheet%E5%90%88%E5%B9%B6%2F</url>
    <content type="text"><![CDATA[和同事合作写产品文档，但是写完后发现两个人没法合并，然后百度查到excel宏可以解决这个问题，以下是宏合并脚本 123456789101112131415161718192021222324Sub CombineWorkbooks()Dim FilesToOpen, ftDim x As IntegerApplication.ScreenUpdating = FalseOn Error GoTo errhandlerFilesToOpen = Application.GetOpenFilename _(FileFilter:=&quot;Micrsofe Excel文件(*.xls), *.xls&quot;, _MultiSelect:=True, Title:=&quot;要合并的文件&quot;)If TypeName(FilesToOpen) = &quot;boolean&quot; ThenMsgBox &quot;没有选定文件&quot;&apos;GoTo errhandlerEnd Ifx = 1While x &lt;= UBound(FilesToOpen)Set wk = Workbooks.Open(Filename:=FilesToOpen(x))wk.Sheets().Move after:=ThisWorkbook.Sheets _(ThisWorkbook.Sheets.Count)x = x + 1WendMsgBox &quot;合并成功完成！&quot;errhandler:&apos;MsgBox Err.Description&apos;Resume errhandlerEnd Sub]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程与线程池]]></title>
    <url>%2F2020%2F08%2F11%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200811%2F</url>
    <content type="text"><![CDATA[1.new Thread的弊端//平时我常用的写法-SonarLint经常提示使用线程池方式123new Thread(()-&gt;&#123; &#125;).start(); 1234567a. 每次new Thread新建对象性能差。b. 线程缺乏统一管理，可能无限制新建线程，相互之间竞争，及可能占用过多系统资源导致死机或oom。c. 缺乏更多功能，如定时执行、定期执行、线程中断。相比new Thread，Java提供的四种线程池的好处在于：a. 重用存在的线程，减少对象创建、消亡的开销，性能佳。b. 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。c. 提供定时执行、定期执行、单线程、并发数控制等功能。 2.Executors提供四种线程池1234newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。线程池的规模不存在限制。newFixedThreadPool 创建一个固定长度线程池，可控制线程最大并发数，超出的线程会在队列中等待。newScheduledThreadPool 创建一个固定长度线程池，支持定时及周期性任务执行。newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 (1). newCachedThreadPool 1234567891011121314151617ExecutorService cachedThreadPool = Executors.newCachedThreadPool();for (int i = 0; i &lt; 10; i++) &#123; final int index = i; try &#123; Thread.sleep(index * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; cachedThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(index); &#125; &#125;);&#125; 线程池为无限大，当执行第二个任务时第一个任务已经完成，会复用执行第一个任务的线程，而不用每次新建线程。 (2). newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。示例代码如下： 1234567891011121314151617ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3);for (int i = 0; i &lt; 10; i++) &#123; final int index = i; fixedThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;);&#125; (3) newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。延迟执行示例代码如下： 12345678ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5);scheduledThreadPool.schedule(new Runnable() &#123; @Override public void run() &#123; System.out.println("delay 3 seconds"); &#125;&#125;, 3, TimeUnit.SECONDS); 表示延迟3秒执行。定期执行示例代码如下：1234567scheduledThreadPool.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; System.out.println("delay 1 seconds, and excute every 3 seconds"); &#125;&#125;, 1, 3, TimeUnit.SECONDS); 表示延迟1秒后每3秒执行一次。ScheduledExecutorService比Timer更安全，功能更强大。 (4)、newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。示例代码如下： 1234567891011121314151617ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor();for (int i = 0; i &lt; 10; i++) &#123; final int index = i; singleThreadExecutor.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;);&#125; 结果依次输出，相当于顺序执行各个任务。 3.ExecutorService中submit和execute的区别以下这是submit 的源码：1234567891011121314151617181920212223242526272829303132public abstract class AbstractExecutorService implements ExecutorService &#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value); &#125; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask; &#125; //....&#125; 可以看出submit最终返回的是FutureTask对象，而execute:123public interface Executor &#123; void execute(Runnable command);&#125; 具体的实现在ThreadPoolExecutor类中1234567891011121314151617181920public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; 所以，submit内部调用execute，且submit有返回值，方便exception处理。submit Demo:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import java.util.ArrayList;import java.util.List;import java.util.Random;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;public class Main &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); List&lt;Future&lt;String&gt;&gt; resultList = new ArrayList&lt;Future&lt;String&gt;&gt;(); // 创建10个任务并执行 for (int i = 0; i &lt; 10; i++) &#123; // 使用ExecutorService执行Callable类型的任务，并将结果保存在future变量中 Future&lt;String&gt; future = executorService.submit(new TaskWithResult(i)); // 将任务执行结果存储到List中 resultList.add(future); &#125; executorService.shutdown(); // 遍历任务的结果 for (Future&lt;String&gt; fs : resultList) &#123; try &#123; System.out.println(fs.get()); // 打印各个线程（任务）执行的结果 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; executorService.shutdownNow(); e.printStackTrace(); return; &#125; &#125; &#125;&#125;class TaskWithResult implements Callable&lt;String&gt; &#123; private int id; public TaskWithResult(int id) &#123; this.id = id; &#125; /** * 任务的具体过程，一旦任务传给ExecutorService的submit方法，则该方法自动在一个线程上执行。 * * @return * @throws Exception */ public String call() throws Exception &#123; System.out.println("call()方法被自动调用,干活！！！ " + Thread.currentThread().getName()); if (new Random().nextBoolean()) throw new TaskException("Meet error in task." + Thread.currentThread().getName()); // 一个模拟耗时的操作 for (int i =9; i &gt; 0; i--) ; return "call()方法被自动调用，任务的结果是：" + id + " " + Thread.currentThread().getName(); &#125;&#125;class TaskException extends Exception &#123; public TaskException(String message) &#123; super(message); &#125;&#125; Runnable和Callable的区别是，(1)Callable规定的方法是call(),Runnable规定的方法是run().(2)Callable的任务执行后可返回值，而Runnable的任务是不能返回值得(3)call方法可以抛出异常，run方法不可以(4)运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[K8S]]></title>
    <url>%2F2020%2F08%2F10%2F%E6%88%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%2F%E6%88%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83-K8S%2F</url>
    <content type="text"><![CDATA[Kubernetes（K8S） 因为前几天电脑坏了，自己的环境都没有了，打算重新装一下K8S，记录一下，因为明天还要加班，争取今天晚上搞定 1.本机硬件：24G内存＋i7-5代，为了不影响开发，打算搭建1主3从外加一个数据卷 2.系统使用Ubuntu Server X64 18.04LTS 长期支持版 3.节点规划: | 主机名 | IP | 角色 | 系统 | CPU/内存 | 磁盘 || —————— | ————— | —— | ——————- | ——– | —- || kubernetes-master | 192.168.xxx.110 | Master | Ubuntu Server 18.04 | 2 核 3G | 20G || kubernetes-node-01 | 192.168.xxx.120 | Node | Ubuntu Server 18.04 | 2 核 3G | 20G || kubernetes-node-02 | 192.168.xxx.121 | Node | Ubuntu Server 18.04 | 2 核 3G | 20G || kubernetes-node-03 | 192.168.xxx.122 | Node | Ubuntu Server 18.04 | 2 核 3G | 20G || kubernetes-volumes | 192.168.xxx.140 | NFS | Ubuntu Server 18.04 | 2 核 3G | 20G | 1.基础准备 关闭交换空间 1swapoff -a 避免开机启动交换空间 12# 注释 swap 开头的行vi /etc/fstab 关闭防火墙 1ufw disable 配置DNS 12# 取消 DNS 行注释，并增加 DNS 配置如：114.114.114.114，修改后重启下计算机vi /etc/systemd/resolved.conf 安装 Docker 12sudo apt-get updatesudo apt install docker.io 配置 Docker 建议使用阿里云 通过修改 daemon 配置文件 /etc/docker/daemon.json 来使用加速器 1234567891011&#123; "exec-opts": [""], "log-driver": "", "log-opts": &#123; "max-size": "" &#125;, "registry-mirrors": [ ], "storage-driver": ""&#125; 重启 Docker 12systemctl daemon-reloadsystemctl restart docker 安装 Kubernetes 必备工具 安装三个 Kubernetes 必备工具，分别为 kubeadm，kubelet，kubectl 12345678910111213# 安装系统工具apt-get update &amp;&amp; apt-get install -y apt-transport-https# 安装 GPG 证书curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -# 写入软件源；注意：我们用系统代号为 bionic，但目前阿里云不支持，所以沿用 16.04 的 xenialcat &lt;&lt; EOF &gt;/etc/apt/sources.list.d/kubernetes.listdeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOF# 安装apt-get update &amp;&amp; apt-get install -y kubelet kubeadm kubectl 同步时间 设置时区 1dpkg-reconfigure tzdata 时间同步 12345678# 安装 ntpdateapt-get install ntpdate# 设置系统时间与网络时间同步（cn.pool.ntp.org 位于中国的公共 NTP 服务器）ntpdate cn.pool.ntp.org# 将系统时间写入硬件时间hwclock --systohc 确认时间 1234date# 输出如下（自行对照与系统时间是否一致）Sun Feb 23 12:05:17 CST 2020 修改cloud.cfg 主要作用是防止重启后主机名还原 1234vi /etc/cloud/cloud.cfg# 该配置默认为 false，修改为 true 即可preserve_hostname: true 单独节点配置 注意： 为 Master 和 Node 节点单独配置对应的 IP 和 主机名 配置IP 编辑 vi /etc/netplan/50-cloud-init.yaml 配置文件，修改内容如下 12345678network: ethernets: ens33: addresses: [192.168.xxx.110/24] gateway4: 192.168.xxx.2 nameservers: addresses: [192.168.xxx.2] version: 2 使用 netplan apply 命令让配置生效 配置主机名 1234567# 修改主机名hostnamectl set-hostname kubernetes-master# 配置 hostscat &gt;&gt; /etc/hosts &lt;&lt; EOF192.168.xxx.110 kubernetes-masterEOF 2.安装集群 创建并修改配置 12# 导出配置文件kubeadm config print init-defaults --kubeconfig ClusterConfiguration &gt; kubeadm.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243apiVersion: kubeadm.k8s.io/v1beta2bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: # 修改为主节点 IP advertiseAddress: 192.168.81.110 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: kubernetes-master taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta2certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcd# 国内不能访问 Google，修改为阿里云imageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfiguration# 修改版本号kubernetesVersion: v1.17.3networking: dnsDomain: cluster.local # 配置 POD 所在网段为我们虚拟机不重叠的网段（这里用的是 Flannel 默认网段） podSubnet: "10.244.0.0/16" serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125; 查看所需镜像 12345678910kubeadm config images list --config kubeadm.yml# 输出如下registry.aliyuncs.com/google_containers/kube-apiserver:v1.17.3registry.aliyuncs.com/google_containers/kube-controller-manager:v1.17.3registry.aliyuncs.com/google_containers/kube-scheduler:v1.17.3registry.aliyuncs.com/google_containers/kube-proxy:v1.17.3registry.aliyuncs.com/google_containers/pause:3.1registry.aliyuncs.com/google_containers/etcd:3.4.3-0registry.aliyuncs.com/google_containers/coredns:1.6.5 拉取所需镜像 12345678910kubeadm config images pull --config kubeadm.yml# 输出如下[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.17.3[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.17.3[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.17.3[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.17.3[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.1[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.4.3-0[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:1.6.5 安装主节点 执行以下命令初始化主节点，该命令指定了初始化时需要使用的配置文件，其中添加 --upload-certs 参数可以在后续执行加入节点时自动分发证书文件。追加的 tee kubeadm-init.log 用以输出日志。 注意： 如果安装 kubernetes 版本和下载的镜像版本不统一则会出现 timed out waiting for the condition 错误。中途失败或是想修改配置可以使用 kubeadm reset 命令重置配置，再做初始化操作即可。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273kubeadm init --config=kubeadm.yml --upload-certs | tee kubeadm-init.log# 输出如下[init] Using Kubernetes version: v1.17.3[preflight] Running pre-flight checks[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Starting the kubelet[certs] Using certificateDir folder "/etc/kubernetes/pki"[certs] Generating "ca" certificate and key[certs] Generating "apiserver" certificate and key[certs] apiserver serving cert is signed for DNS names [kubernetes-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.81.110][certs] Generating "apiserver-kubelet-client" certificate and key[certs] Generating "front-proxy-ca" certificate and key[certs] Generating "front-proxy-client" certificate and key[certs] Generating "etcd/ca" certificate and key[certs] Generating "etcd/server" certificate and key[certs] etcd/server serving cert is signed for DNS names [kubernetes-master localhost] and IPs [192.168.81.110 127.0.0.1 ::1][certs] Generating "etcd/peer" certificate and key[certs] etcd/peer serving cert is signed for DNS names [kubernetes-master localhost] and IPs [192.168.81.110 127.0.0.1 ::1][certs] Generating "etcd/healthcheck-client" certificate and key[certs] Generating "apiserver-etcd-client" certificate and key[certs] Generating "sa" key and public key[kubeconfig] Using kubeconfig folder "/etc/kubernetes"[kubeconfig] Writing "admin.conf" kubeconfig file[kubeconfig] Writing "kubelet.conf" kubeconfig file[kubeconfig] Writing "controller-manager.conf" kubeconfig file[kubeconfig] Writing "scheduler.conf" kubeconfig file[control-plane] Using manifest folder "/etc/kubernetes/manifests"[control-plane] Creating static Pod manifest for "kube-apiserver"W0223 12:38:57.210893 9130 manifests.go:214] the default kube-apiserver authorization-mode is "Node,RBAC"; using "Node,RBAC"[control-plane] Creating static Pod manifest for "kube-controller-manager"[control-plane] Creating static Pod manifest for "kube-scheduler"W0223 12:38:57.214165 9130 manifests.go:214] the default kube-apiserver authorization-mode is "Node,RBAC"; using "Node,RBAC"[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s[apiclient] All control plane components are healthy after 19.005825 seconds[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace[kubelet] Creating a ConfigMap "kubelet-config-1.17" in namespace kube-system with the configuration for the kubelets in the cluster[upload-certs] Storing the certificates in Secret "kubeadm-certs" in the "kube-system" Namespace[upload-certs] Using certificate key:91f1d04e74abd60fbadf2afaae656a5c5bfc3761e5a4a69d6727e429c997165c[mark-control-plane] Marking the node kubernetes-master as control-plane by adding the label "node-role.kubernetes.io/master=''"[mark-control-plane] Marking the node kubernetes-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule][bootstrap-token] Using token: abcdef.0123456789abcdef[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.xxx.110:6443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:3eac1be34c9e324279ebd843087e7dd002b3102c7d14313aec490cd73b4138ad 配置Kubectl 12345mkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/config# 非 ROOT 用户执行chown $(id -u):$(id -g) $HOME/.kube/config 验证是否成功 12345kubectl get node# 输出如下NAME STATUS ROLES AGE VERSIONkubernetes-master NotReady master 115s v1.17.3 安装从节点 将 Node 节点加入到集群中很简单，只需要在 Node 服务器上安装 kubeadm，kubectl，kubelet 三个工具，然后使用 kubeadm join 命令加入即可 123456789101112kubeadm join 192.168.xxx.110:6443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:3eac1be34c9e324279ebd843087e7dd002b3102c7d14313aec490cd73b4138ad # 输出如下[preflight] Running pre-flight checks[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.17" ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Starting the kubelet[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... 验证是否成功 回到 Master 主节点查看是否安装成功 注意： 如果 Node 节点加入 Master 时配置有问题可以在 Node 节点上使用 kubeadm reset 重置配置再使用 kubeadm join 命令重新加入即可。希望在 master 节点删除 node ，可以使用 kubeadm delete nodes &lt;NAME&gt; 删除。 12345678kubectl get nodes# 输出如下NAME STATUS ROLES AGE VERSIONkubernetes-master NotReady master 17m v1.17.3kubernetes-node1 NotReady &lt;none&gt; 24s v1.17.3kubernetes-node2 NotReady &lt;none&gt; 15s v1.17.3kubernetes-node3 NotReady &lt;none&gt; 7s v1.17.3 查看Pods状态 coredns 尚未运行，此时我们还需要安装网络插件 1234567891011121314watch kubectl get pods -n kube-system -o wide# 输出如下NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-9d85f5447-czrdk 0/1 Pending 0 19m &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;coredns-9d85f5447-zsf6f 0/1 Pending 0 19m &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;etcd-kubernetes-master 1/1 Running 0 20m 192.168.81.110 kubernetes-master &lt;none&gt; &lt;none&gt;kube-apiserver-kubernetes-master 1/1 Running 0 20m 192.168.81.110 kubernetes-master &lt;none&gt; &lt;none&gt;kube-controller-manager-kubernetes-master 1/1 Running 0 20m 192.168.81.110 kubernetes-master &lt;none&gt; &lt;none&gt;kube-proxy-jf9jg 1/1 Running 0 3m19s 192.168.81.122 kubernetes-node3 &lt;none&gt; &lt;none&gt;kube-proxy-t2rz5 1/1 Running 0 3m27s 192.168.81.121 kubernetes-node2 &lt;none&gt; &lt;none&gt;kube-proxy-vszhp 1/1 Running 0 3m36s 192.168.81.120 kubernetes-node1 &lt;none&gt; &lt;none&gt;kube-proxy-zpjk2 1/1 Running 0 19m 192.168.81.110 kubernetes-master &lt;none&gt; &lt;none&gt;kube-scheduler-kubernetes-master 1/1 Running 0 20m 192.168.81.110 kubernetes-master &lt;none&gt; &lt;none&gt; kubeadm init 的执行过程 init： 指定版本进行初始化操作 preflight： 初始化前的检查和下载所需要的 Docker 镜像文件 kubelet-start： 生成 kubelet 的配置文件 var/lib/kubelet/config.yaml，没有这个文件 kubelet 无法启动，所以初始化之前的 kubelet 实际上启动不会成功 certificates： 生成 Kubernetes 使用的证书，存放在 /etc/kubernetes/pki 目录中 kubeconfig： 生成 KubeConfig 文件，存放在 /etc/kubernetes 目录中，组件之间通信需要使用对应文件 control-plane： 使用 /etc/kubernetes/manifest 目录下的 YAML 文件，安装 Master 组件 etcd： 使用 /etc/kubernetes/manifest/etcd.yaml 安装 Etcd 服务 wait-control-plane： 等待 control-plan 部署的 Master 组件启动 apiclient： 检查 Master 组件服务状态。 uploadconfig： 更新配置 kubelet： 使用 configMap 配置 kubelet patchnode： 更新 CNI 信息到 Node 上，通过注释的方式记录 mark-control-plane： 为当前节点打标签，打了角色 Master，和不可调度标签，这样默认就不会使用 Master 节点来运行 Pod bootstrap-token： 生成 token 记录下来，后边使用 kubeadm join 往集群中添加节点时会用到 addons： 安装附加组件 CoreDNS 和 kube-proxy 3.网络插件 下载Calico 配置文件并修改 123456wget https://docs.projectcalico.org/manifests/calico.yamlvi calico.yaml修改第 611 行，将 192.168.0.0/16 修改为 10.244.0.0/16，可以通过如下命令快速查找显示行号：:set number查找字符：/要查找的字符，输入小写 n 下一个匹配项，输入大写 N 上一个匹配项 安装网络插件 Calico 参考官方文档安装：https://docs.projectcalico.org/getting-started/kubernetes/quickstart 1234567891011121314151617181920212223242526kubectl apply -f calico.yaml# 输出如下configmap/calico-config createdcustomresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org createdclusterrole.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrole.rbac.authorization.k8s.io/calico-node createdclusterrolebinding.rbac.authorization.k8s.io/calico-node createddaemonset.apps/calico-node createdserviceaccount/calico-node createddeployment.apps/calico-kube-controllers createdserviceaccount/calico-kube-controllers created 验证是否成功 查看 Calico 网络插件处于 Running 状态即表示安装成功 12345678910111213141516171819watch kubectl get pods --all-namespaces# 输出如下NAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-77c4b7448-vzsb7 1/1 Running 0 3m52skube-system calico-node-5gr6m 1/1 Running 0 3m53skube-system calico-node-5pwj6 1/1 Running 0 3m53skube-system calico-node-drp46 1/1 Running 0 3m53skube-system calico-node-npjpx 1/1 Running 0 3m53skube-system coredns-9d85f5447-czrdk 1/1 Running 0 32mkube-system coredns-9d85f5447-zsf6f 1/1 Running 0 32mkube-system etcd-kubernetes-master 1/1 Running 0 33mkube-system kube-apiserver-kubernetes-master 1/1 Running 0 33mkube-system kube-controller-manager-kubernetes-master 1/1 Running 0 33mkube-system kube-proxy-jf9jg 1/1 Running 0 16mkube-system kube-proxy-t2rz5 1/1 Running 0 16mkube-system kube-proxy-vszhp 1/1 Running 0 16mkube-system kube-proxy-zpjk2 1/1 Running 0 32mkube-system kube-scheduler-kubernetes-master 1/1 Running 0 33m 查看节点状态处于Ready 即表示安装成功 12345678kubectl get nodes# 输出如下NAME STATUS ROLES AGE VERSIONkubernetes-master Ready master 33m v1.17.3kubernetes-node1 Ready &lt;none&gt; 17m v1.17.3kubernetes-node2 Ready &lt;none&gt; 16m v1.17.3kubernetes-node3 Ready &lt;none&gt; 16m v1.17.3]]></content>
      <categories>
        <category>我的学习环境</category>
      </categories>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[容器服务]]></title>
    <url>%2F2020%2F08%2F05%2F%E6%88%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%2F%E6%88%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83-%E5%AE%B9%E5%99%A8%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[容器服务 MySQL 12345678910111213141516171819version: '3.1'services: db: image: mysql:8.0.20 restart: always container_name: mysql environment: - TZ=Asia/Shanghai - MYSQL_ROOT_PASSWORD=123456 command: --default-authentication-plugin=mysql_native_password --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci --explicit_defaults_for_timestamp=true --lower_case_table_names=1 ports: - 3306:3306 volumes: - ./data:/var/lib/mysql GitLab 12345678910111213141516171819202122version: '3.1'services: web: image: 'twang2218/gitlab-ce-zh:11.1.4' restart: always hostname: 'gitlab.funtl.com' container_name: 'gitlab' environment: TZ: 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG: | external_url 'http://gitlab.funtl.com' gitlab_rails['gitlab_shell_ssh_port'] = 2222 unicorn['port'] = 8888 nginx['listen_port'] = 80 ports: - '80:80' - '443:443' - '2222:22' volumes: - ./config:/etc/gitlab - ./data:/var/opt/gitlab - ./logs:/var/log/gitlab Nexus 1234567891011121314mkdir /usr/local/docker/nexus/data &amp;&amp; chown -R 200 /usr/local/docker/nexus/dataversion: '3.5'services: nexus: restart: always image: sonatype/nexus3:3.23.0 container_name: nexus environment: INSTALL4J_ADD_VM_PARAMS: -XX:ActiveProcessorCount=4 ports: - 80:8081 volumes: - ./data:/nexus-data Jenkins 123456789101112131415version: '3.5'services: jenkins: restart: always image: jenkins/jenkins:lts container_name: jenkins environment: TZ: Asia/Shanghai ports: - 80:8080 - 50000:50000 volumes: - data:/var/jenkins_homevolumes: data:]]></content>
      <categories>
        <category>我的学习环境</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2020%2F08%2F03%2F%E6%88%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%2F%E6%88%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83-Docker%2F</url>
    <content type="text"><![CDATA[Docker 1.Linux安装(略) 以下为shell配置脚本 功能说明在注释中 适用于Centos7 config.sh 1234567891011121314##### 用户配置区 开始 ###### 1.安装 ntpdate 命令# 2.配置 阿里云镜像# 3.关闭防火墙# 4.重启系统##### 用户配置区 结束 ######!/bin/bashyum install -y vimyum install -y ntpdatentpdate -b ntp1.aliyun.comsystemctl stop firewalldsystemctl disable firewalldsed -ri s/SELINUX=enforcing/SELINUX=disabled/g /etc/selinux/configreboot ​ Confluence.sh 12345678910111213141516171819202122232425262728293031##### 用户配置区 开始 ###### confluence 构建企业WIKI及工单系统##### 用户配置区 结束 ######!/bin/bashecho "开始安装JDK1.8"yum -y install java-1.8.0-openjdk-1.8.0.191.b12-1.el7_6.x86_64 java -versionecho "java安装完成"echo -e "\n"echo "开始安装mariadb"yum -y install mariadb-server mariadbsystemctl start mariadbsystemctl enable mariadbecho "此处有bug，只能输入123456，如果不想设置，请按ctrl+c暂停脚本"echo "进入数据库后，复制下面命令"echo "create database jira default character set utf8 collate utf8_bin;"echo "exit"read -p "请输入mariadb密码:" passwordmysqladmin -u root password $passwordmysql -uroot -p$passwordecho "数据库设置完成"echo -e "\n"echo "开始下载conflunece8.0.2-x64版本，如果需要更改请自行更改"yum -y install wgetwget https://www.atlassian.com/software/jira/downloads/binary/atlassian-jira-software-8.0.2-x64.binchmod 755 atlassian-jira-software-8.0.2-x64.bin./atlassian-jira-software-8.0.2-x64.bino1iy initserver.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/env bash## Author: baize# Date: 2019/05/25# Usage:system# turn off firewalld and selinux.systemctl disable firewalld &amp;&amp; systemctl stop firewalldSTATUS=$(getenforce)if [ $STATUS == "Disabled" ];then printf "SELINUX is closed.\n"else sed -ri s/SELINUX=enforcing/SELINUX=disabled/g /etc/selinux/config setenforce 0fi# init yumrepo and install always software tools. mkdir /etc/yum.repos.d/repobak mv /etc/yum.repos.d/* /etc/yum.repos.d/repobak/ curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repoif [ $? -ne 0 ];then printf "Please check your network!!!\n" exitelse curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo if [ $? -ne 0 ];then printf "Please check your network!!!\n" exit else sed -rie '/aliyuncs*/d' /etc/yum.repos.d/CentOS-Base.repo yum clean all &amp;&amp; yum makecache fast fifi yum -y install vim net-tools wget ntpdate ShellCheck cmake make lftp yum -y groupinstall "Development Tools"# time upload rsync. ntpdate -b ntp1.aliyun.com# sshd majorization. sed -ri s/"#UseDNS yes"/"UseDNS no"/g /etc/ssh/sshd_config systemctl restart sshd Sys_Check.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200#!/bin/bash# auth:baize# func:sys info check# date:2019/05/07[ $(id -u) -gt 0 ] &amp;&amp; echo "请用root用户执行此脚本！" &amp;&amp; exit 1sysversion=$(rpm -q centos-release|cut -d- -f3)line="-------------------------------------------------"[ -d logs ] || mkdir logssys_check_file="logs/$(ip a show dev ens33|grep -w inet|awk '&#123;print $2&#125;'|awk -F '/' '&#123;print $1&#125;')-`date +%Y%m%d`.txt"# 获取系统cpu信息function get_cpu_info() &#123; Physical_CPUs=$(grep "physical id" /proc/cpuinfo| sort | uniq | wc -l) Virt_CPUs=$(grep "processor" /proc/cpuinfo | wc -l) CPU_Kernels=$(grep "cores" /proc/cpuinfo|uniq| awk -F ': ' '&#123;print $2&#125;') CPU_Type=$(grep "model name" /proc/cpuinfo | awk -F ': ' '&#123;print $2&#125;' | sort | uniq) CPU_Arch=$(uname -m)cat &lt;&lt;EOFCPU信息:物理CPU个数:$Physical_CPUs逻辑CPU个数:$Virt_CPUs每CPU核心数:$CPU_KernelsCPU型号:$CPU_TypeCPU架构:$CPU_ArchEOF&#125;# 获取系统内存信息function get_mem_info() &#123; check_mem=$(free -m) MemTotal=$(grep MemTotal /proc/meminfo| awk '&#123;print $2&#125;') #KB MemFree=$(grep MemFree /proc/meminfo| awk '&#123;print $2&#125;') #KB let MemUsed=MemTotal-MemFree MemPercent=$(awk "BEGIN &#123;if($MemTotal==0)&#123;printf 100&#125;else&#123;printf \"%.2f\",$MemUsed*100/$MemTotal&#125;&#125;") report_MemTotal="$((MemTotal/1024))""MB" #内存总容量(MB) report_MemFree="$((MemFree/1024))""MB" #内存剩余(MB) report_MemUsedPercent="$(awk "BEGIN &#123;if($MemTotal==0)&#123;printf 100&#125;else&#123;printf \"%.2f\",$MemUsed*100/$MemTotal&#125;&#125;")""%" #内存使用率%cat &lt;&lt;EOF内存信息：$&#123;check_mem&#125;EOF&#125;# 获取系统网络信息function get_net_info() &#123; pri_ipadd=$(ip a show dev ens33|grep -w inet|awk '&#123;print $2&#125;'|awk -F '/' '&#123;print $1&#125;') pub_ipadd=$(curl ifconfig.me -s) gateway=$(ip route | grep default | awk '&#123;print $3&#125;') mac_info=$(ip link| egrep -v "lo"|grep link|awk '&#123;print $2&#125;') dns_config=$(egrep -v "^$|^#" /etc/resolv.conf) route_info=$(route -n)cat &lt;&lt;EOFIP信息:系统公网地址:$&#123;pub_ipadd&#125;系统私网地址:$&#123;pri_ipadd&#125;网关地址:$&#123;gateway&#125;MAC地址:$&#123;mac_info&#125;路由信息:$&#123;route_info&#125;DNS 信息:$&#123;dns_config&#125;EOF&#125;# 获取系统磁盘信息function get_disk_info() &#123; disk_info=$(fdisk -l|grep "Disk /dev"|cut -d, -f1) disk_use=$(df -hTP|awk '$2!="tmpfs"&#123;print&#125;') disk_inode=$(df -hiP|awk '$1!="tmpfs"&#123;print&#125;')cat &lt;&lt;EOF磁盘信息:$&#123;disk_info&#125;磁盘使用:$&#123;disk_use&#125;inode信息:$&#123;disk_inode&#125;EOF&#125;# 获取系统信息function get_systatus_info() &#123; sys_os=$(uname -o) sys_release=$(cat /etc/redhat-release) sys_kernel=$(uname -r) sys_hostname=$(hostname) sys_selinux=$(getenforce) sys_lang=$(echo $LANG) sys_lastreboot=$(who -b | awk '&#123;print $3,$4&#125;') sys_runtime=$(uptime |awk '&#123;print $3,$4&#125;'|cut -d, -f1) sys_time=$(date) sys_load=$(uptime |cut -d: -f5)cat &lt;&lt;EOF系统信息:系统: $&#123;sys_os&#125;发行版本: $&#123;sys_release&#125;系统内核: $&#123;sys_kernel&#125;主机名: $&#123;sys_hostname&#125;selinux状态: $&#123;sys_selinux&#125;系统语言: $&#123;sys_lang&#125;系统当前时间: $&#123;sys_time&#125;系统最后重启时间: $&#123;sys_lastreboot&#125;系统运行时间: $&#123;sys_runtime&#125;系统负载: $&#123;sys_load&#125;EOF&#125;# 获取服务信息function get_service_info() &#123; port_listen=$(netstat -lntup|grep -v "Active Internet") kernel_config=$(sysctl -p 2&gt;/dev/null) if [ $&#123;sysversion&#125; -gt 6 ];then service_config=$(systemctl list-unit-files --type=service --state=enabled|grep "enabled") run_service=$(systemctl list-units --type=service --state=running |grep ".service") else service_config=$(/sbin/chkconfig | grep -E ":on|:启用" |column -t) run_service=$(/sbin/service --status-all|grep -E "running") ficat &lt;&lt;EOF服务启动配置:$&#123;service_config&#125;$&#123;line&#125;运行的服务:$&#123;run_service&#125;$&#123;line&#125;监听端口:$&#123;port_listen&#125;$&#123;line&#125;内核参考配置:$&#123;kernel_config&#125;EOF&#125;function get_sys_user() &#123; login_user=$(awk -F: '&#123;if ($NF=="/bin/bash") print $0&#125;' /etc/passwd) ssh_config=$(egrep -v "^#|^$" /etc/ssh/sshd_config) sudo_config=$(egrep -v "^#|^$" /etc/sudoers |grep -v "^Defaults") host_config=$(egrep -v "^#|^$" /etc/hosts) crond_config=$(for cronuser in /var/spool/cron/* ;do ls $&#123;cronuser&#125; 2&gt;/dev/null|cut -d/ -f5;egrep -v "^$|^#" $&#123;cronuser&#125; 2&gt;/dev/null;echo "";done)cat &lt;&lt;EOF系统登录用户:$&#123;login_user&#125;$&#123;line&#125;ssh 配置信息:$&#123;ssh_config&#125;$&#123;line&#125;sudo 配置用户:$&#123;sudo_config&#125;$&#123;line&#125;定时任务配置:$&#123;crond_config&#125;$&#123;line&#125;hosts 信息:$&#123;host_config&#125;EOF&#125;function process_top_info() &#123; top_title=$(top -b n1|head -7|tail -1) cpu_top10=$(top b -n1 | head -17 | tail -11) mem_top10=$(top -b n1|head -17|tail -10|sort -k10 -r)cat &lt;&lt;EOFCPU占用top10:$&#123;top_title&#125;$&#123;cpu_top10&#125;内存占用top10:$&#123;top_title&#125;$&#123;mem_top10&#125;EOF&#125;function sys_check() &#123; get_cpu_info echo $&#123;line&#125; get_mem_info echo $&#123;line&#125; get_net_info echo $&#123;line&#125; get_disk_info echo $&#123;line&#125; get_systatus_info echo $&#123;line&#125; get_service_info echo $&#123;line&#125; get_sys_user echo $&#123;line&#125; process_top_info&#125;sys_check &gt; $&#123;sys_check_file&#125; 2.Docker.sh 脚本安装(Ubuntu) 123456789101112131415161718192021222324252627#!/bin/bash############################## 1.安装Dokcer ## 2.安装DockerCompose ##############################echo "docker安装"apt-get remove docker docker-engine docker.io containerd runcapt-get updateapt-get -y install apt-transport-https ca-certificates curl software-properties-commoncurl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"apt-get update &amp;&amp; apt-get install -y docker-cedocker versiontee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; "registry-mirrors": [ "https://registry.docker-cn.com" ]&#125;EOFservice docker restartdocker infoecho -e "\n"echo "docker compose安装"curl -L https://github.com/docker/compose/releases/download/1.24.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-composedocker-compose version 3.Gitlab.sh 脚本安装(Ubuntu) 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/bin/bash############################## 1.编写docker-compose文件 ## 2.运行docker-compose up ###############################===注意：==================##=========需要修改ip地址====#dir=/usr/local/docker/gitlabfunction run_mkcurrent_dir()&#123;my_dir="$dir"if [ ! -d "$my_dir" ]; then echo "创建文件夹" mkdir $my_direlse echo "文件夹已存在"fi&#125;run_mkcurrent_dir;tee /usr/local/docker/gitlab/docker-compose.yml &lt;&lt;-'EOF'version: '3'services: web: image: 'twang2218/gitlab-ce-zh' restart: always hostname: '192.168.75.145' environment: TZ: 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG: | external_url 'http://192.168.75.145' gitlab_rails['gitlab_shell_ssh_port'] = 2222 unicorn['port'] = 8888 nginx['listen_port'] = 80 ports: - '80:80' - '443:443' - '2222:22' volumes: - ./config:/etc/gitlab - ./data:/var/opt/gitlab - ./logs:/var/log/gitlabEOFcd /usr/local/docker/gitlab/docker-compose up 4.Nexus.sh 脚本安装(Ubuntu) 1234567891011121314151617181920212223242526272829303132#!/bin/bash############################## 1.编写docker-compose文件## 2.运行docker-compose up ##############################dir=/usr/local/docker/nexusfunction run_mkcurrent_dir()&#123;my_dir="$dir"if [ ! -d "$my_dir" ]; then echo "创建文件夹" mkdir $my_direlse echo "文件夹已存在"fi&#125;run_mkcurrent_dir;tee /usr/local/docker/nexus/docker-compose.yml &lt;&lt;-'EOF'version: '3.1'services: nexus: restart: always image: sonatype/nexus3 container_name: nexus ports: - 8081:8081 volumes: - ./data:/nexus-dataEOFcd /usr/local/docker/nexus/docker-compose upchmod 777 /usr/local/docker/nexus/data]]></content>
      <categories>
        <category>我的学习环境</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Inner Join与LEFT JOIN]]></title>
    <url>%2F2020%2F08%2F03%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200803%2F</url>
    <content type="text"><![CDATA[inner join与left join的区别 INNER JOIN 产生的结果是AB的交集 SELECT * FROM TableA INNER JOIN TableB ON TableA.id = TableB.rec_id LEFT (OUTER) JOIN 产生表A的完全集，而表B中匹配的则有值，没有匹配的则以null值取代. SELECT * FROM TableA LEFT OUTER JOIN TableB ON TableA.id = TableB.rec_id; 3.RIGHT（OUTER） JOIN 产生表B的完全集，而表A中匹配的则有值，没有匹配的则以null值取代 ​ SELECT * FROM TableA RIGHT OUTER JOIN TableB ON TAbleA.id = TableB.rec_id ​ FULL (OUTER) JOIN 产生A和B的并集，对于没有匹配的记录，以null值做为值 SELECT * FROM TableA FULL OUTER JOIN TableB ON TableA .name = TableB.name 可以通过is null将 没有匹配的值找出来； SELECT * FROM TableA FULL OUTER JOIN TableB ON TableA.name = TableB.name WHERE TableA.id is null OR TableB.id is null]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MybatisPlus默认更新策略]]></title>
    <url>%2F2020%2F07%2F22%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200722%2F</url>
    <content type="text"><![CDATA[问题实际项目中，难免更新的时候,有可能会把已有的值更新成空字符串或者null,但是当你使用updateById()方法的时候，会发现根本不生效。这其实是MyBatis-Plus对字段的验证策略导致的，MyBatis-Plus默认进行了不是全量更新的策略 解决方案 1234567field-strategy字段更新插入策略属性说明： IGNORED(0): "忽略判断", 所有字段都更新和插入 NOT_NULL(1): "非 NULL 判断", 只更新和插入非NULL值 NOT_EMPTY(2): "非空判断", 只更新和插入非NULL值且非空字符串 DEFAULT：默认NOT_NULL]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认识JUC]]></title>
    <url>%2F2020%2F07%2F08%2FJUC%2FJUC%2F</url>
    <content type="text"><![CDATA[JUC (java.until.concurrent) 1.1 进程/线程 1.2 并发/并行 三个包 java.util.concurrent java.util.concurrent.atomic java.util.concurrent.locks 锁 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102class Ticket //资源类 = 实例变量 + 实例方法&#123; private int number = 30; // List list = new ArrayList(); //Lock接口 ReentrantLock可重入锁 Lock lock = new ReentrantLock(); //同步方法 //public synchronized void sale() public void sale() &#123; // synchronized(this) 同步代码块 // 快捷键 trylock 回车 lock.lock(); try&#123; if(number &gt; 0) &#123; //快捷键 mycurr 回车 System.out.println(Thread.currentThread().getName() + "\t卖出第:"+(number--)+"\t 还剩下:" + number); &#125; &#125;catch(Exception e)&#123; e.printStackTrace(); &#125;finally&#123; lock.unlock(); &#125; &#125;&#125;/** * 1.三个售票员 卖出 30张票 * 如何编写企业级的多线程代码 * 固定的变成套路＋模板是什么？ * * 在高内聚低耦合的前提下，线程 操作 资源类 */public class SaleTicketDemo01&#123; public static void main(String[] args) //主线程，一切程序的入口 &#123; Ticket ticket = new Ticket(); //Thread t1 = new Thread(); //Thread t2 = new Thread(); //Thread t3 = new Thread(); //Thread(Runnable target, String name) Allocates a new Thread object new Thread(()-&gt;&#123;for(int i = 1; i&lt;=40;i++ ) ticket.sale();&#125;,"A").start(); new Thread(()-&gt;&#123;for(int i = 1; i&lt;=40;i++ ) ticket.sale();&#125;,"B").start(); new Thread(()-&gt;&#123;for(int i = 1; i&lt;=40;i++ ) ticket.sale();&#125;,"C").start(); //函数式接口 //@FunctionalInterface //public interface Runnable&#123; // public abstract void run(); //&#125; //匿名内部类方法 /* new Thread(new Runable() &#123; @Override public void run() &#123; for(int i = 1; i &lt;=40; i++) &#123; //Thread.state 多线程状态 //1.新建状态 NEW //2.运行状态 RUNABLE //3.阻塞状态 BLOCK //4.死等待 WAITING //5.时间限制等待 TIME_WAITING //6.TERMINATED ticket.sale(); &#125; &#125; &#125;,"A").start(); new Thread(new Runable() &#123; @Override public void run() &#123; for(int i = 1; i &lt;=40; i++) &#123; ticket.sale(); &#125; &#125; &#125;,"B").start(); new Thread(new Runable() &#123; @Override public void run() &#123; for(int i = 1; i &lt;=40; i++) &#123; ticket.sale(); &#125; &#125; &#125;,"C").start(); */ &#125;&#125; 3.ArrayList线程不安全 123456789101112131415161718192021222324252627282930313233343536373839/** * 1.故障现象 * java.util.ConcurrentModificationException * 2.导致原因 多线程争抢资源没有加索 * 3.解决方法 * 3.1 new Vector(); * 3.2 Collections.synchronizedList(new ArrayList&lt;&gt;); * 3.3 new CopyOnWriteArrayList(); * 4.优化建议(同样的错误不犯第2次) * * */public class NotSafe&#123; public static void main(String[] args) &#123; //Vector线程安全，重锁 synchronized修饰 List&lt;String&gt; list = new CopyOnWriteArrayList();//Collections.synchronizedList(new ArrayList&lt;&gt;);//new Vector(); //new ArrayList(); /* list.add("a"); list.add("a"); list.add("a"); //4大函数 //Predicate&lt;T&gt; 断言型 有参数，有返回值 返回值为boolean类型 boolean test(T t) //Functaion&lt;T,R&gt; 函数型接口，有参数，有返回值 R apply(T t) //Supplier&lt;T&gt; 供给型函数接口，没有参数，有返回值 T get(); //Consumer&lt;T&gt; 消费型接口 有参数，无返回值 void accept(T t) list.forEach(System.out::println); */ for(int i=0;i&lt;=3;i++) &#123; new Thread(()-&gt;&#123; list.add(UUID.randomUUID().toString().substring(0,8)); System.out.println(list); &#125;,String.valueOf(i)).start(); &#125; &#125;&#125; 123456789101112131415161718192021/** * CopyOnWriteArrayList add方法底层 * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */ public boolean add(E e) &#123; final ReentrantLock lock = this.lock; //可重用锁 lock.lock(); //加锁 try &#123; Object[] elements = getArray(); //获取原数组 int len = elements.length; //获取原数组长度 Object[] newElements = Arrays.copyOf(elements, len + 1); //复制新的数组，长度加1 newElements[len] = e; //新的数据加入新的数组中 setArray(newElements); //将数据加入新的数组中 return true; // 返回正确 &#125; finally &#123; lock.unlock(); &#125; &#125; 12345678910111213141516171819202122/** * HashSet线程不安全，底层使用HashMap */ public class NotSafeDemo &#123; public static void main(String[] args) &#123; setNotSafe(); &#125; public static void setNoteSafe() &#123; set&lt;String&gt; set = new CopyOnWriteArraySet&lt;&gt;(); for(int i = 1; i&lt;=30;i++) &#123; new Thread(()-&gt;&#123; set.add(UUID.randomUUID().toString().substring(0,8)); System.out.println(set); &#125;,String.valueOf(i)).start(); &#125; &#125; &#125; 123456789101112131415161718/** * Map线程不安全 */public class NotSafeDemo1&#123; public static void main(String[] args) &#123; //HashMap线程不安全 Map&lt;String,String&gt; map = new ConcurrentHashMap&lt;&gt;(); for(int i=0;i&lt;=30;i++) &#123; new Thread(()-&gt;&#123; map.put(Thread.currentThread().getName(),UUID.randomUUID().toString().substring(0,8)); System.out.println(map); &#125;,String.valueOf(i)).start(); &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485class Phone&#123; //8.5 public static synchronized void sentEmail() thrwos Exception &#123; //8.2 //Thread.sleep(4000); TimeUnit.SECONDS.sleep(4); System.out.println("*********sendEmail"); &#125; //8.5 //public static synchronized void sendSMS() throws Exception //8.6 public synchronized void sendSMS() throws Exception &#123; System.out.println("*********sendSMS"); &#125; public void sayHello() throws Exception &#123; System.out.println("*********sayHello"); &#125;&#125;/** * 8 lock * 8.1 标准访问 请问先打印邮件还是短信 邮件 * 8.2 暂停4秒钟再邮件方法，请问先打印邮件还是短信 邮件 * 8.3 新增普通sayHello方法，请问先打印邮件还是sayHello sayHello * 8.4 2部手机 请问先打印邮件还是短信 短信 * 8.5 2个静态同步方法，同一部手机 请问先打印邮件还是短信 邮件 * 8.6 2个静态同步方法，2部手机 请问先打印邮件还是短信 邮件 * 8.7 1个静态同步方法，1个普通同步方法，同一部手机 短信 * 8.8 1个静态同步方法，1个普通同步方法，2部手机 短信 * * * 一个对象里面如果有多个synchronized方法，某一个时刻内，只要一个线程去调用其中的一个synchronized方法了， *其它的线程都只能等待，换句话说，某一个时刻内，只能有唯一一个线程去访问这些synchronized方法 * *锁的是当前对象this，被锁定后，其它的线程都不能进入到当前对象的其它的synchronized方法 * *加个普通方法后发现和同步锁无关 * *换成两个对象后，不是同一把锁了，情况立刻变化。 * *synchronized实现同步的基础：Java中的每一个对象都可以作为锁。 *具体表现为以下3种形式。 *对于普通同步方法，锁是当前实例对象,锁的是当前对象this， *对于同步方法块，锁是Synchonized括号里配置的对象。 * *对于静态同步方法，锁是当前类的Class对象。 */public class Lock8&#123; public static void main(String[] args) throws InterruptedException &#123; Phone phone = new Phone(); Phone phone2 = new Phone(); new Thread(()-&gt;&#123; try&#123; phone.sendEmail(); &#125;catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;,"A").start(); Thread.sleep(100); new Thread(()-&gt;&#123; try&#123; //8.3 //phone.sendSMS(); //phone.sayHello(); //8.4 //phone2.sendSMS(); //8.5 //phone.sendSMS(); //8.6 phone2.sendSMS(); &#125;catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;,"B").start(); &#125;&#125;]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>JUC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo以及两个实体List的合并]]></title>
    <url>%2F2020%2F06%2F17%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200617%2F</url>
    <content type="text"><![CDATA[Dubbo以及两个实体List的合并 工作中有导出功能，导出需要和页面展示的内容一致，但是，导出的数据Float型自动转成了Double型，日期多.0，很是奇怪，同事自己写的sql没有这些问题，因为公司框架中封装了mybatis-plus，我的页面有很多字段，为了方便开发，使用了mybatis-plus，出现这些问题，于是Debug代码，发现在service层，没有查询出的数据格式，与页面相同，但是到了controller层就变得Double，.0等问题了，回想了一下执行流程发现，自己写的sql，会通过实体类，实体类中有实现序列化，所以没有问题，而自己使用mybatis-plus的方法，直接封装了结果，中间没有序列化，导致数据传输错误，以上是我认为的，后续还要验证，究竟是什么原因导致的自动变成了Double 因为还有一个需求，通过两次查询结果，合并成一个结果返回前端，数据需要将相同的合并，不同的保留，起初的写法只是双重for循环＋if判断，可以把相同的数据合并，并保留外层数据的不同值，但是，内层循环的不同数据就丢失了。后面想到相同添加，同时删除内层数据，最后再加上内层剩余数据就可以完成了，实现过程中出现了异常，最后换了一个方式。将一个list的匹配字段放入hashmap中当key，剩下实体当value，另一个list遍历，添加，最后实现了 失败的方法 123456789101112131415//第一个实体类集合List&lt;Entity&gt; entity = mapper.select();//第二个实体类集合List&lt;Entity&gt; entity1 = mapper.select();for(Entity en : entity)&#123; for(Entity en2 : entity1)&#123; if(en.getxxx().equals(en2.getxx))&#123; en.setxx(en2.setxxx); &#125; &#125;&#125;例如： 第一个实体结果：1，2，3，4，5，6，7 第二个实体结果：1，2，4，5，6，7，8 上面的写法只会拿到：1，2，3，4，5，6，7， 丢失第8个数字 成功的方法 1234567891011121314151617181920212223242526272829303132//第一个实体类集合List&lt;Entity&gt; entity = mapper.select();//第二个实体类集合List&lt;Entity&gt; entity1 = mapper.select();//创建一个HashMap，key放判断是否相同的字段，Value放整个数据Map&lt;String, Entity&gt; target = new HashMap&lt;String, Entity&gt;();//判断是否为空if (CollectionUtils.isNotEmpty(entity) &amp;&amp; CollectionUtils.isNotEmpty(entity1)) &#123;//遍历第一个实体类集合，放入map中for (Entity ent : entity) &#123; target.put(ent.getXXX(), ent);&#125;//遍历第二个集合for (Entity en : entity1) &#123; //获取第一个实体类中的key值 String a = en.getA(); //如果第一个实体类集合中包含第二个实体类集合中的值if (target.containsKey(a)) &#123; //获取第一个实体类的所有值 Entity temp = target.get(a); //设置自己想要添加的数据 temp.setXxxx(en.getXXX()); //重新将数据放回 target.put(a, temp);&#125; else &#123; //不同时候将第二个实体类中，与第一个实体类不想同的数据放入Map中 target.put(a, en); &#125; &#125;&#125;这个方法会拿到：1，2，3，4，5，6，7，8]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认识JVM]]></title>
    <url>%2F2020%2F06%2F13%2FJDK%E6%96%B0%E7%89%B9%E6%80%A7%2F%E8%AE%A4%E8%AF%86JVM%2F</url>
    <content type="text"><![CDATA[认识 JVM [TOC] 一、什么是JVM​ 虚拟机，是Java的运行环境，是一种能够运行.class字节码文件的机器 JVM 基本结构 1.类加载器 ： 用来加载磁盘.class的JVM内存 2.运行时数据区(内存结构)： 内存结构，不同的数据存储到不同的区域 3.执行引擎：运行代码，输出执行结果 4.本地方法接口 5.本地方法库 类加载过程 1.加载：将磁盘中的.class文件读取到内存中 2.连接： 1.验证：验证.class文件是否正确性 2.准备：给类的静态变量分配内存，并且给默认值(数据类型默认值) 3.解析：将关联的类也装载到内存(A类，A类用B类，所以这步将B类也载入) 3.初始化 给静态变量赋予真正的值。(涉及到类的初始化：父类的静态变量，父类的静态代码块，子类静态变量，子类静态代码块，父类变量，父类代码块，父类构造函数，子类变量，子类代码块，子类构造函数) 4.使用 5.卸载 类加载器 启动类加载器（C语言实现） 用来加载jre核心类库（rt.jar，charsets.jar…） 扩展类加载器（Java） jre的扩展类库（ext目录） 系统类加载器（Java） 自定义的类 类加载机制：类加载的原理 全盘负责委托机制 A类，B类，A类中引用B类 A类是自定义的类，所以Jvm会使用系统类加载器，去加载A类，那么会使用哪个加载器去加载B类呢？？？判断有没有去手动指定类加载器去加载B类，如果没有手动指定类加载器，将使用A类的加载器去加载B类，如果手动指定了加载器，将使用指定的加载器去加载B类，会使用当前类加载器去加载关联类 双亲委派机制 启动类加载器 3.查看A类是否被加载，否：判断是否该自己加载 4.不该自己加载，向下询问 扩展类加载器 2.查看A类是否被加载，否：向上询问 5.判断是否该自己加载，否：向下询问 系统类加载器 1.查看A类是否被加载，否：向上询问 6.自己加载 JVM内存 Java虚拟机（1.7） 程序计数器： 线程私有的（每个线程都有自己的程序计数器）。是一个个指针，代码运行，执行命令，而每个命令都有行号。使用程序技术来记录命令执行到多少行了 Java虚拟机栈： 线程私有的（每个线程都有一个自己的Java虚拟机栈）。一个方法运行，就会给这个方法创建一个栈帧，栈帧入栈执行代码，执行完毕之后出栈(弹栈) 本地方法栈： 线程私有的（每个线程都有一个自己的本地方法栈）。和Java虚拟机栈类似，Java虚拟机栈加载的是普通方法。本地方法栈加载的是native修饰的方法 堆 线程共享的（所有线程共享一份），存放对象的，new的对象都存储这个区域 方法区 线程共享的（所有线程共享一份），存放.class的信息，类的信息，方法的定义，常量池，静态变量等。 Java虚拟机（1.8） 没有方法区，放到本地内存 元数据区（元空间） 存储.class信息，类的信息，方法的定义，静态变量等。而常量池放到堆里存储 二、什么是垃圾 什么是GC？ 内存空间有限，程序运行时如何把不需要使用的对象(垃圾对象）清除而释放资源，这就是GC的功能 GC的操作区域 Java 虚拟机栈，本地方法栈，程序计数器是不需要GC，因为1这个都是线程私有的，线程私有的就会随着线程的产生而产生，随着线程的结束而销毁 堆和方法区需要GC，需要GC来及时清理运行过程中产生的垃圾 GC的操作对象是什么 垃圾对象 三、如何发现垃圾 引用计数 给每个对象定义一个变量，存储引用数，就是通过引用计数是否为0来判断是否清理 可达性分析 会记录对象的引用链。如果一个对象没有引用链，就证明这个对象没有被使用，那么就会销毁 GC 的运行时机 1.手动调用 System.gc()可以触发GC操作 2.系统本身自己出发：内存不足时就会触发 GC做了什么？ 清理对象，整理内存 四、GC 算法 标记清除： 给每个对象存储一个标记位，记录对象的状态（死/活），两个阶段，第一是标记阶段：检查对象的状态，判断对象是否死亡。第二是清理阶段：将死亡对象清理掉 标记压缩 是标记清除算法的改进版。两个阶段，第一是标记阶段：检查对象的状态，判断对象是否死亡。第二是将所有存活的对象整理放到另外一处内空间，把剩余的对象全部清除掉 复制算法 会将内存平均分两块，每次只使用其中的一块，当这块内存存满了，将这个内存中，存活的对象复制到另外一块内存中，将刚才那块儿内存清空 分代收集算法 堆如果细分还可以分为新生代，老年代。在新生代中对象存活的时间短，所以采用的算法是复制算法，老年代中的对象存活率高，所以使用标记压缩或标记清除算法 五、Available collectors​]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>认识JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java数据校验]]></title>
    <url>%2F2020%2F06%2F06%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200606%2F</url>
    <content type="text"><![CDATA[Java数据校验 1.因为工作中有部分时间在写前端，没有怎么写后台，突然给到任务让写数据校验，就参考了一下以前的校验方式，感觉有些性能不好，而且作用不好，重新写一下校验 2.原来的校验方式：是通过查询所有数据，遍历数据，与输入数据进行比较，第一：性能不好，要查询所有数据，然后遍历。 第二：如果是自己本身数据没有改变，需要判断，代码感觉混乱，不容易维护 3.我的想法： 1.添加： 根据传入数据，使用mybatis-plus的selectCount方式查询数据有几条？ 123456789QueryWrapper&lt;XXX&gt; wrapper = new QueryWrapper&lt;XXX&gt;(); //mybatis-plus条件构造器wrapper.eq("IS_ENABLE", 1); //因为有伪删除，所以有这个字段if (StringUtils.isEmpty(XXX.getxxx()) == false) &#123; wrapper.eq("数据库字段", XXX.getxxx());&#125; //需要校验的数据Integer count = mapper.selectCount(wrapper);//查询条数if(count&gt;0)&#123; //数据库存在数据，重复，不可添加&#125; 2.编辑： 和添加相同的道理，但是多了一个自己本身校验 1234567891011121314151617181920 //首先使用 mybatis-plus的selectById方法，返回查询结果的实体类 XXX val = mapper.selectById(XXX.getId()); QueryWrapper&lt;XXX&gt; wrapper = new QueryWrapper&lt;XXX&gt;(); //mybatis-plus条件构造器 wrapper.eq("IS_ENABLE", 1); //因为有伪删除，所以有这个字段 if (StringUtils.isEmpty(XXX.getxxx()) == false) &#123; wrapper.eq("数据库字段", XXX.getxxx()); &#125; //需要校验的数据 Integer count = mapper.selectCount(wrapper);//查询条数 if(count&gt;1)&#123; //数据库存在数据，重复，不可添加 &#125; else if(count == 1)&#123; //此时说明数据库中有一个数据与现在相同，但是，不知道是是不是自己 if(val.getxxx().equals(xxx.getxxx()...))&#123; //不用操作，直接跳出，更新数据，此处通过id查询与传入数据相同，代表自己本身&#125; else &#123; //不可操作，数据已存在 retrun false; &#125; &#125; mapper.updateById(xxx);//更新数据 3.上传 思路和添加相同，总体就是判断count，大于0失败，数据存在]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVN版本冲突]]></title>
    <url>%2F2020%2F05%2F15%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200515%2F</url>
    <content type="text"><![CDATA[SVN版本冲突 这个冲突文件是同事写的代码，并不是我的，但是，我在更新代码的时候发生了代码冲突 解决步骤 1.选中冲突文件鼠标右键Edit conficts 2.虽然我没有修改但是，我还是选择了第三个，合并到本地目录，保存我的和服务器的，再次更新代码就可以了 出现界面，分为”Theirs”、”Mine”和”Merged”3部分，表示”别人修改的内容”、 ”我修改的内容”和”合并后的结果”3部分。我们是要将”别人修改的内容”和”我修改的内容”有取舍地合并起来，形成”合并后的结果”。 合并一般分为4种情况： 1.保留”我的修改”,舍弃”别人的修改”。鼠标右键点击Mine框的相应行，点击”Use this text block”。 2.舍弃”我的修改”,保留”别人的修改”。鼠标右键点击Theirs框的相应行，点击”Use this text block”。 3.同时保留”我的修改”和”别人的修改”，并将”我的修改” 放在前面。鼠标右键点击Mine框的相应行，点击”Use text block from mine before theirs”。 4.同时保留”我的修改”和”别人的修改”，并将”别人的修改”放在前面。鼠标右键点击Mine框的相应行，点击”Use text block from theirs before mine”。]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JqGrid行编辑]]></title>
    <url>%2F2020%2F05%2F14%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200514%2F</url>
    <content type="text"><![CDATA[JqGrid行编辑 ​ 1.jqGrid学习网站 jqGrid实例中文版 jqGrid官网 ​ 2.editRow 编辑行 //最后一行追加行 123456$("#productList").addRowData(rowid, josnData, "last");//调用方式jQuery("#grid_id").editRow(rowid, keys, oneditfunc, successfunc, url, extraparam, aftersavefunc,errorfunc, afterrestorefunc);//新版本调用方式jQuery("#grid_id").jqGrid('editRow',rowid, keys, oneditfunc, successfunc, url, extraparam, aftersavefunc,errorfunc, afterrestorefunc); editRow参数配置说明 grid_id ：已经构造过的jqGrid rowid：此数据行的id keys：设置为true可以使用 [Enter]保存数据或者[Esc] 取消编辑 oneditfunc：在行成功转为编辑模式下触发的事件，参数为此行数据id successfunc, url, extraparam, aftersavefunc,errorfunc 和 afterrestorefunc在下面的saveRow方法中介绍 拥有’not-editable-row’ 样式的行不可编辑，即使colModel中配置了某些列能编辑。 123456789101112131415//默认参数editparameters = &#123; "keys" : false, "oneditfunc" : null, "successfunc" : null, "url" : null, "extraparam" : &#123;&#125;, "aftersavefunc" : null, "errorfunc": null, "afterrestorefunc" : null, "restoreAfterError" : true, "mtype" : "POST"&#125; jQuery("#grid_id").jqGrid('editRow',rowid, parameters); //事件编辑行 123456onSelectRow: function (id) &#123; $("#productList").saveRow(id, false); $("#productList").jqGrid('restoreRow', id); $("#productList").jqGrid('editRow', id, true); lastrow = id;&#125; saveRow保存行 1$("#jqGrid").jqGrid('saveRow',rowKey); restoreRow还原数据行 1jQuery("#grid_id").restoreRow(rowid, afterrestorefunc); inlineNav： 给行编辑添加导航操作按钮 12jQuery("#grid_id").navGrid(pagerid, &#123;...&#125;);jQuery("#grid_id").inlineNav(pagerid, parameters); 12345 - delGridRow删除行​```javascript$(&quot;#jqGrid&quot;).delGridRow(rowKey);]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图书推荐]]></title>
    <url>%2F2020%2F04%2F29%2F%E5%9B%BE%E4%B9%A6%E6%8E%A8%E8%8D%90%2F%E5%9B%BE%E4%B9%A6%E6%8E%A8%E8%8D%90%2F</url>
    <content type="text"><![CDATA[高清下载 图书下载]]></content>
      <categories>
        <category>图书推荐</category>
      </categories>
      <tags>
        <tag>图书推荐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK新特性]]></title>
    <url>%2F2020%2F04%2F26%2FJDK%E6%96%B0%E7%89%B9%E6%80%A7%2FJDK%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[JDK8 新特性 概述以下列出两点重要特性： Lambda 表达式（匿名函数） Stream 多线程并行数据处理（重要） 新特性 接口的默认方法只需要使用 default 关键字即可，这个特征又叫做 扩展方法 Lambda 表达式 Functional 接口 函数式接口 是指仅仅只包含一个抽象方法的接口，每一个该类型的 Lambda 表达式都会被匹配到这个抽象方法。你只需要给你的接口添加 @FunctionalInterface 注解 使用 :: 双冒号关键字来传递方法(静态方法和非静态方法) Predicate 接口和 Lambda 表达式 Function 接口 Function 有一个参数并且返回一个结果，并附带了一些可以和其他函数组合的默认方法 compose 方法表示在某个方法之前执行 andThen 方法表示在某个方法之后执行 注意：compose 和 andThen 方法调用之后都会把对象自己本身返回，这可以 方便链式编程 Supplier 接口，返回一个任意范型的值，和 Function 接口不同的是该接口 没有任何参数 Consumer 接口，接收一个任意范型的值，和 Function 接口不同的是该接口 没有任何值 Optional 类 Optional 不是接口而是一个类，这是个用来防止 NullPointerException 异常的辅助类型 Optional 被定义为一个简单的容器，其值可能是 null 或者不是 null。 在 Java8 之前一般某个函数应该返回非空对象但是偶尔却可能返回了 null，而在 Java8 中，不推荐你返回 null 而是返回 Optional。 这是一个可以为 null 的容器对象。 如果值存在则 isPresent() 方法会返回 true，调用 get() 方法会返回该对象。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package com.funtl.jdk8.feature.lambda;import java.util.Arrays;import java.util.List;import java.util.stream.Collectors;/** * Lambda 基本用法 * &lt;p&gt;Title: BaseLambda&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * * @author Lusifer * @version 1.0.0 * @date 2019/1/6 10:42 */public class BaseLambda &#123; public static void main(String[] args) &#123; testForeach(); testStreamDuplicates(); &#125; /** * Lambda 遍历 */ public static void testForeach() &#123; // 定义一个数组 String[] array = &#123; "尼尔机械纪元", "关于我转生成为史莱姆这件事", "实力至上主义教师", "地狱少女" &#125;; // 转换成集合 List&lt;String&gt; acgs = Arrays.asList(array); // 传统的遍历方式 System.out.println("传统的遍历方式："); for (String acg : acgs) &#123; System.out.println(acg); &#125; System.out.println(); // 使用 Lambda 表达式以及函数操作(functional operation) System.out.println("Lambda 表达式以及函数操作："); acgs.forEach((acg) -&gt; System.out.println(acg)); System.out.println(); // 在 Java 8 中使用双冒号操作符(double colon operator) System.out.println("使用双冒号操作符："); acgs.forEach(System.out::println); System.out.println(); &#125; /** * Stream 去重复 * String 和 Integer 可以使用该方法去重 */ public static void testStreamDuplicates() &#123; System.out.println("Stream 去重复："); // 定义一个数组 String[] array = &#123; "test", "test", "test1", "test1", "test2", "test2", "test3", "test3" &#125;; // 转换成集合 List&lt;String&gt; acgs = Arrays.asList(array); // Stream 去重复 acgs = acgs.stream().distinct().collect(Collectors.toList()); // 打印 acgs.forEach(System.out::println); &#125;&#125;]]></content>
      <categories>
        <category>Java新特性</category>
      </categories>
      <tags>
        <tag>JDK新特性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[请求头]]></title>
    <url>%2F2020%2F04%2F22%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200422%2F</url>
    <content type="text"><![CDATA[请求头 前端请求415错误 @RequestParam主要来是于URL，例如百度的地址 https://www.baidu.com/s?wd=前端415@RequestBody主要来自表单信息，通过POST的方式把表单的信息传到后台。@RequestHeader求请的表单头。一般用来放浏览器信息，cookies等信息。 @RequestParam对应的是URL的参数。@RequestBody对应的 是Form 的值@RequestHeader 对应是 Head的参数 1234567891011121314151617181920function f_c() &#123; var url = "http://localhost:8080/test/paramTest?OperateType=add"; var opt = &#123; attr1: "a", attr2: "b", &#125;; $.ajax(&#123; type: "POST", url: url, headers: &#123; token:'key' &#125;, data: JSON.stringify(opt), contentType: "application/json", success: function (data) &#123; alert(data) &#125;, error: function (data) &#123; alert("error"); &#125; &#125;); &#125; 原文链接：https://richy.blog.csdn.net/article/details/104571682]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo+Zookeeper中MyBatis-PLUS分页使用]]></title>
    <url>%2F2020%2F04%2F20%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200420%2F</url>
    <content type="text"><![CDATA[Dubbo+Zookeeper中MyBatis-PLUS分页使用 2020-04-20 所在项目组架构使用Dubbo+Zookeeper以及spingboot，mybatis，mybatis-plus，开发过程中，需要传递实体类并传递分页信息，以便根据实体类条件查询结果分页，查阅资料，都是在controller层，使用service接口调用mybatis-plus的page方法，但是，因为公司使用dubbo架构，会产生rpc调用，所以导致调用失败，MyBaits-Plus官网提示 ​ 选择在service层，服务提供者处，使用selectPage方法 ​ 2.实体类LocalDateTime 在项目中，序列化出现问题，导致异常（截取自网络）解决方法：更换数据类型 com.alibaba.dubbo.rpc.RpcException: Failed to invoke the method compositeQuery in the service com.wwwarehouse.xdw.resourcecenter.service.ImConsumeRealityService. Tried 3 times of the providers [192.168.72.158:20880] (1/1) from the registry 192.168.6.21:2181 on the consumer 192.168.72.158 using the dubbo version 2.8.4. Last error is: Failed to invoke remote method: compositeQuery, provider:]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA]]></title>
    <url>%2F2020%2F04%2F19%2F%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%2F1.IDEA%2F</url>
    <content type="text"><![CDATA[一、安装（略） 二、使用 关闭自动更新 安装插件 设置字体 设置版本控制]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis 调用 带返回值 的存储过程]]></title>
    <url>%2F2020%2F02%2F17%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200217%2F</url>
    <content type="text"><![CDATA[MyBatis 调用 带返回值 的存储过程 序 mybatis 调用oracle 存储过程，返回一个表。这样的景场用得比较少，我用了mybatis这么长时间，还第一次这么用。尝试过程也是比较痛苦，网上资料少不说，很多配置拿下来，也是跑不起来。。最后自己不停地跟据mybatis抛出来的错误调整代码，终于跑起来了。做一下笔记。 存储过程 存储过程比较长，只需要关注输入，输出参数就可以了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899CREATE OR REPLACE PROCEDURE P_QMS_GET_MIS_RPT(MIS_TYPE VARCHAR2, --1:3MIS 2:6MIS MIS_DATE VARCHAR2, --时间条件 OTHER_CONDITION VARCHAR2, --其它条件 DATE_TYPE NVARCHAR2, -- 1:年 2：月 3：周 GROUP_BY VARCHAR2, --维度 BRAND P_CUR OUT SYS_REFCURSOR ) AS V_SQL VARCHAR2(4000); V_CON VARCHAR2(500):=''; V_DATE DATE; V_STRAT_DATE date; V_END_DATE date; V_MIS_MONTH varchar2(50); V_START_DATE_STR VARCHAR2(100); V_END_DATE_STR VARCHAR2(100);BEGINV_DATE:=TO_DATE(MIS_DATE,'yyyy-MM-dd'); V_STRAT_DATE := Trunc(add_months(V_DATE, -3 * MIS_TYPE ), 'mm'); V_END_DATE := Last_Day(add_months(V_DATE, -1)); V_MIS_MONTH := to_char(Trunc(add_months(V_DATE, -1), 'mm'), 'yyyymm'); V_START_DATE_STR:= ' to_date('''|| to_char( V_STRAT_DATE,'yyyy-MM-dd') ||''',''yyyy-MM-dd'') '; V_END_DATE_STR := ' to_date('''|| to_char( V_END_DATE,'yyyy-MM-dd') ||''',''yyyy-MM-dd'') '; V_CON:=V_CON || ' and ACTIVE_START&gt;= ' || V_START_DATE_STR ; V_CON:=V_CON || ' and ACTIVE_START &lt; '|| V_END_DATE_STR || '+1'; V_CON:=V_CON|| ' '; V_SQL := ' with B as --市场不良数 (SELECT '|| GROUP_BY ||', sum(QTY) AS sc_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''10'' '|| V_CON ||' group by '|| GROUP_BY ||'), --销售数量 C as (SELECT '|| GROUP_BY ||', sum(QTY) AS s_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''40'' '|| V_CON ||' group by '|| GROUP_BY ||' ), --生产数量 D as (SELECT '|| GROUP_BY ||', sum(QTY) AS pro_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''30'' '|| V_CON ||' group by '|| GROUP_BY ||' ), --销售比率 E as (select d.'|| GROUP_BY ||', round(least(sum(c.s_qty) / sum(d.pro_qty), 1), 8) as rate, sum(c.s_qty) sale_qty, sum(d.pro_qty) pro_qty from D, c where 1 = 1 and d.'|| GROUP_BY ||' = c.'|| GROUP_BY ||' group by d.'|| GROUP_BY ||'), --交货数量 F as (SELECT '|| GROUP_BY ||', sum(QTY) AS part_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''20'' '|| V_CON ||' group by '|| GROUP_BY ||' ), --交货数量*销售比率获取 =索赔零件总数 G as (select F.BRAND, sum(F.part_qty * E.rate) as instrorage_qty from F, E where F.'|| GROUP_BY ||' = E.'|| GROUP_BY ||' group by F.'|| GROUP_BY ||'), --计算实绩值 H AS (select G.'|| GROUP_BY ||', B.sc_qty, instrorage_qty, round(B.sc_qty / instrorage_qty * 1000000, 1) as rate, round(B.sc_qty / instrorage_qty * 1000000, 10) rate_dec from G left join B on G.'|| GROUP_BY ||' = B.'|| GROUP_BY ||'), V AS (SELECT TARGET_VAL, BRAND AS TARGET_TYPE_NAME FROM T_QMS_DB_TARGET_VAL T WHERE T.BUSI_TYPE = ''10'' AND T.TARGET_DATE= '''||V_MIS_MONTH||''') SELECT '|| GROUP_BY ||' as SUMARY_NAME, rate_dec, '''||V_MIS_MONTH||''' as MIS_DATE, nvl((select target_val from V where H.'|| GROUP_BY ||' = V.target_type_name and rownum=1), 0) as target_val FROM H'; OPEN P_CUR FOR V_SQL;END; Mapper.xml 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;&lt;mapper namespace="com.xx.xx.xx.reportstatic.idal.mapper.MisRptMapper"&gt; &lt;resultMap id= "misPrcInputResult" type ="com.ly.mp.qms.reportstatic.entities.MisPrcInputResult" &gt; &lt;result column ="sumary_name" property="sumaryName" jdbcType="VARCHAR" /&gt; &lt;result column ="rate" property="rate" jdbcType="VARCHAR" /&gt; &lt;result column ="mis_date" property="misDate" jdbcType="VARCHAR" /&gt; &lt;result column ="target_val" property="targetVal" jdbcType="VARCHAR" /&gt; &lt;/resultMap &gt; &lt;select id="getMisRpt" statementType="CALLABLE" &gt; &#123;call p_qms_get_mis_rpt ( #&#123;misType,mode=IN,jdbcType=VARCHAR&#125;, &lt;!--注意要使用置jdbcType --&gt; #&#123;misDate,mode=IN,jdbcType=VARCHAR&#125;, #&#123;otherCondition,mode=IN,jdbcType=VARCHAR&#125;, #&#123;dateType,mode=IN,jdbcType=VARCHAR&#125;, #&#123;groupBy,mode=IN,jdbcType=VARCHAR&#125;, #&#123;result,mode=OUT,jdbcType=CURSOR, javaType=ResultSet,resultMap=misPrcInputResult&#125; )&#125; &lt;/select&gt;&lt;/mapper&gt; 这里主要注意1：输入参数的格式为 #{misType,mode=IN,jdbcType=VARCHAR}，需要设参数名称（misType），参数类型 （mode=IN)，参数数据类型（jdbcType=VARCHAR）为字符,网上找的资料都是没有设置 jdbcType=VARCHAR，但我的环境跑不起来。2：输出参数设置， #{result,mode=OUT,jdbcType=CURSOR, javaType=ResultSet,resultMap=misPrcInputResult。名称（result），参数类型为输出（mode=OUT），参数数据类型（jdbcType=CURSOR）为索引。输出的参数还需要另外设置javaType和resultMap。javaType=ResultSet 表示对应的java类型是一个列表，对应List；resultMap=misPrcInputResult 表示集合字段对应的印身是 misPrcInputResult。 Entity 123456789101112131415161718192021222324252627282930313233343536373839public class MisPrcInputResult implements java.io.Serializable &#123; private String sumaryName; private String rate; private String misDate; private String targetVal; public String getSumaryName() &#123; return sumaryName; &#125; public void setSumaryName(String sumaryName) &#123; this.sumaryName = sumaryName; &#125; public String getRate() &#123; return rate; &#125; public void setRate(String rate) &#123; this.rate = rate; &#125; public String getMisDate() &#123; return misDate; &#125; public void setMisDate(String misDate) &#123; this.misDate = misDate; &#125; public String getTargetVal() &#123; return targetVal; &#125; public void setTargetVal(String targetVal) &#123; this.targetVal = targetVal; &#125; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.sql.Date;import java.util.List;public class MisPrcInput implements java.io.Serializable &#123; private String misType; private String misDate; private String otherCondition; private String dateType; private String groupBy; private List&lt;MisPrcInputResult&gt; result; public String getMisType() &#123; return misType; &#125; public void setMisType(String misType) &#123; this.misType = misType; &#125; public String getMisDate() &#123; return misDate; &#125; public void setMisDate(String misDate) &#123; this.misDate = misDate; &#125; public String getOtherCondition() &#123; return otherCondition; &#125; public void setOtherCondition(String otherCondition) &#123; this.otherCondition = otherCondition; &#125; public String getDateType() &#123; return dateType; &#125; public void setDateType(String dateType) &#123; this.dateType = dateType; &#125; public String getGroupBy() &#123; return groupBy; &#125; public void setGroupBy(String groupBy) &#123; this.groupBy = groupBy; &#125; public List&lt;MisPrcInputResult&gt; getResult() &#123; return result; &#125; public void setResult(List&lt;MisPrcInputResult&gt; result) &#123; this.result = result; &#125;&#125; Mapper.java 1234public interface MisRptMapper extends BaseMapper&lt;MisCaculate&gt; &#123; public void getMisRpt(MisPrcInput inp );&#125; Biz 1234567891011121314151617181920@Autowired MisRptMapper misRptMapper; @Override public RestResult&lt;List&lt;MisPrcInputResult&gt;&gt; getMisPrc() throws ParseException &#123; MisPrcInput inp= new MisPrcInput(); inp.setDateType("1"); inp.setGroupBy("brand"); inp.setMisType("1"); inp.setMisDate("2018-02-1"); inp.setOtherCondition( " 1=1 "); inp.setResult(new ArrayList&lt;MisPrcInputResult&gt;()); RestResult&lt;List&lt;MisPrcInputResult&gt;&gt; result =new RestResult(); result.setResult(1); misRptMapper.getMisRpt( inp); result.setMsg("获取成功"); result.setData(inp.getResult()); return result; &#125; 接口跟Service层就不贴代码了。。 最终运行结果]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[煮方便面谈 CountDownLatch]]></title>
    <url>%2F2020%2F02%2F16%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200216%2F</url>
    <content type="text"><![CDATA[煮方便面谈 CountDownLatch CountDownLatch用法解释 CountDownLatch要是控制多线程操作时，等待多线程执行完后，再执行下去。举个例子，冲泡面，需要以下3个步骤A：装水到电锅，打开电源，等3分钟B：拆方便盒，放调味料C：倒开水到方便面盒。其中A跟B是可以同时进行的，C则需要依赖A，B完成了再执行。 代码参数 实始化：CountDownLatch latch = new CountDownLatch(3) ，表示 count初始化为2个。wait方法:表示等待count=0时，执行。countDown方法：count减1。 实例 上面说的冲泡面的生活例子。 代码实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.concurrent.CountDownLatch;public class ClassTestApplication &#123; public static void main(String[] args) &#123; final CountDownLatch latch = new CountDownLatch(2); //初始化，count=3 System.out.println("Count="+latch.getCount()); new Thread(() -&gt; &#123; System.out.println("开始煮开水。。。"); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("开水煮好了。。。"); latch.countDown(); //count = count -1; System.out.println("Count="+latch.getCount()); &#125;).start(); new Thread(() -&gt; &#123; System.out.println("拆方便面盒。。。"); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("方便面盒拆好了。。。"); latch.countDown(); //count = count -1; System.out.println("Count="+latch.getCount()); &#125;).start(); try &#123; latch.await(); System.out.println("水煮好了，面拆好了，充水到面盒。。。"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行结果如下：Count=2开始煮开水。。。拆方便面盒。。。方便面盒拆好了。。。Count=1开水煮好了。。。Count=0水煮好了，面拆好了，充水到面盒。。。]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORACLE动态SQL存储过程]]></title>
    <url>%2F2020%2F02%2F14%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200214%2F</url>
    <content type="text"><![CDATA[ORACLE动态SQL存储过程 引言 在工作中，经常会遇到拼写动态sql，虽然写法不是很优美，但却无法避免。如果在后台（java 或者C#）写非常简单，拼写完直接运行就可以了。但如果是在数据库里面拼呢？因为公司经常用到，我把它总结一下，用一个简单的例子来说明。 场景 写一个存储过程，支持动态的条件，并根据条件输出结果。 实现 12345678910111213141516171819202122232425262728CREATE OR REPLACE PROCEDURE P_TEST(V_C1 VARCHAR2, --条件1 V_C2 VARCHAR2, --条件2 P_CUR OUT SYS_REFCURSOR --用于输出的索引（输出表） ) AS V_SQL VARCHAR2(4000) := ' '; --用于构造要执行的动态SQL V_CON VARCHAR2(500) := ' where 1=1 '; --用于构造条件BEGIN V_SQL := ' WITH T AS (SELECT ''1'' AS C1 ,''1'' AS C2 FROM DUAL UNIONSELECT ''2'' AS C1 ,''2'' AS C2 FROM DUAL UNIONSELECT ''3'' AS C1 ,''3'' AS C2 FROM DUAL UNIONSELECT ''4'' AS C1 ,''4'' AS C2 FROM DUAL )SELECT * FROM T ';--构造条件 V_CON := V_CON || ' AND C1=''' || V_C1 || ''' '; V_CON := V_CON || ' AND C2=''' || V_C2 || ''' ';--构造动态SQL V_SQL := V_SQL || V_CON; DBMS_OUTPUT.put_line(V_SQL); ----输出，方便测试动态生成的SQL OPEN P_CUR FOR V_SQL;//关键，执行并输出结果END; 以上实现已经完成，我们在PL SQL运行一下看看结果。 实例分享 下面分再享个复杂一些的，以及写的写的过程。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176CREATE OR REPLACE PROCEDURE P_QMS_GET_MIS_RPT(MIS_TYPE VARCHAR2, --1:3MIS 2:6MIS V_DATE DATE, --时间条件 OTHER_CONDITION VARCHAR2, --其它条件 DATE_TYPE NVARCHAR2, -- 1:年 2：月 3：周 GROUP_BY VARCHAR2, --维度 BRAND P_CUR OUT SYS_REFCURSOR ) AS V_SQL VARCHAR2(4000); V_CON VARCHAR2(500):=''; V_STRAT_DATE date; V_END_DATE date; V_MIS_MONTH varchar2(50); V_START_DATE_STR VARCHAR2(100); V_END_DATE_STR VARCHAR2(100);BEGIN V_STRAT_DATE := Trunc(add_months(V_DATE, -3 * MIS_TYPE ), 'mm'); V_END_DATE := Last_Day(add_months(V_DATE, -1)); V_MIS_MONTH := to_char(Trunc(add_months(V_DATE, -1), 'mm'), 'yyyymm'); V_START_DATE_STR:= ' to_date('''|| to_char( V_STRAT_DATE,'yyyy-MM-dd') ||''',''yyyy-MM-dd'') '; V_END_DATE_STR := ' to_date('''|| to_char( V_END_DATE,'yyyy-MM-dd') ||''',''yyyy-MM-dd'') '; V_CON:=V_CON || ' and ACTIVE_START&gt;= ' || V_START_DATE_STR ; V_CON:=V_CON || ' and ACTIVE_START &lt; '|| V_END_DATE_STR || '+1'; V_CON:=V_CON|| ' '; V_SQL := ' with B as --市场不良数 (SELECT '|| GROUP_BY ||', sum(QTY) AS sc_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''10'' '|| V_CON ||' group by '|| GROUP_BY ||'), --销售数量 C as (SELECT '|| GROUP_BY ||', sum(QTY) AS s_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''40'' '|| V_CON ||' group by '|| GROUP_BY ||' ), --生产数量 D as (SELECT '|| GROUP_BY ||', sum(QTY) AS pro_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''30'' '|| V_CON ||' group by '|| GROUP_BY ||' ), --销售比率 E as (select d.'|| GROUP_BY ||', round(least(sum(c.s_qty) / sum(d.pro_qty), 1), 8) as rate, sum(c.s_qty) sale_qty, sum(d.pro_qty) pro_qty from D, c where 1 = 1 and d.'|| GROUP_BY ||' = c.'|| GROUP_BY ||' group by d.'|| GROUP_BY ||'), --交货数量 F as (SELECT '|| GROUP_BY ||', sum(QTY) AS part_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''20'' '|| V_CON ||' group by '|| GROUP_BY ||' ), --交货数量*销售比率获取 =索赔零件总数 G as (select F.BRAND, sum(F.part_qty * E.rate) as instrorage_qty from F, E where F.'|| GROUP_BY ||' = E.'|| GROUP_BY ||' group by F.'|| GROUP_BY ||'), --计算实绩值 H AS (select G.'|| GROUP_BY ||', B.sc_qty, instrorage_qty, round(B.sc_qty / instrorage_qty * 1000000, 1) as rate, round(B.sc_qty / instrorage_qty * 1000000, 10) rate_dec from G left join B on G.'|| GROUP_BY ||' = B.'|| GROUP_BY ||'), V AS (SELECT TARGET_VAL, BRAND AS TARGET_TYPE_NAME FROM T_QMS_DB_TARGET_VAL T WHERE T.BUSI_TYPE = ''10'' AND T.TARGET_DATE= '''||V_MIS_MONTH||''') SELECT sysdate, '|| GROUP_BY ||' as SUMARY_NAME, rate_dec, '''||V_MIS_MONTH||''' as MIS_MONTH, nvl((select target_val from V where H.'|| GROUP_BY ||' = V.target_type_name and rownum=1), 0) as target_val FROM H'; /* with B as --市场不良数 (SELECT BRAND, sum(QTY) AS sc_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = '10' and ACTIVE_START&gt;= V_STRAT_DATE and ACTIVE_START &lt; V_END_DATE+1 group by BRAND), --销售数量 C as (SELECT BRAND, sum(QTY) AS s_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = '40' and ACTIVE_START&gt;= V_STRAT_DATE and ACTIVE_START &lt; V_END_DATE+1 group by BRAND), --生产数量 D as (SELECT BRAND, sum(QTY) AS pro_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = '30' and ACTIVE_START&gt;= V_STRAT_DATE and ACTIVE_START &lt; V_END_DATE+1 group by BRAND), --销售比率 E as (select d.BRAND, round(least(sum(c.s_qty) / sum(d.pro_qty), 1), 8) as rate, sum(c.s_qty) sale_qty, sum(d.pro_qty) pro_qty from D, c where 1 = 1 and d.BRAND = c.BRAND group by d.BRAND), --交货数量 F as (SELECT BRAND, sum(QTY) AS part_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = '20' and ACTIVE_START&gt;= V_STRAT_DATE and ACTIVE_START &lt; V_END_DATE+1 group by BRAND), --交货数量*销售比率获取 =索赔零件总数 G as (select F.BRAND, sum(F.part_qty * E.rate) as instrorage_qty from F, E where F.BRAND = E.BRAND group by F.BRAND), --计算实绩值 H AS (select G.BRAND, B.sc_qty, instrorage_qty, round(B.sc_qty / instrorage_qty * 1000000, 1) as rate, round(B.sc_qty / instrorage_qty * 1000000, 10) rate_dec from G left join B on G.BRAND = B.BRAND), V AS (SELECT TARGET_VAL, BRAND AS TARGET_TYPE_NAME FROM T_QMS_DB_TARGET_VAL T WHERE T.BUSI_TYPE = '10' AND T.TARGET_DATE= V_MIS_MONTH) SELECT sysdate, '10' AS CACULATE_TYPE, '统计因子，品牌3MIS' AS REMARK, BRAND, BRAND, rate_dec, V_MIS_MONTH, nvl((select target_val from V where H.BRAND = V.target_type_name and rownum=1), 0) as target_val, V_ASYNC_ID FROM H */ DBMS_OUTPUT.put_line(V_SQL); OPEN P_CUR FOR V_SQL;END; 经验分享 123456上面这个实例其实也不算复杂，但做这样的活，却是一件很头痛的事情。过程非常不好调整，特别是业务调整的时候，你想死的心都有。当然，实际使用能避免就避免吧。经过了多次经维护与编写，我总结了以下步骤。1：整理好逻辑，最好以文字的方式把它实现的逻辑写出来贴在备注里。因为SQL本身可读性就差。下次维护连自己都可能不认识了。2：根据第1步整理好的逻辑，写代SQL，变量部分先写死。保证能运行通过。3：整理并定义变量。4：拼写SQL主体，条件。用变量替换写死的代码。5：执行，输出。一般这个过程需要输出多次，先解决语法问题，再解决数据正确性问题。]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java公平锁与非公平锁]]></title>
    <url>%2F2020%2F02%2F10%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200210%2F</url>
    <content type="text"><![CDATA[Java公平锁与非公平锁 定义 当程序使用多线程里，难免有多线程争夺资源的情况。而资源只能被一个线程独占使用，至于资源怎么分配，就涉及到非公平锁与公平锁了。 非公平锁：非公平锁的资源的分配是随机的，看谁先抢到就给谁。可能会出现一个线程长期霸占资源，而另一线程长期得不到资源。公平锁：顾名思义，公平锁的资源是公平分配的，先来先得，后来排队。 实例 开20个线程进行计数，每个线程计算到10000，最后 非公平锁synchroized实现 12345678910111213141516171819202122232425import org.springframework.util.StopWatch;public class ClassTestApp4lication &#123; public static Integer i = new Integer(0); public static Object oj = new Object(); public static void main(String[] args) &#123; StopWatch watch = new StopWatch(); watch.start(); for (int ac = 0; ac &lt; 20; ac++) &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; for (int ac2 = 0; ac2 &lt; 10000; ac2++) &#123; synchronized (oj) &#123; System.out.println("线程ID:"+Thread.currentThread().getId());//输出当前线程ID，便于确认分配的机制 i = i + 1; &#125; &#125; &#125; &#125;; t1.start(); &#125; &#125;&#125; 因为输出的结果太长了，这里抽取部分输出结果，如下：线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:14线程ID:14线程ID:14线程ID:14线程ID:14线程ID:27线程ID:27线程ID:27线程ID:27 非公平锁ReentrantLock实现 用ReentrantLock实现，关键在于实例化ReentrantLock时传参为false。使用无参数重载也是非公平锁，如：public static ReentrantLock rlock=new ReentrantLock(false)或者 public static ReentrantLock rlock=new ReentrantLock()。代码如下： 12345678910111213141516171819202122232425262728import org.springframework.util.StopWatch;import java.util.concurrent.locks.ReentrantLock;public class ClassTest3Application &#123; public static ReentrantLock rlock=new ReentrantLock(false);//false表示非公平锁，或使用无参数重载。 public volatile static int i; public static void main(String[] args) &#123; StopWatch watch =new StopWatch(); watch.start(); for (int ac = 0; ac &lt; 20; ac++) &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; for (int ac2 = 0; ac2 &lt; 1000; ac2++) &#123; try &#123; rlock.lock(); System.out.println("线程ID:"+Thread.currentThread().getId()); i = i + 1; &#125; finally &#123; rlock.unlock(); &#125; &#125; &#125; &#125;; t1.start(); &#125; &#125;&#125; 同样这里也只贴出部分的输出，如下线程ID:12线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:28线程ID:28 公平锁ReentrantLock实现 用ReentrantLock实现，关键在于实例化ReentrantLock时传参为true。如：public static ReentrantLock rlock=new ReentrantLock(true) 12345678910111213141516171819202122232425262728import org.springframework.util.StopWatch;import java.util.concurrent.locks.ReentrantLock;public class ClassTest3Application &#123; public static ReentrantLock rlock=new ReentrantLock(true);//true 表示公平锁 public volatile static int i; public static void main(String[] args) &#123; StopWatch watch =new StopWatch(); watch.start(); for (int ac = 0; ac &lt; 20; ac++) &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; for (int ac2 = 0; ac2 &lt; 1000; ac2++) &#123; try &#123; rlock.lock(); System.out.println("线程ID:"+Thread.currentThread().getId()); i = i + 1; &#125; finally &#123; rlock.unlock(); &#125; &#125; &#125; &#125;; t1.start(); &#125; &#125;&#125; 同样这里也只贴出部分的输出，如下线程ID:12线程ID:13线程ID:14线程ID:15线程ID:16线程ID:17线程ID:12线程ID:18线程ID:19线程ID:13线程ID:20线程ID:14线程ID:21线程ID:15线程ID:22线程ID:16线程ID:23线程ID:17线程ID:24线程ID:12线程ID:25线程ID:18线程ID:26线程ID:19 性能测试 性能测试场景 开启20个线程，每个线程计数1000000次。计划耗时 测试结果 synchronized 非公平锁 | 测试序号 | 耗时(单位为秒) || ——– | ————– || 1 | 0.5398486 || 2 | 0.5319575 || 3 | 0.5299667 || 4 | 0.5496109 || 5 | 0.5520412 | ReentrantLock 非公平锁 | 测试序号 | 耗时(单位为秒) || ——– | ————– || 1 | 0.4283422 || 2 | 0.4390329 || 3 | 0.4378793 || 4 | 0.4409746 || 5 | 0.4377871 | ReentrantLock 公平锁 | 测试序号 | 耗时(单位为秒) || ——– | ————– || 1 | 209.9848296 | 这个比较久，我等了好几分钟，就只做一次测试吧。 结论 | | 性能 | 描述 || ———————- | —- | ——————————————————- || synchronized 非公平锁 | 很好 | 耗时在0.54秒样子 || ReentrantLock 非公平锁 | 最好 | 耗时在0.43秒样子 || ReentrantLock 公平锁 | 最差 | 耗时超过200秒，与非公平锁不是一样等级，公平是有代价的。 |]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java悲观锁与乐观锁]]></title>
    <url>%2F2020%2F02%2F09%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200209%2F</url>
    <content type="text"><![CDATA[Java悲观锁与乐观锁 锁的目的 多线程编程如有共用资源的使用时，需要保证数据安全，资源需要同步处理。处理资源的手段可以有：互斥同步与非阻塞同步。实现分别对应：悲观锁与乐观锁。 实例 开20个线程进行计数，每个线程计算到10000。分别使用悲观锁与乐观锁来实现。 悲观锁实现 悲观锁是主要使用synchronized实现，通过锁住对应的对象，独占资源的方式。demo实现代码如下： 1234567891011121314151617181920212223242526272829303132import org.springframework.util.StopWatch;public class ClassTestApplication &#123; public static Integer i = new Integer(0); public static Object oj = new Object();//用于锁对象 public static void main(String[] args) &#123; StopWatch watch = new StopWatch(); watch.start(); for (int ac = 0; ac &lt; 20; ac++) &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; for (int ac2 = 0; ac2 &lt; 10000; ac2++) &#123; synchronized (oj) &#123;//锁只能锁对象，不能锁值类型,所以需要另外新建oj对象 i = i + 1; Thread.yield();//降低当前线程的优先级 &#125; &#125; System.out.println("i=" + i); //输出时耗 if (i == 200000) &#123; watch.stop(); System.out.println("耗时:" + watch.getTotalTimeSeconds()); &#125; &#125; &#125;; t1.start(); &#125; &#125;&#125; 输出结果如下：i=20480i=60223i=71641i=102771i=103641i=117543i=127194i=131049i=140436i=146951i=153894i=160899i=162207i=164290i=170482i=181676i=189241i=194425i=198873i=200000耗时:0.1261655 乐观锁实现 乐观锁主要通过CAS（Compare and swap）去现实。demo实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637import org.springframework.util.StopWatch;import java.util.concurrent.atomic.AtomicInteger;public class ClassTest2Application &#123; public static AtomicInteger j = new AtomicInteger(); public volatile static int i; public static void main(String[] args) &#123; StopWatch watch =new StopWatch(); watch.start(); for (int ac = 0; ac &lt; 20; ac++) &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; for (int ac2 = 0; ac2 &lt; 10000; ac2++) &#123; for (; ; ) &#123; //自旋 Integer current = i; Integer next = i + 1; if (j.compareAndSet(current, next)) &#123; //对比并赋值,注意需要新建一变量current，不能直接使用i i = next; Thread.yield();//降低当前线程的优先级 break; &#125; &#125; &#125; System.out.println("i=" + i); if(i==200000) &#123; watch.stop(); System.out.println("耗时:"+watch.getTotalTimeSeconds()); &#125; &#125; &#125;; t1.start(); &#125; &#125;&#125; 输出结果如下i=143289i=146323i=147099i=150204i=150598i=155177i=177143i=184003i=184685i=187439i=188419i=189595i=190235i=192196i=193054i=194514i=194798i=198438i=199530i=200000耗时:0.0482009 总结 这里只针对demo的场景做一下简单对比。 性能(好) 可读性（好） 复杂度（低） 乐观锁 悲观锁 悲观锁 PS：1： synchronize 实际是多种锁组合，根据使用的情况，从 无锁-&gt;偏向锁-&gt;轻量级锁-&gt;重量级锁 。2：因为测试的线程比较多，使用synchronize瞬间就升级为重量级锁。所以性能的对比还是可以的。]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis添加记录，返回主键ID]]></title>
    <url>%2F2020%2F02%2F07%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200207%2F</url>
    <content type="text"><![CDATA[MyBatis添加记录，返回主键ID Role.java实体类 Role.java 1234567891011121314151617181920212223public class Role implements Serializable &#123; private String roleId; private String name; private Integer status; public String getRoleId() &#123; return roleId; &#125; public void setRoleId(String roleId) &#123; this.roleId = roleId; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getStatus() &#123; return status; &#125; public void setStatus(Integer status) &#123; this.status = status; &#125;&#125; SysRoleDao.java 1234public interface SysRoleDao &#123; public int addRole(SysRole role);&#125; mapper-role.xml 12345678910&lt;insert id="addRole" parameterType="SysRole" useGeneratedKeys="true" keyProperty="roleId" keyColumn="role_id"&gt; insert into t_sys_role( name,status ) values( #&#123;name,jdbcType=VARCHAR&#125;, #&#123;status,jdbcType=VARCHAR&#125;, )&lt;/insert&gt; 注: 123451、添加记录能够返回主键的关键点在于需要在&lt;insert&gt;标签中添加以下三个属性&lt;insert useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot; keyColumn=&quot;id&quot;&gt;&lt;/insert&gt;。useGeneratedKeys：必须设置为true，否则无法获取到主键id。keyProperty：设置为POJO对象的主键id属性名称。keyColumn：设置为数据库记录的主键id字段名称2、新添加主键id并不是在执行添加操作时直接返回的，而是在执行添加操作之后将新添加记录的主键id字段设置为POJO对象的主键id属性 TestDao.java 1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations= &#123;"classpath:config/spring-core.xml","classpath:config/spring-web.xml"&#125;)public class TestDao&#123; @Autowired SysRoleDao roleDao; @Test public void test() &#123; SysRole role=new SysRole(); role.setName("admin10"); role.setStatus(1); System.out.println("返回结果:"+roleDao.addRole(role)); System.out.println("主键id:"+role.getRoleId()); &#125;&#125;]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[过滤器与拦截器的区别]]></title>
    <url>%2F2020%2F02%2F05%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200205%2F</url>
    <content type="text"><![CDATA[拦截器与过滤器的区别 [TOC] 1.过滤器：1依赖于servlet容器。在实现上基于函数回调，可以对几乎所有请求进行过滤，但是缺点是一个过滤器实例只能在容器初始化时调用一次。使用过滤器的目的是用来做一些过滤操作，获取我们想要获取的数据，比如：在过滤器中修改字符编码；在过滤器中修改HttpServletRequest的一些参数，包括：过滤低俗文字、危险字符等 2.拦截器：1依赖于web框架，在SpringMVC中就是依赖于SpringMVC框架。在实现上基于Java的反射机制，属于面向切面编程（AOP）的一种运用。由于拦截器是基于web框架的调用，因此可以使用Spring的依赖注入（DI）进行一些业务操作，同时一个拦截器实例在一个controller生命周期之内可以多次调用。但是缺点是只能对controller请求进行拦截，对其他的一些比如直接访问静态资源的请求则没办法进行拦截处理 3.过滤器和拦截器的区别：1234567891011①拦截器是基于java的反射机制的，而过滤器是基于函数回调。②拦截器不依赖与servlet容器，过滤器依赖与servlet容器。③拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。④拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。⑤在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。⑥拦截器可以获取IOC容器中的各个bean，而过滤器就不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。 过滤器@Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)throws IOException, ServletException { ​ System.out.println(“before…”); ​ chain.doFilter(request, response); ​ System.out.println(“after…”); } chain.doFilter(request, response);这个方法的调用作为分水岭。事实上调用Servlet的doService()方法是在chain.doFilter(request, response);这个方法中进行的。 拦截器拦截器是被包裹在过滤器之中的。 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)throws Exception { ​ System.out.println(“preHandle”); ​ returntrue; ​ } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView)throws Exception { ​ System.out.println(“postHandle”); ​ } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)throws Exception { ​ System.out.println(“afterCompletion”); ​ } 1234567a.preHandle()这个方法是在过滤器的chain.doFilter(request, response)方法的前一步执行，也就是在 [System.out.println(&quot;before...&quot;)][chain.doFilter(request, response)]之间执行。 b.preHandle()方法之后，在return ModelAndView之前进行，可以操控Controller的ModelAndView内容。 c.afterCompletion()方法是在过滤器返回给前端前一步执行，也就是在[chain.doFilter(request, response)][System.out.println(&quot;after...&quot;)]之间执行。 SpringMVC的机制是由同一个Servlet来分发请求给不同的Controller，其实这一步是在Servlet的service()方法中执行的。所以过滤器、拦截器、service()方法，dispatc()方法的执行顺序应该是这样的，大致画了个图：其实非常好测试，自己写一个过滤器，一个拦截器，然后在这些方法中都加个断点，一路F8下去就得出了结论。 123作者：谁在烽烟彼岸链接：https://www.jianshu.com/p/7bd0cad17f23来源：简书]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[insert是行锁还是表锁？]]></title>
    <url>%2F2020%2F02%2F01%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200201%2F</url>
    <content type="text"><![CDATA[Insert是行锁还是表锁？[toc] 一、前言项目中遇到一个很奇怪的问题：问题描述：现在需要从项目外部导大量的数据到项目内，这个时候我起了一个spring事务往很多张表中去插入数据，这个时候其他用户访问系统去更新旧的数据的时候发现表被锁了。也就是说我在导入数据的时候，其他用户都不能对系统的表进行相应的更新操作。这是为什么？？？？于是想要了解一下insert加锁机制，但是发现网上介绍的文章比较少且零散，挖掘过程比较忙乱。 本以为只需要系统学习一个较完全的逻辑，但是实际牵扯很多innodb锁相关知识及加锁方式。我好像并没有那么大的能耐，把各种场景的加锁过程一一列举并加之分析；亦没有太多的精力验证网上的言论的准确性。 只好根据现在了解的内容，参考官方文档，说说自己当前的理解。本文仅供参考，如有误导，概不负责。 答：数据库的事务机制就是这样，insert时全表锁，因为要生成主键字段、索引等等，update是行级锁。同时对一张表进行读写操作，会产生‘脏’数据，导致读、写两端的数据不一致。当然了，这是要在绝对意义上的‘同时’情况下才会发生。 二、现场状态不同的mysql版本，不同的参数设置，都可能对加锁过程有影响。分析加锁机制还是应当尽可能多地列举一下关键参数，例如：当前mysql版本、事务隔离级别等。如下，仅仅只列出个别比较重要的参数。 1.数据库版本123456mysql&gt; select version();+-----------+| version() |+-----------+| 5.6.27 |+-----------+ 2.数据库引擎12345678mysql&gt; show variables like '%engine%';+----------------------------+--------+| Variable_name | Value |+----------------------------+--------+| default_storage_engine | InnoDB || default_tmp_storage_engine | InnoDB || storage_engine | InnoDB |+----------------------------+--------+ 注：InnoDB支持事务，Myisam不支持事务；InnoDB支持行锁和表锁；Myisam不支持行锁。 3.事务隔离级别123456mysql&gt; select @@global.tx_isolation, @@session.tx_isolation, @@tx_isolation;+-----------------------+------------------------+-----------------+| @@global.tx_isolation | @@session.tx_isolation | @@tx_isolation |+-----------------------+------------------------+-----------------+| REPEATABLE-READ | REPEATABLE-READ | REPEATABLE-READ |+-----------------------+------------------------+-----------------+ 注：几种事务隔离级别：READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE 4.查看gap锁开启状态123456mysql&gt; show variables like &apos;innodb_locks_unsafe_for_binlog&apos;;+--------------------------------+-------+| Variable_name | Value |+--------------------------------+-------+| innodb_locks_unsafe_for_binlog | OFF |+--------------------------------+-------+ innodb_locks_unsafe_for_binlog：默认值为0，即启用gap lock。最主要的作用就是控制innodb是否对gap加锁。但是，这一设置变更并不影响外键和唯一索引（含主键）对gap进行加锁的需要。开启innodb_locks_unsafe_for_binlog的REPEATABLE-READ事务隔离级别，很大程度上已经蜕变成了READ-COMMITTED。 参见官方文档[^1]： By default, the value of innodb_locks_unsafe_for_binlog is 0 (disabled), which means that gap locking is enabled: InnoDB uses next-key locks for searches and index scans. To enable the variable, set it to 1. This causes gap locking to be disabled: InnoDB uses only index-record locks for searches and index scans. Enabling innodb_locks_unsafe_for_binlog does not disable the use of gap locking for foreign-key constraint checking or duplicate-key checking. The effect of enabling innodb_locks_unsafe_for_binlog is similar to but not identical to setting the transaction isolation level to READ COMMITTED. 5. 查看自增锁模式123456mysql&gt; show variables like &apos;innodb_autoinc_lock_mode&apos;;+--------------------------+-------+| Variable_name | Value |+--------------------------+-------+| innodb_autoinc_lock_mode | 1 |+--------------------------+-------+ innodb_autoinc_lock_mode有3种配置模式：0、1、2，分别对应”传统模式”, “连续模式”, “交错模式”。[^8]传统模式：涉及auto-increment列的插入语句加的表级AUTO-INC锁，只有插入执行结束后才会释放锁。这是一种兼容MySQL 5.1之前版本的策略。连续模式：可以事先确定插入行数的语句(包括单行和多行插入)，分配连续的确定的auto-increment值；对于插入行数不确定的插入语句，仍加表锁。这种模式下，事务回滚，auto-increment值不会回滚，换句话说，自增列内容会不连续。交错模式：同一时刻多条SQL语句产生交错的auto-increment值。 由于insert语句常常涉及自增列的加锁过程，会涉及到AUTO-INC Locks加锁过程。为了分步了解insert加锁过程，本文暂不讨论任何涉及自增列的加锁逻辑。 三、InnoDB锁类型[^2]1. 基本锁基本锁：共享锁(Shared Locks：S锁)与排他锁(Exclusive Locks：X锁) mysql允许拿到S锁的事务读一行，允许拿到X锁的事务更新或删除一行。加了S锁的记录，允许其他事务再加S锁，不允许其他事务再加X锁；加了X锁的记录，不允许其他事务再加S锁或者X锁。 mysql对外提供加这两种锁的语法如下：加S锁：select…lock in share mode加X锁：select…for update 2. 意向锁(Intention Locks)InnoDB为了支持多粒度(表锁与行锁)的锁并存，引入意向锁。意向锁是表级锁，可分为意向共享锁(IS锁)和意向排他锁(IX锁)。 InnoDB supports multiple granularity locking which permits coexistence of row-level locks and locks on entire tables. To make locking at multiple granularity levels practical, additional types of locks called intention locks are used. Intention locks are table-level locks in InnoDB that indicate which type of lock (shared or exclusive) a transaction will require later for a row in that table. There are two types of intention locks used in InnoDB (assume that transaction T has requested a lock of the indicated type on table t):Intention shared (IS): Transaction T intends to set S locks on individual rows in table t.Intention exclusive (IX): Transaction T intends to set X locks on those rows. 事务在请求S锁和X锁前，需要先获得对应的IS、IX锁。 Before a transaction can acquire an S lock on a row in table t, it must first acquire an IS or stronger lock on t. Before a transaction can acquire an X lock on a row, it must first acquire an IX lock on t. 意向锁产生的主要目的是为了处理行锁和表锁之间的冲突，用于表明“某个事务正在某一行上持有了锁，或者准备去持有锁”。 The main purpose of IX and IS locks is to show that someone is locking a row, or going to lock a row in the table. 共享锁、排他锁与意向锁的兼容矩阵如下： X IX S IS X 冲突 冲突 冲突 冲突 IX 冲突 兼容 冲突 兼容 S 冲突 冲突 兼容 兼容 IS 冲突 兼容 兼容 兼容 思考从官方文档字面意思上看意向锁是表级锁，但是大牛不认为“Intention lock 是表级锁”[^5]?另外，由于意向锁主要用于解决行锁与表锁间冲突问题，鉴于平时表级操作特别少，在分析加锁过程是否可以不用过多考虑意向锁的问题? 3. 行锁记录锁(Record Locks)记录锁, 仅仅锁住索引记录的一行。单条索引记录上加锁，record lock锁住的永远是索引，而非记录本身，即使该表上没有任何索引，那么innodb会在后台创建一个隐藏的聚集主键索引，那么锁住的就是这个隐藏的聚集主键索引。所以说当一条sql没有走任何索引时，那么将会在每一条聚集索引后面加X锁，这个类似于表锁，但原理上和表锁应该是完全不同的。 参见官方文档[^3]： If the table has no PRIMARY KEY or suitable UNIQUE index, InnoDB internally generates a hidden clustered index on a synthetic column containing row ID values. The rows are ordered by the ID that InnoDB assigns to the rows in such a table. The row ID is a 6-byte field that increases monotonically as new rows are inserted. Thus, the rows ordered by the row ID are physically in insertion order. 间隙锁(Gap Locks)区间锁, 仅仅锁住一个索引区间(开区间)。在索引记录之间的间隙中加锁，或者是在某一条索引记录之前或者之后加锁，并不包括该索引记录本身。 next-key锁(Next-Key Locks)record lock + gap lock, 左开右闭区间。 A next-key lock is a combination of a record lock on the index record and a gap lock on the gap before the index record. By default, InnoDB operates in REPEATABLE READ transaction isolation level and with the innodb_locks_unsafe_for_binlog system variable disabled. In this case, InnoDB uses next-key locks for searches and index scans, which prevents phantom rows。 默认情况下，innodb使用next-key locks来锁定记录。但当查询的索引含有唯一属性的时候，Next-Key Lock 会进行优化，将其降级为Record Lock，即仅锁住索引本身，不是范围。 插入意向锁(Insert Intention Locks)Gap Lock中存在一种插入意向锁（Insert Intention Lock），在insert操作时产生。在多事务同时写入不同数据至同一索引间隙的时候，并不需要等待其他事务完成，不会发生锁等待。假设有一个记录索引包含键值4和7，不同的事务分别插入5和6，每个事务都会产生一个加在4-7之间的插入意向锁，获取在插入行上的排它锁，但是不会被互相锁住，因为数据行并不冲突。 An insert intention lock is a type of gap lock set by INSERT operations prior to row insertion. This lock signals the intent to insert in such a way that multiple transactions inserting into the same index gap need not wait for each other if they are not inserting at the same position within the gap. Suppose that there are index records with values of 4 and 7. Separate transactions that attempt to insert values of 5 and 6, respectively, each lock the gap between 4 and 7 with insert intention locks prior to obtaining the exclusive lock on the inserted row, but do not block each other because the rows are nonconflicting. 注：插入意向锁并非意向锁，而是一种特殊的间隙锁。 4. 行锁的兼容矩阵[^4] Gap Insert Intention Record Next-Key Gap 兼容 兼容 兼容 兼容 Insert Intention 冲突 兼容 兼容 冲突 Record 兼容 兼容 冲突 冲突 Next-Key 兼容 兼容 冲突 冲突 表注：横向是已经持有的锁，纵向是正在请求的锁。 由于S锁和S锁是完全兼容的，因此在判别兼容性时只考虑持有的锁与请求的锁是这三种组合情形：X、S和S、X和X、X。另外，需要提醒注意的是进行兼容判断也只是针对于加锁涉及的行有交集的情形。 分析兼容矩阵可以得出如下几个结论： INSERT操作之间不会有冲突。 GAP,Next-Key会阻止Insert。 GAP和Record,Next-Key不会冲突 Record和Record、Next-Key之间相互冲突。 已有的Insert锁不阻止任何准备加的锁。 5. 自增锁(AUTO-INC Locks)AUTO-INC锁是一种特殊的表级锁，发生涉及AUTO_INCREMENT列的事务性插入操作时产生。 官方解释如下[^3]： An AUTO-INC lock is a special table-level lock taken by transactions inserting into tables with AUTO_INCREMENT columns. In the simplest case, if one transaction is inserting values into the table, any other transactions must wait to do their own inserts into that table, so that rows inserted by the first transaction receive consecutive primary key values. 四、insert加锁过程官方文档[^6]对于insert加锁的描述如下： INSERT sets an exclusive lock on the inserted row. This lock is an index-record lock, not a next-key lock (that is, there is no gap lock) and does not prevent other sessions from inserting into the gap before the inserted row. Prior to inserting the row, a type of gap lock called an insert intention gap lock is set. This lock signals the intent to insert in such a way that multiple transactions inserting into the same index gap need not wait for each other if they are not inserting at the same position within the gap. Suppose that there are index records with values of 4 and 7. Separate transactions that attempt to insert values of 5 and 6 each lock the gap between 4 and 7 with insert intention locks prior to obtaining the exclusive lock on the inserted row, but do not block each other because the rows are nonconflicting. If a duplicate-key error occurs, a shared lock on the duplicate index record is set. This use of a shared lock can result in deadlock should there be multiple sessions trying to insert the same row if another session already has an exclusive lock. 简单的insert会在insert的行对应的索引记录上加一个排它锁，这是一个record lock，并没有gap，所以并不会阻塞其他session在gap间隙里插入记录。 不过在insert操作之前，还会加一种锁，官方文档称它为insertion intention gap lock，也就是意向的gap锁。这个意向gap锁的作用就是预示着当多事务并发插入相同的gap空隙时，只要插入的记录不是gap间隙中的相同位置，则无需等待其他session就可完成，这样就使得insert操作无须加真正的gap lock。假设有一个记录索引包含键值4和7，不同的事务分别插入5和6，每个事务都会产生一个加在4-7之间的插入意向锁，获取在插入行上的排它锁，但是不会被互相锁住，因为数据行并不冲突。 假设发生了一个唯一键冲突错误，那么将会在重复的索引记录上加读锁。当有多个session同时插入相同的行记录时，如果另外一个session已经获得该行的排它锁，那么将会导致死锁。 思考：Insert Intention Locks作用Insert Intention Locks的引入，我理解是为了提高数据插入的并发能力。如果没有Insert Intention Locks的话，可能就需要使用Gap Locks来代替。 五、insert死锁场景分析接下来，带大家看几个与insert相关的死锁场景。 表结构123456789CREATE TABLE `aa` (`id` int(10) unsigned NOT NULL COMMENT &apos;主键&apos;,`name` varchar(20) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;姓名&apos;,`age` int(11) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;年龄&apos;,`stage` int(11) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;关卡数&apos;,PRIMARY KEY (`id`),UNIQUE KEY `udx_name` (`name`),KEY `idx_stage` (`stage`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 表数据12345678910mysql&gt; select * from aa;+----+------+-----+-------+| id | name | age | stage |+----+------+-----+-------+| 1 | yst | 11 | 8 || 2 | dxj | 7 | 4 || 3 | lb | 13 | 7 || 4 | zsq | 5 | 7 || 5 | lxr | 13 | 4 |+----+------+-----+-------+ 事务执行时序表 T1(36727) T2(36728) T3(36729) begin; begin; begin; insert into aa values(6, ‘test’, 12, 3); insert into aa values(6, ‘test’, 12, 3); insert into aa values(6, ‘test’, 12, 3); rollback; ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction Query OK, 1 row affected (13.10 sec) 如果T1未rollback，而是commit的话，T2和T3会报唯一键冲突：ERROR 1062 (23000): Duplicate entry ‘6’ for key ‘PRIMARY’ 事务锁占用情况T1 rollback前，各事务锁占用情况： 12345678mysql&gt; select * from information_schema.innodb_locks;+--------------+-------------+-----------+-----------+-------------+------------+------------+-----------+--| lock_id | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |+--------------+-------------+-----------+-----------+-------------+------------+------------+-----------+--| 36729:24:3:7 | 36729 | S | RECORD | `test`.`aa` | PRIMARY | 24 | 3 | 7 | 6 || 36727:24:3:7 | 36727 | X | RECORD | `test`.`aa` | PRIMARY | 24 | 3 | 7 | 6 || 36728:24:3:7 | 36728 | S | RECORD | `test`.`aa` | PRIMARY | 24 | 3 | 7 | 6 |+--------------+-------------+-----------+-----------+-------------+------------+------------+-----------+-- 注：mysql有自己的一套规则来决定T2与T3哪个进行回滚，本文不做讨论。 死锁日志1234567891011121314151617181920212223242526272829------------------------LATEST DETECTED DEADLOCK------------------------2016-07-21 19:34:23 700000a3f000*** (1) TRANSACTION:TRANSACTION 36728, ACTIVE 199 sec insertingmysql tables in use 1, locked 1LOCK WAIT 4 lock struct(s), heap size 1184, 2 row lock(s)MySQL thread id 13, OS thread handle 0x700000b0b000, query id 590 localhost root updateinsert into aa values(6, &apos;test&apos;, 12, 3)*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 24 page no 3 n bits 80 index `PRIMARY` of table `test`.`aa` trx id 36728 lock_mode X insert intention waitingRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 00: len 8; hex 73757072656d756d; asc supremum;;*** (2) TRANSACTION:TRANSACTION 36729, ACTIVE 196 sec insertingmysql tables in use 1, locked 14 lock struct(s), heap size 1184, 2 row lock(s)MySQL thread id 14, OS thread handle 0x700000a3f000, query id 591 localhost root updateinsert into aa values(6, &apos;test&apos;, 12, 3)*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 24 page no 3 n bits 80 index `PRIMARY` of table `test`.`aa` trx id 36729 lock mode SRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 00: len 8; hex 73757072656d756d; asc supremum;;*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 24 page no 3 n bits 80 index `PRIMARY` of table `test`.`aa` trx id 36729 lock_mode X insert intention waitingRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 00: len 8; hex 73757072656d756d; asc supremum;;*** WE ROLL BACK TRANSACTION (2) 死锁成因事务T1成功插入记录，并获得索引id=6上的排他记录锁(LOCK_X | LOCK_REC_NOT_GAP)。紧接着事务T2、T3也开始插入记录，请求排他插入意向锁(LOCK_X | LOCK_GAP | LOCK_INSERT_INTENTION)；但由于发生重复唯一键冲突，各自请求的排他记录锁(LOCK_X | LOCK_REC_NOT_GAP)转成共享记录锁(LOCK_S | LOCK_REC_NOT_GAP)。 T1回滚释放索引id=6上的排他记录锁(LOCK_X | LOCK_REC_NOT_GAP)，T2和T3都要请求索引id=6上的排他记录锁(LOCK_X | LOCK_REC_NOT_GAP)。由于X锁与S锁互斥，T2和T3都等待对方释放S锁。于是，死锁便产生了。 如果此场景下，只有两个事务T1与T2或者T1与T3，则不会引发如上死锁情况产生。 思考 为什么发现重复主键冲突的时候，要将事务请求的X锁转成S锁？(比较牵强的)个人理解，跟插入意向锁类型，也是为了提高插入的并发效率。 插入前请求插入意向锁的作用？个人认为，通过兼容矩阵来分析，Insert Intention Locks是为了减少插入时的锁冲突。 2. GAP与Insert Intention冲突引发的死锁表结构123456CREATE TABLE `t` (`a` int(11) NOT NULL,`b` int(11) DEFAULT NULL,PRIMARY KEY (`a`),KEY `idx_b` (`b`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 表数据123456789mysql&gt; select * from t;+----+------+| a | b |+----+------+| 1 | 2 || 2 | 3 || 3 | 4 || 11 | 22 |+----+------+ 事务执行时序表 T1(36831) T2(36832) begin; begin; select * from t where b = 6 for update; select * from t where b = 8 for update; insert into t values (4,5); insert into t values (4,5); ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction Query OK, 1 row affected (5.45 sec) 事务锁占用情况T2 insert前，各事务锁占用情况： 1234567mysql&gt; select * from information_schema.innodb_locks;+--------------+-------------+-----------+-----------+------------+------------+------------+-----------+---| lock_id | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |+--------------+-------------+-----------+-----------+------------+------------+------------+-----------+---| 36831:25:4:5 | 36831 | X,GAP | RECORD | `test`.`t` | idx_b | 25 | 4 | 5 | 22, 11 || 36832:25:4:5 | 36832 | X,GAP | RECORD | `test`.`t` | idx_b | 25 | 4 | 5 | 22, 11 |+--------------+-------------+-----------+-----------+------------+------------+------------+-----------+--- 死锁日志12345678910111213141516171819202122232425262728293031323334------------------------LATEST DETECTED DEADLOCK------------------------2016-07-28 12:28:34 700000a3f000*** (1) TRANSACTION:TRANSACTION 36831, ACTIVE 17 sec insertingmysql tables in use 1, locked 1LOCK WAIT 4 lock struct(s), heap size 1184, 3 row lock(s), undo log entries 1MySQL thread id 38, OS thread handle 0x700000b0b000, query id 953 localhost root updateinsert into t values (4,5)*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 25 page no 4 n bits 72 index `idx_b` of table `test`.`t` trx id 36831 lock_mode X locks gap before rec insert intention waitingRecord lock, heap no 5 PHYSICAL RECORD: n_fields 2; compact format; info bits 00: len 4; hex 80000016; asc ;;1: len 4; hex 8000000b; asc ;;*** (2) TRANSACTION:TRANSACTION 36832, ACTIVE 13 sec insertingmysql tables in use 1, locked 13 lock struct(s), heap size 360, 2 row lock(s)MySQL thread id 39, OS thread handle 0x700000a3f000, query id 954 localhost root updateinsert into t values (4,5)*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 25 page no 4 n bits 72 index `idx_b` of table `test`.`t` trx id 36832 lock_mode X locks gap before recRecord lock, heap no 5 PHYSICAL RECORD: n_fields 2; compact format; info bits 00: len 4; hex 80000016; asc ;;1: len 4; hex 8000000b; asc ;;*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 25 page no 3 n bits 72 index `PRIMARY` of table `test`.`t` trx id 36832 lock mode S locks rec but not gap waitingRecord lock, heap no 5 PHYSICAL RECORD: n_fields 4; compact format; info bits 00: len 4; hex 80000004; asc ;;1: len 6; hex 000000008fdf; asc ;;2: len 7; hex 8d000001d00110; asc ;;3: len 4; hex 80000005; asc ;;*** WE ROLL BACK TRANSACTION (2) 死锁成因事务T1执行查询语句，在索引b=6上加排他Next-key锁(LOCK_X | LOCK_ORDINARY)，会锁住idx_b索引范围(4, 22)。事务T2执行查询语句，在索引b=8上加排他Next-key锁(LOCK_X | LOCK_ORDINARY)，会锁住idx_b索引范围(4, 22)。由于请求的GAP与已持有的GAP是兼容的，因此，事务T2在idx_b索引范围(4, 22)也能加锁成功。 事务T1执行插入语句，会先加排他Insert Intention锁。由于请求的Insert Intention锁与已有的GAP锁不兼容，则事务T1等待T2释放GAP锁。事务T2执行插入语句，也会等待T1释放GAP锁。于是，死锁便产生了。 注：LOCK_ORDINARY拥有LOCK_GAP一部分特性。 思考：Insert Intention锁在加哪级索引上？这个排他锁加在PK上，还是二级索引上？ 七、补充知识1. 查看事务隔离级别SELECT @@global.tx_isolation;SELECT @@session.tx_isolation;SELECT @@tx_isolation; 2. 设置隔离级别SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE}例如：set session transaction isolation level read uncommitted; 3. 查看auto_increment机制模式show variables like ‘innodb_autoinc_lock_mode’; 4. 查看表状态show table status like ‘plan_branch’\G;show table status from test like ‘plan_branch’\G; 5. 查看SQL性能show profilesshow profile for query 1; 6. 查看当前最新事务ID每开启一个新事务，记录当前最新事务的id，可用于后续死锁分析。show engine innodb status\G; 7. 查看事务锁等待状态情况select from information_schema.innodb_locks;select from information_schema.innodb_lock_waits;select * from information_schema.innodb_trx; 8. 查看innodb状态(包含最近的死锁日志)show engine innodb status; 八、参考文档[^1]: InnoDB Startup Options and System Variables[^2]: InnoDB Locking[^3]: Clustered and Secondary Indexes[^4]: [MySQL] gap lock/next-key lock浅析[^5]: Intention Lock是否表级锁[^6]: Locks Set by Different SQL Statements in InnoDB[^8]: AUTO_INCREMENT lock Handing in InnoDB[^9]: 深入理解innodb的锁(record,gap,Next-Key lock)[^11]: The INFORMATION_SCHEMA INNODB_LOCKS Table[^12]: The INFORMATION_SCHEMA INNODB_TRX Table[^13]: mysql innodb插入意向锁 123本文标题:mysql insert锁机制文章作者:yeshaoting原始链接:http://yeshaoting.cn/article/database/mysql insert锁机制/]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL是行级锁还是表级锁]]></title>
    <url>%2F2020%2F01%2F31%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200131%2F</url>
    <content type="text"><![CDATA[MySQL是行级锁还是表级锁[toc] 一、概述​ 数据库锁定机制简单来说，就是数据库为了保证数据的一致性，而使各种共享资源在被并发访问变得有序所设计的一种规则。对于任何一种数据库来说都需要有相应的锁定机制，所以MySQL自然也不能例外。MySQL数据库由于其自身架构的特点，存在多种数据存储引擎，每种存储引擎所针对的应用场景特点都不太一样，为了满足各自特定应用场景的需求，每种存储引擎的锁定机制都是为各自所面对的特定场景而优化设计，所以各存储引擎的锁定机制也有较大区别。MySQL各存储引擎使用了三种类型（级别）的锁定机制：表级锁定，行级锁定和页级锁定。 1.表级锁定（table-level）​ 表级别的锁定是MySQL各存储引擎中最大颗粒度的锁定机制。该锁定机制最大的特点是实现逻辑非常简单，带来的系统负面影响最小。所以获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所以可以很好的避免困扰我们的死锁问题。​ 当然，锁定颗粒度大所带来最大的负面影响就是出现锁定资源争用的概率也会最高，致使并大度大打折扣。使用表级锁定的主要是MyISAM，MEMORY，CSV等一些非事务性存储引擎。 2.行级锁定（row-level）​ 行级锁定最大的特点就是锁定对象的颗粒度很小，也是目前各大数据库管理软件所实现的锁定颗粒度最小的。由于锁定颗粒度很小，所以发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能。​ 虽然能够在并发处理能力上面有较大的优势，但是行级锁定也因此带来了不少弊端。由于锁定资源的颗粒度很小，所以每次获取锁和释放锁需要做的事情也更多，带来的消耗自然也就更大了。此外，行级锁定也最容易发生死锁。使用行级锁定的主要是InnoDB存储引擎。 3.页级锁定（page-level）​ 页级锁定是MySQL中比较独特的一种锁定级别，在其他数据库管理软件中也并不是太常见。页级锁定的特点是锁定颗粒度介于行级锁定与表级锁之间，所以获取锁定所需要的资源开销，以及所能提供的并发处理能力也同样是介于上面二者之间。另外，页级锁定和行级锁定一样，会发生死锁。​ 在数据库实现资源锁定的过程中，随着锁定资源颗粒度的减小，锁定相同数据量的数据所需要消耗的内存数量是越来越多的，实现算法也会越来越复杂。不过，随着锁定资源颗粒度的减小，应用程序的访问请求遇到锁等待的可能性也会随之降低，系统整体并发度也随之提升。使用页级锁定的主要是BerkeleyDB存储引擎。 总的来说，MySQL这3种锁的特性可大致归纳如下： 1234表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低；行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高； 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。适用：从锁的角度来说，表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。 二、表级锁定由于MyISAM存储引擎使用的锁定机制完全是由MySQL提供的表级锁定实现，所以下面我们将以MyISAM存储引擎作为示例存储引擎。 1.MySQL表级锁的锁模式MySQL的表级锁有两种模式：表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。锁模式的兼容性： 123对MyISAM表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；对MyISAM表的写操作，则会阻塞其他用户对同一表的读和写操作；MyISAM表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作。其他线程的读、写操作都会等待，直到锁被释放为止。 2.如何加表锁MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此，用户一般不需要直接用LOCK TABLE命令给MyISAM表显式加锁。 3.MyISAM表锁优化建议对于MyISAM存储引擎，虽然使用表级锁定在锁定实现的过程中比实现行级锁定或者页级锁所带来的附加成本都要小，锁定本身所消耗的资源也是最少。但是由于锁定的颗粒度比较到，所以造成锁定资源的争用情况也会比其他的锁定级别都要多，从而在较大程度上会降低并发处理能力。所以，在优化MyISAM存储引擎锁定问题的时候，最关键的就是如何让其提高并发度。由于锁定级别是不可能改变的了，所以我们首先需要尽可能让锁定的时间变短，然后就是让可能并发进行的操作尽可能的并发。 （1）查询表级锁争用情况MySQL内部有两组专门的状态变量记录系统内部锁资源争用情况： 1234567mysql&gt; show status like &apos;table%&apos;;+----------------------------+---------+| Variable_name | Value |+----------------------------+---------+| Table_locks_immediate | 100 || Table_locks_waited | 11 |+----------------------------+---------+ 这里有两个状态变量记录MySQL内部表级锁定的情况，两个变量说明如下：Table_locks_immediate：产生表级锁定的次数；Table_locks_waited：出现表级锁定争用而发生等待的次数；两个状态值都是从系统启动后开始记录，出现一次对应的事件则数量加1。如果这里的Table_locks_waited状态值比较高，那么说明系统中表级锁定争用现象比较严重，就需要进一步分析为什么会有较多的锁定资源争用了。 （2）缩短锁定时间12345如何让锁定时间尽可能的短呢？唯一的办法就是让我们的Query执行时间尽可能的短。a)尽两减少大的复杂Query，将复杂Query分拆成几个小的Query分布进行；b)尽可能的建立足够高效的索引，让数据检索更迅速；c)尽量让MyISAM存储引擎的表只存放必要的信息，控制字段类型；d)利用合适的机会优化MyISAM表数据文件。 （3）分离能并行的操作​ 说到MyISAM的表锁，而且是读写互相阻塞的表锁，可能有些人会认为在MyISAM存储引擎的表上就只能是完全的串行化，没办法再并行了。大家不要忘记了，MyISAM的存储引擎还有一个非常有用的特性，那就是ConcurrentInsert（并发插入）的特性。MyISAM存储引擎有一个控制是否打开Concurrent Insert功能的参数选项：concurrent_insert，可以设置为0，1或者2。 三个值的具体说明如下： 1234concurrent_insert=2，无论MyISAM表中有没有空洞，都允许在表尾并发插入记录；concurrent_insert=1，如果MyISAM表中没有空洞（即表的中间没有被删除的行），MyISAM允许在一个进程读表的同时，另一个进程从表尾插入记录。这也是MySQL的默认设置；concurrent_insert=0，不允许并发插入。可以利用MyISAM存储引擎的并发插入特性，来解决应用中对同一表查询和插入的锁争用。例如，将concurrent_insert系统变量设为2，总是允许并发插入；同时，通过定期在系统空闲时段执行OPTIMIZE TABLE语句来整理空间碎片，收回因删除记录而产生的中间空洞。 （4）合理利用读写优先级MyISAM存储引擎的是读写互相阻塞的，那么，一个进程请求某个MyISAM表的读锁，同时另一个进程也请求同一表的写锁，MySQL如何处理呢？ 12345678 答案是写进程先获得锁。不仅如此，即使读请求先到锁等待队列，写请求后到，写锁也会插到读锁请求之前。这是因为MySQL的表级锁定对于读和写是有不同优先级设定的，默认情况下是写优先级要大于读优先级。所以，如果我们可以根据各自系统环境的差异决定读与写的优先级：通过执行命令SET LOW_PRIORITY_UPDATES=1，使该连接读比写的优先级高。如果我们的系统是一个以读为主，可以设置此参数，如果以写为主，则不用设置； 通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级。虽然上面方法都是要么更新优先，要么查询优先的方法，但还是可以用其来解决查询相对重要的应用（如用户登录系统）中，读锁等待严重的问题。另外，MySQL也提供了一种折中的办法来调节读写冲突，即给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一定获得锁的机会。 这里还要强调一点：一些需要长时间运行的查询操作，也会使写进程“饿死”，因此，应用中应尽量避免出现长时间运行的查询操作，不要总想用一条SELECT语句来解决问题，因为这种看似巧妙的SQL语句，往往比较复杂，执行时间较长，在可能的情况下可以通过使用中间表等措施对SQL语句做一定的“分解”，使每一步查询都能在较短时间完成，从而减少锁冲突。如果复杂查询不可避免，应尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行。 三、行级锁定行级锁定不是MySQL自己实现的锁定方式，而是由其他存储引擎自己所实现的，如广为大家所知的InnoDB存储引擎，以及MySQL的分布式存储引擎NDBCluster等都是实现了行级锁定。考虑到行级锁定君由各个存储引擎自行实现，而且具体实现也各有差别，而InnoDB是目前事务型存储引擎中使用最为广泛的存储引擎，所以这里我们就主要分析一下InnoDB的锁定特性。 1.InnoDB锁定模式及实现机制123考虑到行级锁定均由各个存储引擎自行实现，而且具体实现也各有差别，而InnoDB是目前事务型存储引擎中使用最为广泛的存储引擎，所以这里我们就主要分析一下InnoDB的锁定特性。总的来说，InnoDB的锁定机制和Oracle数据库有不少相似之处。InnoDB的行级锁定同样分为两种类型，共享锁和排他锁，而在锁定机制的实现过程中为了让行级锁定和表级锁定共存，InnoDB也同样使用了意向锁（表级锁定）的概念，也就有了意向共享锁和意向排他锁这两种。当一个事务需要给自己需要的某个资源加锁的时候，如果遇到一个共享锁正锁定着自己需要的资源的时候，自己可以再加一个共享锁，不过不能加排他锁。但是，如果遇到自己需要锁定的资源已经被一个排他锁占有之后，则只能等待该锁定释放资源之后自己才能获取锁定资源并添加自己的锁定。而意向锁的作用就是当一个事务在需要获取资源锁定的时候，如果遇到自己需要的资源已经被排他锁占用的时候，该事务可以需要锁定行的表上面添加一个合适的意向锁。如果自己需要一个共享锁，那么就在表上面添加一个意向共享锁。而如果自己需要的是某行（或者某些行）上面添加一个排他锁的话，则先在表上面添加一个意向排他锁。意向共享锁可以同时并存多个，但是意向排他锁同时只能有一个存在。所以，可以说InnoDB的锁定模式实际上可以分为四种：共享锁（S），排他锁（X），意向共享锁（IS）和意向排他锁（IX），我们可以通过以下表格来总结上面这四种所的共存逻辑关系： ​ 如果一个事务请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。意向锁是InnoDB自动加的，不需用户干预。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁（X)；对于普通SELECT语句，InnoDB不会加任何锁；事务可以通过以下语句显示给记录集加共享锁或排他锁。 12共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE ​ 用SELECT … IN SHARE MODE获得共享锁，主要用在需要数据依存关系时来确认某行记录是否存在，并确保没有人对这个记录进行UPDATE或者DELETE操作。​ 但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用SELECT… FOR UPDATE方式获得排他锁。 2.InnoDB行锁实现方式InnoDB行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。下面通过一些实际例子来加以说明。 1234（1）在不通过索引条件查询的时候，InnoDB确实使用的是表锁，而不是行锁。（2）由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。（3）当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。（4）即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。 3.间隙锁（Next-Key锁）当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。例：假如emp表中只有101条记录，其empid的值分别是 1,2,…,100,101，下面的SQL： 1mysql&gt; select * from emp where empid &gt; 100 for update; 是一个范围条件的检索，InnoDB不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁。InnoDB使用间隙锁的目的： 12（1）防止幻读，以满足相关隔离级别的要求。对于上面的例子，要是不使用间隙锁，如果其他事务插入了empid大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；（2）为了满足其恢复和复制的需要。 ​ 很显然，在使用范围条件检索并锁定记录时，即使某些不存在的键值也会被无辜的锁定，而造成在锁定的时候无法插入锁定键值范围内的任何数据。在某些场景下这可能会对性能造成很大的危害。​ 除了间隙锁给InnoDB带来性能的负面影响之外，通过索引实现锁定的方式还存在其他几个较大的性能隐患： 123（1）当Query无法利用索引的时候，InnoDB会放弃使用行级别锁定而改用表级别的锁定，造成并发性能的降低；（2）当Query使用的索引并不包含所有过滤条件的时候，数据检索使用到的索引键所只想的数据可能有部分并不属于该Query的结果集的行列，但是也会被锁定，因为间隙锁锁定的是一个范围，而不是具体的索引键；（3）当Query在使用索引定位数据的时候，如果使用的索引键一样但访问的数据行不同的时候（索引只是过滤条件的一部分），一样会被锁定。 ​ 因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。​ 还要特别说明的是，InnoDB除了通过范围条件加锁时使用间隙锁外，如果使用相等条件请求给一个不存在的记录加锁，InnoDB也会使用间隙锁。 4.死锁​ 上文讲过，MyISAM表锁是deadlock free的，这是因为MyISAM总是一次获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，当两个事务都需要获得对方持有的排他锁才能继续完成事务，这种循环锁等待就是典型的死锁。​ 在InnoDB的事务管理和锁定机制中，有专门检测死锁的机制，会在系统中产生死锁之后的很短时间内就检测到该死锁的存在。当InnoDB检测到系统中产生了死锁之后，InnoDB会通过相应的判断来选这产生死锁的两个事务中较小的事务来回滚，而让另外一个较大的事务成功完成。​ 那InnoDB是以什么来为标准判定事务的大小的呢？MySQL官方手册中也提到了这个问题，实际上在InnoDB发现死锁之后，会计算出两个事务各自插入、更新或者删除的数据量来判定两个事务的大小。也就是说哪个事务所改变的记录条数越多，在死锁中就越不会被回滚掉。​ 但是有一点需要注意的就是，当产生死锁的场景中涉及到不止InnoDB存储引擎的时候，InnoDB是没办法检测到该死锁的，这时候就只能通过锁定超时限制参数InnoDB_lock_wait_timeout来解决。​ 需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。通常来说，死锁都是应用设计的问题，通过调整业务流程、数据库对象设计、事务大小，以及访问数据库的SQL语句，绝大部分死锁都可以避免。下面就通过实例来介绍几种避免死锁的常用方法： 12345（1）在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。（2）在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能。（3）在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁，更新时再申请排他锁，因为当用户申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。（4）在REPEATABLE-READ隔离级别下，如果两个线程同时对相同条件记录用SELECT...FOR UPDATE加排他锁，在没有符合该条件记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁。这种情况下，将隔离级别改成READ COMMITTED，就可避免问题。（5）当隔离级别为READ COMMITTED时，如果两个线程都先执行SELECT...FOR UPDATE，判断是否存在符合条件的记录，如果没有，就插入记录。此时，只有一个线程能插入成功，另一个线程会出现锁等待，当第1个线程提交后，第2个线程会因主键重出错，但虽然这个线程出错了，却会获得一个排他锁。这时如果有第3个线程又来申请排他锁，也会出现死锁。对于这种情况，可以直接做插入操作，然后再捕获主键重异常，或者在遇到主键重错误时，总是执行ROLLBACK释放获得的排他锁。 5.什么时候使用表锁对于InnoDB表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们之所以选择InnoDB表的理由。但在个别特殊事务中，也可以考虑使用表级锁： 123（1）事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度。（2）事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。当然，应用中这两种事务不能太多，否则，就应该考虑使用MyISAM表了。 在InnoDB下，使用表锁要注意以下两点。 12（1）使用LOCK TABLES虽然可以给InnoDB加表级锁，但必须说明的是，表锁不是由InnoDB存储引擎层管理的，而是由其上一层──MySQL Server负责的，仅当autocommit=0、InnoDB_table_locks=1（默认设置）时，InnoDB层才能知道MySQL加的表锁，MySQL Server也才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁，否则，InnoDB将无法自动检测并处理这种死锁。（2）在用 LOCK TABLES对InnoDB表加锁时要注意，要将AUTOCOMMIT设为0，否则MySQL不会给表加锁；事务结束前，不要用UNLOCK TABLES释放表锁，因为UNLOCK TABLES会隐含地提交事务；COMMIT或ROLLBACK并不能释放用LOCK TABLES加的表级锁，必须用UNLOCK TABLES释放表锁。正确的方式见如下语句： 例如，如果需要写表t1并从表t读，可以按如下做： 12345SET AUTOCOMMIT=0;LOCK TABLES t1 WRITE, t2 READ, ...;[do something with tables t1 and t2 here];COMMIT;UNLOCK TABLES; 6.InnoDB行锁优化建议​ InnoDB存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面所带来的性能损耗可能比表级锁定会要更高一些，但是在整体并发处理能力方面要远远优于MyISAM的表级锁定的。当系统并发量较高的时候，InnoDB的整体性能和MyISAM相比就会有比较明显的优势了。但是，InnoDB的行级锁定同样也有其脆弱的一面，当我们使用不当的时候，可能会让InnoDB的整体性能表现不仅不能比MyISAM高，甚至可能会更差。（1）要想合理利用InnoDB的行级锁定，做到扬长避短，我们必须做好以下工作： 12345a)尽可能让所有的数据检索都通过索引来完成，从而避免InnoDB因为无法通过索引键加锁而升级为表级锁定；b)合理设计索引，让InnoDB在索引键上面加锁的时候尽可能准确，尽可能的缩小锁定范围，避免造成不必要的锁定而影响其他Query的执行；c)尽可能减少基于范围的数据检索过滤条件，避免因为间隙锁带来的负面影响而锁定了不该锁定的记录；d)尽量控制事务的大小，减少锁定的资源量和锁定时间长度；e)在业务环境允许的情况下，尽量使用较低级别的事务隔离，以减少MySQL因为实现事务隔离级别所带来的附加成本。 （2）由于InnoDB的行级锁定和事务性，所以肯定会产生死锁，下面是一些比较常用的减少死锁产生概率的小建议： 123a)类似业务模块中，尽可能按照相同的访问顺序来访问，防止产生死锁；b)在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；c)对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率。 （3）可以通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况： 12345678910mysql&gt; show status like &apos;InnoDB_row_lock%&apos;;+-------------------------------+-------+| Variable_name | Value |+-------------------------------+-------+| InnoDB_row_lock_current_waits | 0 || InnoDB_row_lock_time | 0 || InnoDB_row_lock_time_avg | 0 || InnoDB_row_lock_time_max | 0 || InnoDB_row_lock_waits | 0 |+-------------------------------+-------+ InnoDB 的行级锁定状态变量不仅记录了锁定等待次数，还记录了锁定总时长，每次平均时长，以及最大时长，此外还有一个非累积状态量显示了当前正在等待锁定的等待数量。对各个状态量的说明如下：InnoDB_row_lock_current_waits：当前正在等待锁定的数量；InnoDB_row_lock_time：从系统启动到现在锁定总时间长度；InnoDB_row_lock_time_avg：每次等待所花平均时间；InnoDB_row_lock_time_max：从系统启动到现在等待最常的一次所花的时间；InnoDB_row_lock_waits：系统启动后到现在总共等待的次数；对于这5个状态变量，比较重要的主要是InnoDB_row_lock_time_avg（等待平均时长），InnoDB_row_lock_waits（等待总次数）以及InnoDB_row_lock_time（等待总时长）这三项。尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手指定优化计划。如果发现锁争用比较严重，如InnoDB_row_lock_waits和InnoDB_row_lock_time_avg的值比较高，还可以通过设置InnoDB Monitors 来进一步观察发生锁冲突的表、数据行等，并分析锁争用的原因。锁冲突的表、数据行等，并分析锁争用的原因。具体方法如下： 1mysql&gt; create table InnoDB_monitor(a INT) engine=InnoDB; 然后就可以用下面的语句来进行查看： 1mysql&gt; show engine InnoDB status; 监视器可以通过发出下列语句来停止查看： 1mysql&gt; drop table InnoDB_monitor; 设置监视器后，会有详细的当前锁等待的信息，包括表名、锁类型、锁定记录的情况等，便于进行进一步的分析和问题的确定。可能会有读者朋友问为什么要先创建一个叫InnoDB_monitor的表呢？因为创建该表实际上就是告诉InnoDB我们开始要监控他的细节状态了，然后InnoDB就会将比较详细的事务以及锁定信息记录进入MySQL的errorlog中，以便我们后面做进一步分析使用。打开监视器以后，默认情况下每15秒会向日志中记录监控的内容，如果长时间打开会导致.err文件变得非常的巨大，所以用户在确认问题原因之后，要记得删除监控表以关闭监视器，或者通过使用“–console”选项来启动服务器以关闭写日志文件。查看更多：MySQL优化MySQL各存储引擎MySQL事务MySQL索引类型 参考资料：《MySQL性能优化与架构设计》《深入浅出MySQL》 出处：https://luyucheng.cnblogs.com]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL四种常见数据库引擎]]></title>
    <url>%2F2020%2F01%2F20%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200120%2F</url>
    <content type="text"><![CDATA[四种MySQL存储引擎 [toc] 前言数据库存储引擎是数据库底层软件组织，数据库管理系统（DBMS）使用数据引擎进行创建、查询、更新和删除数据。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎，还可以 获得特定的功能。现在许多不同的数据库管理系统都支持多种不同的数据引擎。MySQL的核心就是存储引擎。 存储引擎查看MySQL给开发者提供了查询存储引擎的功能，我这里使用的是MySQL5.1，可以使用： SHOW ENGINES 命令来查看MySQL使用的引擎，命令的输出为（我用的Navicat Premium）： 看到MySQL给用户提供了这么多存储引擎，包括处理事务安全表的引擎和出来了非事物安全表的引擎。 如果要想查看数据库默认使用哪个引擎，可以通过使用命令： show variables like ‘%storage_engine%’; 来查看，查询结果为： ​ 在MySQL中，不需要在整个服务器中使用同一种存储引擎，针对具体的要求，可以对每一个表使用不同的存储引擎。Support列的值表示某种引擎是否能使用：YES表示可以使用、NO表示不能使用、DEFAULT表示该引擎为当前默认的存储引擎 。下面来看一下其中几种常用的引擎。 InnoDB存储引擎InnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键，上图也看到了，InnoDB是默认的MySQL引擎。InnoDB主要特性有： 1234567891、InnoDB给MySQL提供了具有提交、回滚和崩溃恢复能力的事物安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合2、InnoDB是为处理巨大数据量的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系型数据库引擎锁不能匹敌的3、InnoDB存储引擎完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上4、InnoDB支持外键完整性约束，存储表中的数据时，每张表的存储都按主键顺序存放，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6字节的ROWID，并以此作为主键5、InnoDB被用在众多需要高性能的大型数据库站点上 InnoDB不创建目录，使用InnoDB时，MySQL将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件 MyISAM存储引擎MyISAM基于ISAM存储引擎，并对其进行扩展。它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。MyISAM拥有较高的插入、查询速度，但不支持事物。MyISAM主要特性有： 12345678910111213141516171819202122231、大文件（达到63位文件长度）在支持大文件的文件系统和操作系统上被支持2、当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块，以及若下一个块被删除，就扩展到下一块自动完成3、每个MyISAM表最大索引数是64，这可以通过重新编译来改变。每个索引最大的列数是164、最大的键长度是1000字节，这也可以通过编译来改变，对于键长度超过250字节的情况，一个超过1024字节的键将被用上5、BLOB和TEXT列可以被索引6、NULL被允许在索引的列中，这个值占每个键的0~1个字节7、所有数字键值以高字节优先被存储以允许一个更高的索引压缩8、每个MyISAM类型的表都有一个AUTO_INCREMENT的内部列，当INSERT和UPDATE操作的时候该列被更新，同时AUTO_INCREMENT列将被刷新。所以说，MyISAM类型表的AUTO_INCREMENT列更新比InnoDB类型的AUTO_INCREMENT更快9、可以把数据文件和索引文件放在不同目录10、每个字符列可以有不同的字符集11、有VARCHAR的表可以固定或动态记录长度12、VARCHAR和CHAR列可以多达64KB 使用MyISAM引擎创建数据库，将产生3个文件。文件的名字以表名字开始，扩展名之处文件类型：frm文件存储表定义、数据文件的扩展名为.MYD（MYData）、索引文件的扩展名时.MYI（MYIndex） MEMORY存储引擎MEMORY存储引擎将表中的数据存储到内存中，未查询和引用其他表数据提供快速访问。MEMORY主要特性有： 12345678910111213141516171、MEMORY表的每个表可以有多达32个索引，每个索引16列，以及500字节的最大键长度2、MEMORY存储引擎执行HASH和BTREE缩影3、可以在一个MEMORY表中有非唯一键值4、MEMORY表使用一个固定的记录长度格式5、MEMORY不支持BLOB或TEXT列6、MEMORY支持AUTO_INCREMENT列和对可包含NULL值的列的索引7、MEMORY表在所由客户端之间共享（就像其他任何非TEMPORARY表）8、MEMORY表内存被存储在内存中，内存是MEMORY表和服务器在查询处理时的空闲中，创建的内部表共享9、当不再需要MEMORY表的内容时，要释放被MEMORY表使用的内存，应该执行DELETE FROM或TRUNCATE TABLE，或者删除整个表（使用DROP TABLE） 存储引擎的选择不同的存储引擎都有各自的特点，以适应不同的需求，如下表所示： 如果要提供提交、回滚、崩溃恢复能力的事物安全（ACID兼容）能力，并要求实现并发控制，InnoDB是一个好的选择 如果数据表主要用来插入和查询记录，则MyISAM引擎能提供较高的处理效率 如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存中的Memory引擎，MySQL中使用该引擎作为临时表，存放查询的中间结果 如果只有INSERT和SELECT操作，可以选择Archive，Archive支持高并发的插入操作，但是本身不是事务安全的。Archive非常适合存储归档数据，如记录日志信息可以使用Archive 使用哪一种引擎需要灵活选择，一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求，使用合适的存储引擎，将会提高整个数据库的性能 作者：一行代码一首诗链接：https://www.jianshu.com/p/4bb9f78b4f6d来源：简书]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String、StringBuffer与StringBuilder之间区别]]></title>
    <url>%2F2020%2F01%2F18%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200118%2F</url>
    <content type="text"><![CDATA[String、StringBuffer与StringBuilder之间区别 String StringBuffer StringBuilder String的值是不可变的，这就导致每次对String的操作都会生成新的String对象，不仅效率低下，而且浪费大量优先的内存空间 StringBuffer是可变类，和线程安全的字符串操作类，任何对它指向的字符串的操作都不会产生新的对象。每个StringBuffer对象都有一定的缓冲区容量，当字符串大小没有超过容量时，不会分配新的容量，当字符串大小超过容量时，会自动增加容量 可变类，速度更快 不可变 可变 可变 线程安全 线程不安全 多线程操作字符串 单线程操作字符串 一、Java String 类——String字符串常量​ 简要的说， String 类型和 StringBuffer 类型的主要性能区别其实在于 String 是不可变的对象, 因此在每次对 String 类型进行改变的时候其实都等同于生成了一个新的 String 对象，然后将指针指向新的 String 对象，这样不仅效率低下，而且大量浪费有限的内存空间，所以经常改变内容的字符串最好不要用 String 。因为每次生成对象都会对系统性能产生影响，特别当内存中无引用对象多了以后， JVM 的 GC 就会开始工作，那速度是一定会相当慢的。 我们来看一下这张对String操作时内存变化的图： ​ 我们可以看到，初始String值为“hello”，然后在这个字符串后面加上新的字符串“world”，这个过程是需要重新在栈堆内存中开辟内存空间的，最终得到了“hello world”字符串也相应的需要开辟内存空间，这样短短的两个字符串，却需要开辟三次内存空间，不得不说这是对内存空间的极大浪费。为了应对经常性的字符串相关的操作，就需要使用Java提供的其他两个操作字符串的类——StringBuffer类和StringBuild类来对此种变化字符串进行处理。 二、StringBuffer 和 StringBuilder 类——StringBuffer、StringBuilder字符串变量StringBuffer 字符串变量（线程安全）StringBuilder 字符串变量（非线程安 当对字符串进行修改的时候，特别是字符串对象经常改变的情况下，需要使用 StringBuffer 和 StringBuilder 类。 和 String 类不同的是，StringBuffer 和 StringBuilder 类的对象能够被多次的修改，并且不产生新的未使用对象。 StringBuilder 类在 Java 5 中被提出，它和 StringBuffer 之间的最大不同在于 StringBuilder 的方法不是线程安全的（不能同步访问）。 由于 StringBuilder 相较于 StringBuffer 有速度优势，所以多数情况下建议使用 StringBuilder 类。然而在应用程序要求线程安全的情况下，则必须使用 StringBuffer 类。 三者的继承结构 三者的区别： （1）字符修改上的区别（主要，见上面分析） （2）初始化上的区别，String可以空赋值，后者不行，报错 ①String String s = null; String s = “abc”; ②StringBuffer StringBuffer s = null; //结果警告：Null pointer access: The variable result can only be null at this location StringBuffer s = new StringBuffer();//StringBuffer对象是一个空的对象 StringBuffer s = new StringBuffer(“abc”);//创建带有内容的StringBuffer对象,对象的内容就是字符串” 小结：（1）如果要操作少量的数据用 String； ​ （2）多线程操作字符串缓冲区下操作大量数据 StringBuffer； ​ （3）单线程操作字符串缓冲区下操作大量数据 StringBuilder。 而在某些特别情况下， String 对象的字符串拼接其实是被 JVM 解释成了 StringBuffer 对象的拼接，所以这些时候 String 对象的速度并不会比 StringBuffer 对象慢，而特别是以下的字符串对象生成中， String 效率是远要比 StringBuffer 快的： 12String S1 = &quot;This is only a&quot; + &quot; simple&quot; + &quot; test&quot;;StringBuffer Sb = new StringBuffer(&quot;This is only a&quot;).append(&quot; simple&quot;).append(&quot; test&quot;); 你会很惊讶的发现，生成 String S1 对象的速度简直太快了，而这个时候 StringBuffer 居然速度上根本一点都不占优势。其实这是 JVM 的一个把戏，在 JVM 眼里，这个 12String S1 = “This is only a” + “ simple” + “test”; 其实就是：String S1 = “This is only a simple test”; 所以当然不需要太多的时间了。但大家这里要注意的是，如果你的字符串是来自另外的 String 对象的话，速度就没那么快了，譬如： 1234String S2 = “This is only a”;String S3 = “ simple”;String S4 = “ test”;String S1 = S2 +S3 + S4; 这时候 JVM 会规规矩矩的按照原来的方式去做 在大部分情况下 StringBuffer &gt; StringStringBufferJava.lang.StringBuffer线程安全的可变字符序列。一个类似于 String 的字符串缓冲区，但不能修改。虽然在任意时间点上它都包含某种特定的字符序列，但通过某些方法调用可以改变该序列的长度和内容。可将字符串缓冲区安全地用于多个线程。可以在必要时对这些方法进行同步，因此任意特定实例上的所有操作就好像是以串行顺序发生的，该顺序与所涉及的每个线程进行的方法调用顺序一致。StringBuffer 上的主要操作是 append 和 insert 方法，可重载这些方法，以接受任意类型的数据。每个方法都能有效地将给定的数据转换成字符串，然后将该字符串的字符追加或插入到字符串缓冲区中。append 方法始终将这些字符添加到缓冲区的末端；而 insert 方法则在指定的点添加字符。例如，如果 z 引用一个当前内容是“start”的字符串缓冲区对象，则此方法调用 z.append(“le”) 会使字符串缓冲区包含“startle”，而 z.insert(4, “le”) 将更改字符串缓冲区，使之包含“starlet”。在大部分情况下 StringBuilder &gt; StringBuffer java.lang.StringBuilderjava.lang.StringBuilder一个可变的字符序列是5.0新增的。此类提供一个与 StringBuffer 兼容的 API，但不保证同步。该类被设计用作 StringBuffer 的一个简易替换，用在字符串缓冲区被单个线程使用的时候（这种情况很普遍）。如果可能，建议优先采用该类，因为在大多数实现中，它比 StringBuffer 要快。两者的方法基本相同。 作者：每次上网冲杯Java时，都能看到关于String无休无止的争论。还是觉得有必要让这个讨厌又很可爱的String美眉，赤裸裸的站在我们这些Java色狼面前了。嘿嘿…. 众所周知，String是由字符组成的串，在程序中使用频率很高。Java中的String是一个类，而并非基本数据类型。 不过她却不是普通的类哦！！！ 【镜头1】 String对象的创建 1、关于类对象的创建，很普通的一种方式就是利用构造器，String类也不例外：String s=new String(“Hello world”); 问题是参数”Hello world”是什么东西，也是字符串对象吗?莫非用字符串对象创建一个字符串对象? 2、当然，String类对象还有一种大家都很喜欢的创建方式：String s=”Hello world”; 但是有点怪呀，怎么与基本数据类型的赋值操作（int i=1）很像呀? 在开始解释这些问题之前，我们先引入一些必要的知识: ★ Java class文件结构 和常量池 我们都知道，Java程序要运行，首先需要编译器将源代码文件编译成字节码文件(也就是.class文件)。然后在由JVM解释执行。 class文件是8位字节的二进制流 。这些二进制流的涵义由一些紧凑的有意义的项组成。比如class字节流中最开始的4个字节组成的项叫做魔数 (magic)，其意义在于分辨class文件(值为0xCAFEBABE)与非class文件。class字节流大致结构如下图左侧。 ​ 其中，在class文件中有一个非常重要的项——常量池 。这个常量池专门放置源代码中的符号信息(并且不同的符号信息放置在不同标志的常量表中)。如上图右侧是HelloWorld代码中的常量表（HelloWorld代码如下），其中有四个不同类型的常量表(四个不同的常量池入口)。关于常量池的具体细节，请参照我的博客《Class文件内容及常量池 》 Java代码 12345public class HelloWorld&#123; void hello()&#123; System.out.println("Hello world"); &#125; &#125; ​ 通过上图可见，代码中的”Hello world”字符串字面值被编译之后，可以清楚的看到存放在了class常量池中的字符串常量表中(上图右侧红框区域)。 ★ JVM运行class文件 源代码编译成class文件之后，JVM就要运行这个class文件。它首先会用类装载器加载进class文件。然后需要创建许多内存[数据结构](http://lib.csdn.net/base/datastructure)来存放class文件中的字节数据。比如class文件对应的类信息数据、常量池结构、方法中的二进制指令序列、类方法与字段的描述信息等等。当然，在运行的时候，还需要为方法创建栈帧等。这么多的内存结构当然需要管理，JVM会把这些东西都组织到几个“**运行时数据区** ”中。这里面就有我们经常说的“**方法区** ”、“**堆** ”、“**Java栈** ”等。**详细请参见我的博客《[Java 虚拟机体系结构](http://www.iteye.com/blog/676235) 》 。** 上面我们提到了，在Java源代码中的每一个字面值字符串，都会在编译成class文件阶段，形成标志号 为8(CONSTANT_String_info)的常量表 。 当JVM加载 class文件的时候，会为对应的常量池建立一个内存数据结构，并存放在方法区中。同时JVM会自动为CONSTANT_String_info常量表中 的字符串常量字面值 在堆中 创建 新的String对象(intern字符串 对象，又叫拘留字符串对象)。然后把CONSTANT_String_info常量表的入口地址转变成这个堆中String对象的直接地址(常量池解 析)。 这里很关键的就是这个**拘留字符串对象** 。源代码中所有相同字面值的字符串常量只可能建立唯一一个拘留字符串对象。 实际上JVM是通过一个记录了拘留字符串引用的内部数据结构来维持这一特性的。在Java程序中，可以调用String的intern()方法来使得一个常规字符串对象成为拘留字符串对象。我们会在后面介绍这个方法的。 ★ 操作码助忆符指令 有了上面阐述的两个知识前提，下面我们将根据二进制指令来区别两种字符串对象的创建方式： (1) String s=new String(“Hello world”);编译成class文件后的指令(在myeclipse中查看):Class字节码指令集代码 123450 new java.lang.String [15] //在堆中分配一个String类对象的空间，并将该对象的地址堆入操作数栈。 3 dup //复制操作数栈顶数据，并压入操作数栈。该指令使得操作数栈中有两个String对象的引用值。 4 ldc &lt;String &quot;Hello world&quot;&gt; [17] //将常量池中的字符串常量&quot;Hello world&quot;指向的堆中拘留String对象的地址压入操作数栈 6 invokespecial java.lang.String(java.lang.String) [19] //调用String的初始化方法，弹出操作数栈栈顶的两个对象地址，用拘留String对象的值初始化new指令创建的String对象，然后将这个对象的引用压入操作数栈 9 astore_1 [s] // 弹出操作数栈顶数据存放在局部变量区的第一个位置上。此时存放的是new指令创建出的，已经被初始化的String对象的地址 （此时的栈顶值弹出存入局部变量中去)。 注意：【这里有个dup指令。其作用就是复制之前分配的Java.lang.String空间的引用并压入栈顶。那么这里为什么需要这样么做呢？因为invokespecial指令通过[15]这个常量池入口寻找到了java.lang.String()构造方法，构造方法虽然找到了。但是必须还得知道是谁的构造方法，所以要将之前分配的空间的应用压入栈顶让invokespecial命令应用才知道原来这个构造方法是刚才创建的那个引用的，调用完成之后将栈顶的值弹出。之后调用astore_1将此时的栈顶值弹出存入局部变量中去。】 事实上，在运行这段指令之前，JVM就已经为&quot;Hello world&quot;在堆中创建了一个拘留字符串( 值得注意的是：如果源程序中还有一个&quot;Hello world&quot;字符串常量，那么他们都对应了同一个堆中的拘留字符串)。然后用这个拘留字符串的值来初始化堆中用new指令创建出来的新的String对象，局部变量s实际上存储的是new出来的堆对象地址。 大家注意了，此时在JVM管理的堆中，有两个相同字符串值的String对象：一个是拘留字符串对象，一个是new新建的字符串对象。如果还有一条创建语句String s1=new String(&quot;Hello world&quot;)；堆中有几个值为&quot;Hello world&quot;的字符串呢? 答案是3个，大家好好想想为什么吧！ (2)将String s=”Hello world”;编译成class文件后的指令:Class字节码指令集代码 120 ldc &lt;String "Hello world"&gt; [15]//将常量池中的字符串常量"Hello world"指向的堆中拘留String对象的地址压入操作数栈 2 astore_1 [str] // 弹出操作数栈顶数据存放在局部变量区的第一个位置上。此时存放的是拘留字符串对象在堆中的地址 ​ 和上面的创建指令有很大的不同，局部变量s存储的是早已创建好的拘留字符串的堆地址(没有new 的对象了)。 大家好好想想，如果还有一条穿件语句String s1=”Hello word”；此时堆中有几个值为”Hello world”的字符串呢?答案是1个。那么局部变量s与s1存储的地址是否相同呢？ 呵呵, 这个你应该知道了吧。 ★ 镜头总结： String类型脱光了其实也很普通。真正让她神秘的原因就在于CONSTANT_String_info常量表 和拘留字符串对象 的存在。现在我们可以解决江湖上的许多纷争了。 【 纷争1】关于字符串相等关系的争论 Java代码 123456789//代码1 String sa=new String("Hello world"); String sb=new String("Hello world"); System.out.println(sa==sb); // false //代码2 String sc="Hello world"; String sd="Hello world"; System.out.println(sc==sd); // true ​ 代码1中局部变量sa,sb中存储的是JVM在堆中new出来的两个String对象的内存地址。虽然这两个String对象的值(char[]存放的字符序列)都是”Hello world”。 因此”==”比较的是两个不同的堆地址。代码2中局部变量sc,sd中存储的也是地址，但却都是常量池中”Hello world”指向的堆的唯一的那个拘留字符串对象的地址 。自然相等了。 【纷争2】 字符串“+”操作的内幕 Java代码 1234567891011//代码1 String sa = "ab"; String sb = "cd"; String sab=sa+sb; String s="abcd"; System.out.println(sab==s); // false //代码2 String sc="ab"+"cd"; String sd="abcd"; System.out.println(sc==sd); //true 代码1中局部变量sa,sb存储的是堆中两个拘留字符串对象的地址。而当执行sa+sb时，JVM首先会在堆中创建一个StringBuilder类，同时用sa指向的拘留字符串对象完成初始化，然后调用append方法完成对sb所指向的拘留字符串的合并操作，接着调用StringBuilder的toString()方法在堆中创建一个String对象，最后将刚生成的String对象的堆地址存放在局部变量sab中。而局部变量s存储的是常量池中&quot;abcd&quot;所对应的拘留字符串对象的地址。 sab与s地址当然不一样了。这里要注意了，代码1的堆中实际上有五个字符串对象：三个拘留字符串对象、一个String对象和一个StringBuilder对象。 代码2中&quot;ab&quot;+&quot;cd&quot;会直接在编译期就合并成常量&quot;abcd&quot;， 因此相同字面值常量&quot;abcd&quot;所对应的是同一个拘留字符串对象，自然地址也就相同。 【镜头二】 String三姐妹(String,StringBuffer,StringBuilder) String扒的差不多了。但他还有两个妹妹StringBuffer,StringBuilder长的也不错哦！我们也要下手了： String(大姐，出生于JDK1.0时代) 不可变字符序列 StringBuffer(二姐，出生于JDK1.0时代) 线程安全的可变字符序列 StringBuilder(小妹，出生于JDK1.5时代) 非线程安全的可变字符序列 ★StringBuffer与String的可变性问题。 我们先看看这两个类的部分源代码： Java代码 12345678910111213141516//String public final class String &#123; private final char value[]; public String(String original) &#123; // 把原字符串original切分成字符数组并赋给value[]; &#125; &#125; //StringBuffer public final class StringBuffer extends AbstractStringBuilder &#123; char value[]; //继承了父类AbstractStringBuilder中的value[] public StringBuffer(String str) &#123; super(str.length() + 16); //继承父类的构造器，并创建一个大小为str.length()+16的value[]数组 append(str); //将str切分成字符序列并加入到value[]中 &#125; &#125; 很显然，String和StringBuffer中的value[]都用于存储字符序列。但是, (1) String中的是常量(final)数组，只能被赋值一次。​ 比如：new String(“abc”)使得value[]={‘a’,’b’,’c’}(查看jdk String 就是这么实现的)，之后这个String对象中的value[]再也不能改变了。这也正是大家常说的，String是不可变的原因 。​ 注意：这个对初学者来说有个误区，有人说String str1=new String(“abc”); str1=new String(“cba”);不是改变了字符串str1吗？那么你有必要先搞懂对象引用和对象本身的区别。这里我简单的说明一下，对象本身指的是存放在堆空间中的该对象的实例数据(非静态非常量字段)。而对象引用指的是堆中对象本身所存放的地址，一般方法区和Java栈中存储的都是对象引用，而非对象本身的数据。 (2) StringBuffer中的value[]就是一个很普通的数组，而且可以通过append()方法将新字符串加入value[]末尾。这样也就改变了value[]的内容和大小了。比如：new StringBuffer(&quot;abc&quot;)使得value[]={&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;&apos;,&apos;&apos;...}(注意构造的长度是str.length()+16)。如果再将这个对象append(&quot;abc&quot;)，那么这个对象中的value[]={&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;&apos;....}。这也就是为什么大家说 StringBuffer是可变字符串 的涵义了。从这一点也可以看出，StringBuffer中的value[]完全可以作为字符串的缓冲区功能。其累加性能是很不错的，在后面我们会进行比较。 ​ 总结，讨论String和StringBuffer可不可变。本质上是指对象中的value[]字符数组可不可变，而不是对象引用可不可变。 ★StringBuffer与StringBuilder的线程安全性问题 StringBuffer和StringBuilder可以算是双胞胎了，这两者的方法没有很大区别。但在线程安全性方面，StringBuffer允许多线程进行字符操作。这是因为在源代码中StringBuffer的很多方法都被关键字synchronized 修饰了，而StringBuilder没有。 有多线程编程经验的程序员应该知道synchronized。这个关键字是为线程同步机制 设定的。我简要阐述一下synchronized的含义： 每一个类对象都对应一把锁，当某个线程A调用类对象O中的synchronized方法M时，必须获得对象O的锁才能够执行M方法，否则线程A阻塞。一旦线程A开始执行M方法，将独占对象O的锁。使得其它需要调用O对象的M方法的线程阻塞。只有线程A执行完毕，释放锁后。那些阻塞线程才有机会重新调用M方法。这就是解决线程同步问题的锁机制。 了解了synchronized的含义以后，大家可能都会有这个感觉。多线程编程中StringBuffer比StringBuilder要安全多了 ，事实确实如此。如果有多个线程需要对同一个字符串缓冲区进行操作的时候，StringBuffer应该是不二选择。 注意：是不是String也不安全呢？事实上不存在这个问题，String是不可变的。线程对于堆中指定的一个String对象只能读取，无法修改。试问：还有什么不安全的呢？ ★String和StringBuffer的效率问题（这可是个热门话题呀!） 首先说明一点：StringBuffer和StringBuilder可谓双胞胎，StringBuilder是1.5新引入的，其前身就是StringBuffer。StringBuilder的效率比StringBuffer稍高，如果不考虑线程安全，StringBuilder应该是首选。另外，JVM运行程序主要的时间耗费是在创建对象和回收对象上。 我们用下面的代码运行1W次字符串的连接操作，测试String,StringBuffer所运行的时间。 Java代码 123456789101112//测试代码 public class RunTime&#123; public static void main(String[] args)&#123; ● 测试代码位置1 long beginTime=System.currentTimeMillis(); for(int i=0;i&lt;10000;i++)&#123; ● 测试代码位置2 &#125; long endTime=System.currentTimeMillis(); System.out.println(endTime-beginTime); &#125; &#125; (1) String常量与String变量的”+”操作比较 ▲测试①代码： (测试代码位置1) String str=””; (测试代码位置2) str=”Heart”+”Raid”; [耗时： 0ms] ▲测试②代码 (测试代码位置1) String s1=&quot;Heart&quot;; String s2=&quot;Raid&quot;; String str=&quot;&quot;; (测试代码位置2) str=s1+s2; [耗时： 15—16ms] 结论：String常量的“+连接” 稍优于 String变量的“+连接”。 原因：测试①的&quot;Heart&quot;+&quot;Raid&quot;在编译阶段就已经连接起来，形成了一个字符串常量&quot;HeartRaid&quot;，并指向堆中的拘留字符串对象。运行时只需要将&quot;HeartRaid&quot;指向的拘留字符串对象地址取出1W次，存放在局部变量str中。这确实不需要什么时间。 测试②中局部变量s1和s2存放的是两个不同的拘留字符串对象的地址。然后会通过下面三个步骤完成“+连接”： 1、StringBuilder temp=new StringBuilder(s1)， 2、temp.append(s2); 3、str=temp.toString(); 我们发现，虽然在中间的时候也用到了append()方法，但是在开始和结束的时候分别创建了StringBuilder和String对象。可想而知：调用1W次，是不是就创建了1W次这两种对象呢？不划算。 ​ 但是，String变量的”+连接”操作比String常量的”+连接”操作使用的更加广泛。 这一点是不言而喻的。 (2)String对象的”累+”连接操作与StringBuffer对象的append()累和连接操作比较。 ▲测试①代码： (代码位置1) String s1=”Heart”; String s=””; (代码位置2) s=s+s1; [耗时： 4200—4500ms] ▲测试②代码 (代码位置1) String s1=&quot;Heart&quot;; StringBuffer sb=new StringBuffer(); (代码位置2) sb.append(s1); [耗时： 0ms(当循环100000次的时候，耗时大概16—31ms)] 结论：大量字符串累加时，StringBuffer的append()效率远好于String对象的&quot;累+&quot;连接 原因：测试① 中的s=s+s1，JVM会利用首先创建一个StringBuilder，并利用append方法完成s和s1所指向的字符串对象值的合并操作，接着调用StringBuilder的 toString()方法在堆中创建一个新的String对象，其值为刚才字符串的合并结果。而局部变量s指向了新创建的String对象。 ​ 因为String对象中的value[]是不能改变的，每一次合并后字符串值都需要创建一个新的String对象来存放。循环1W次自然需要创建1W个String对象和1W个StringBuilder对象，效率低就可想而知了。​ 测试②中sb.append(s1);只需要将自己的value[]数组不停的扩大来存放s1即可。循环过程中无需在堆中创建任何新的对象。效率高就不足为奇了。 ★ 镜头总结： (1) 在编译阶段就能够确定的字符串常量，完全没有必要创建String或StringBuffer对象。直接使用字符串常量的”+”连接操作效率最高。 (2) StringBuffer对象的append效率要高于String对象的”+”连接操作。 (3) 不停的创建对象是程序低效的一个重要原因。那么相同的字符串值能否在堆中只创建一个String对象那。显然拘留字符串能够做到这一点，除了程序中的字符串常量会被JVM自动创建拘留字符串之外，调用String的intern()方法也能做到这一点。当调用intern()时，如果常量池中已经有了当前String的值，那么返回这个常量指向拘留对象的地址。如果没有，则将String值加入常量池中，并创建一个新的拘留字符串对象。 参照： https://www.cnblogs.com/goody9807/p/6516374.html https://blog.csdn.net/u011702479/article/details/82262823 https://blog.csdn.net/weixin_41101173/article/details/79677982 https://blog.csdn.net/itchuxuezhe_yang/article/details/89966303]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化]]></title>
    <url>%2F2019%2F10%2F13%2F%E5%85%B6%E5%AE%83%2FMySQL%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[MySQL优化 表关联查询时务必遵循 小表驱动大表 原则； 使用查询语句 where 条件时，不允许出现 函数，否则索引会失效； 使用单表查询时，相同字段尽量不要用 OR，因为可能导致索引失效，比如：SELECT * FROM table WHERE name = &#39;手机&#39; OR name = &#39;电脑&#39;，可以使用 UNION 替代； LIKE 语句不允许使用 % 开头，否则索引会失效； 组合索引一定要遵循 从左到右 原则，否则索引会失效；比如：SELECT * FROM table WHERE name = &#39;张三&#39; AND age = 18，那么该组合索引必须是 name,age 形式； 索引不宜过多，根据实际情况决定，尽量不要超过 10 个； 每张表都必须有 主键，达到加快查询效率的目的； 分表，可根据业务字段尾数中的个位或十位或百位（以此类推）做表名达到分表的目的； 分库，可根据业务字段尾数中的个位或十位或百位（以此类推）做库名达到分库的目的； 表分区，类似于硬盘分区，可以将某个时间段的数据放在分区里，加快查询速度，可以配合 分表 + 表分区 结合使用； 神器EXPLAIN 语句EXPLAIN 显示了 MySQL 如何使用索引来处理 SELECT 语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句。 使用方法，在 SELECT 语句前加上 EXPLAIN 即可，如： 1EXPLAIN SELECT * FROM tb_item WHERE cid IN (SELECT id FROM tb_item_cat) id： SELECT 识别符。这是 SELECT 的查询序列号 select_type： SELECT类型,可以为以下任何一种 SIMPLE: 简单 SELECT(不使用 UNION 或子查询) PRIMARY: 最外面的 SELECT UNION: UNION 中的第二个或后面的 SELECT 语句 DEPENDENT UNION: UNION 中的第二个或后面的 SELECT 语句,取决于外面的查询 UNION RESULT: UNION 的结果 SUBQUERY: 子查询中的第一个 SELECT DEPENDENT SUBQUERY: 子查询中的第一个 SELECT,取决于外面的查询 DERIVED: 导出表的 SELECT(FROM 子句的子查询) table： 输出的行所引用的表 partitions： 表分区 type： 联接类型。下面给出各种联接类型，按照 从最佳类型到最坏类型 进行排序 system: 表仅有一行(=系统表)。这是 const 联接类型的一个特例。 const: 表最多有一个匹配行,它将在查询开始时被读取。因为仅有一行,在这行的列值可被优化器剩余部分认为是常数。const 表很快,因为它们只读取一次! eq_ref: 对于每个来自于前面的表的行组合, 从该表中读取一行。这可能是最好的联接类型, 除了 const 类型。 ref: 对于每个来自于前面的表的行组合, 所有有匹配索引值的行将从这张表中读取。 ref_or_null: 该联接类型如同 ref,但是添加了 MySQL 可以专门搜索包含 NULL 值的行。 index_merge: 该联接类型表示使用了索引合并优化方法。 unique_subquery: 该类型替换了下面形式的 IN 子查询的 ref: value IN (SELECT primary_key FROM single_table WHERE some_expr) unique_subquery 是一个索引查找函数, 可以完全替换子查询, 效率更高。 index_subquery: 该联接类型类似于 unique_subquery。可以替换 IN 子查询, 但只适合下列形式的子查询中的非唯一索引: value IN (SELECT key_column FROM single_table WHERE some_expr) range: 只检索给定范围的行,使用一个索引来选择行。 index: 该联接类型与 ALL 相同,除了只有索引树被扫描。这通常比 ALL 快,因为索引文件通常比数据文件小。 ALL: 对于每个来自于先前的表的行组合, 进行完整的表扫描。 possible_keys： 指出 MySQL 能使用哪个索引在该表中找到行 key： 显示 MySQL 实际决定使用的键(索引)。如果没有选择索引, 键是 NULL。 key_len： 显示 MySQL 决定使用的键长度。如果键是 NULL, 则长度为 NULL。 ref： 显示使用哪个列或常数与 key 一起从表中选择行。 rows： 显示 MySQL 认为它执行查询时必须检查的行数。多行之间的数据相乘可以估算要处理的行数。 filtered： 显示了通过条件过滤出的行数的百分比估计值。 Extra： 该列包含 MySQL 解决查询的详细信息 Distinct: MySQL 发现第 1 个匹配行后,停止为当前的行组合搜索更多的行。 Not exists: MySQL 能够对查询进行 LEFT JOIN 优化, 发现 1 个匹配 LEFT JOIN 标准的行后, 不再为前面的的行组合在该表内检查更多的行。 range checked for each record (index map: #): MySQL 没有发现好的可以使用的索引, 但发现如果来自前面的表的列值已知, 可能部分索引可以使用。 Using filesort: MySQL 需要额外的一次传递, 以找出如何按排序顺序检索行。 Using index: 从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。 Using temporary: 为了解决查询, MySQL 需要创建一个临时表来容纳结果。 Using where: WHERE 子句用于限制哪一个行匹配下一个表或发送到客户。 Using sort_union(…), Using union(…), Using intersect(…): 这些函数说明如何为 index_merge 联接类型合并索引扫描。 Using index for group-by: 类似于访问表的 Using index 方式,Using index for group-by 表示 MySQL 发现了一个索引,可以用来查询 GROUP BY 或 DISTINCT 查询的所有列, 而不要额外搜索硬盘访问实际的表。]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo面试题整理]]></title>
    <url>%2F2018%2F08%2F27%2F%E9%9D%A2%E8%AF%95%2FDubbo%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[Dubbo面试题整理 [toc] 1.Dubbo是什么？​ Dubbo 是一个分布式、高性能、透明化的 RPC 服务框架，提供服务自动注册、自动发现等高效服务治理方案， 可以和 Spring 框架无缝集成。RPC 指的是远程调用协议，也就是说两个服务器交互数据。 2.Dubbo的由来？​ 互联网的快速发展，Web应用程序的规模不断扩大，一般会经历如下四个发展阶段。 单一应用架构 当网站流量很小时，只需一个应用，将所有功能都部署在一起即可。 垂直应用架构 当访问量逐渐增大，单一应用按照有业务线拆成多个应用，以提升效率。 此时，用于加速前端页面开发的 Web框架(MVC) 是关键。 分布式服务架构 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。 此时，用于提高业务复用及整合的分布式服务框架(RPC) 是关键。 流动计算架构 当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。 此时，用于提高机器利用率的 资源调度和治理中心(SOA) 是关键。 3.Dubbo的主要应用场景？​ 透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。 ​ 软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。 ​ 服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。 4.Dubbo的核心功能？主要就是如下3个核心功能： ​ Remoting：网络通信框架，提供对多种NIO框架抽象封装，包括“同步转异步”和“请求-响应”模式的信息交换方式。 ​ Cluster：服务框架，提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。 ​ Registry：服务注册，基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。 5.Dubbo的核心组件？ 6.Dubbo服务注册与发现的流程？ 流程说明： Provider(提供者)绑定指定端口并启动服务 指供者连接注册中心，并发本机IP、端口、应用信息和提供服务信息发送至注册中心存储 Consumer(消费者），连接注册中心 ，并发送应用信息、所求服务信息至注册中心 注册中心根据 消费 者所求服务信息匹配对应的提供者列表发送至Consumer 应用缓存。 Consumer 在发起远程调用时基于缓存的消费者列表择其一发起调用。 Provider 状态变更会实时通知注册中心、在由注册中心实时推送至Consumer 设计的原因： Consumer 与Provider 解偶，双方都可以横向增减节点数。 注册中心对本身可做对等集群，可动态增减节点，并且任意一台宕掉后，将自动切换到另一台 去中心化，双方不直接依懒注册中心，即使注册中心全部宕机短时间内也不会影响服务的调用 服务提供者无状态，任意一台宕掉后，不影响使用 7.Dubbo的架构设计？ Dubbo框架设计一共划分了10个层： 服务接口层（Service）：该层是与实际业务逻辑相关的，根据服务提供方和服务消费方的业务设计对应的接口和实现。 配置层（Config）：对外配置接口，以ServiceConfig和ReferenceConfig为中心。 服务代理层（Proxy）：服务接口透明代理，生成服务的客户端Stub和服务器端Skeleton。 服务注册层（Registry）：封装服务地址的注册与发现，以服务URL为中心。 集群层（Cluster）：封装多个提供者的路由及负载均衡，并桥接注册中心，以Invoker为中心。 监控层（Monitor）：RPC调用次数和调用时间监控。 远程调用层（Protocol）：封将RPC调用，以Invocation和Result为中心，扩展接口为Protocol、Invoker和Exporter。 信息交换层（Exchange）：封装请求响应模式，同步转异步，以Request和Response为中心。 网络传输层（Transport）：抽象mina和netty为统一接口，以Message为中心。 8.Dubbo的服务调用流程？ 9.Dubbo支持哪些协议，每种协议的应用场景，优缺点？ dubbo： 单一长连接和NIO异步通讯，适合大并发小数据量的服务调用，以及消费者远大于提供者。传输协议TCP，异步，Hessian序列化； rmi： 采用JDK标准的rmi协议实现，传输参数和返回参数对象需要实现Serializable接口，使用java标准序列化机制，使用阻塞式短连接，传输数据包大小混合，消费者和提供者个数差不多，可传文件，传输协议TCP。多个短连接，TCP协议传输，同步传输，适用常规的远程服务调用和rmi互操作。在依赖低版本的Common-Collections包，java序列化存在安全漏洞； webservice： 基于WebService的远程调用协议，集成CXF实现，提供和原生WebService的互操作。多个短连接，基于HTTP传输，同步传输，适用系统集成和跨语言调用； http： 基于Http表单提交的远程调用协议，使用Spring的HttpInvoke实现。多个短连接，传输协议HTTP，传入参数大小混合，提供者个数多于消费者，需要给应用程序和浏览器JS调用； hessian： 集成Hessian服务，基于HTTP通讯，采用Servlet暴露服务，Dubbo内嵌Jetty作为服务器时默认实现，提供与Hession服务互操作。多个短连接，同步HTTP传输，Hessian序列化，传入参数较大，提供者大于消费者，提供者压力较大，可传文件； memcache： 基于memcached实现的RPC协议 redis： 基于redis实现的RPC协议 10.dubbo推荐用什么协议？​ 默认使用dubbo协议 11.Dubbo有些哪些注册中心？ Multicast注册中心： Multicast注册中心不需要任何中心节点，只要广播地址，就能进行服务注册和发现。基于网络中组播传输实现； Zookeeper注册中心： 基于分布式协调系统Zookeeper实现，采用Zookeeper的watch机制实现数据变更； redis注册中心： 基于redis实现，采用key/Map存储，住key存储服务名和类型，Map中key存储服务URL，value服务过期时间。基于redis的发布/订阅模式通知数据变更； Simple注册中心 12.Dubbo的服务治理？ 过多的服务URL配置困难 负载均衡分配节点压力过大的情况下也需要部署集群 服务依赖混乱，启动顺序不清晰 过多服务导致性能指标分析难度较大，需要监控 13.Dubbo的注册中心集群挂掉，发布者和订阅者之间还能通信么？可以的，启动dubbo时，消费者会从zookeeper拉取注册的生产者的地址接口等数据，缓存在本地。每次调用时，按照本地存储的地址进行调用。 14.Dubbo与Spring的关系？Dubbo采用全Spring配置方式，透明化接入应用，对应用没有任何API侵入，只需用Spring加载Dubbo的配置即可，Dubbo基于Spring的Schema扩展进行加载。 15.Dubbo使用的是什么通信框架?默认使用NIO Netty框架 16.Dubbo集群提供了哪些负载均衡策略？ Random LoadBalance: 随机选取提供者策略，有利于动态调整提供者权重。截面碰撞率高，调用次数越多，分布越均匀； RoundRobin LoadBalance: 轮循选取提供者策略，平均分布，但是存在请求累积的问题； LeastActive LoadBalance: 最少活跃调用策略，解决慢提供者接收更少的请求； ConstantHash LoadBalance: 一致性Hash策略，使相同参数请求总是发到同一提供者，一台机器宕机，可以基于虚拟节点，分摊至其他提供者，避免引起提供者的剧烈变动； 缺省时为Random随机调用 17.Dubbo的集群容错方案有哪些？ Failover Cluster 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。 Failfast Cluster 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2″ 来设置最大并行数。 Broadcast Cluster 广播调用所有提供者，逐个调用，任意一台报错则报错 。通常用于通知所有提供者更新缓存或日志等本地资源信息。 18.Dubbo的默认集群容错方案？Failover Cluster 19.Dubbo支持哪些序列化方式？默认使用Hessian序列化，还有Duddo、FastJson、Java自带序列化。 20.Dubbo超时时间怎样设置？Dubbo超时时间设置有两种方式： 服务提供者端设置超时时间，在Dubbo的用户文档中，推荐如果能在服务端多配置就尽量多配置，因为服务提供者比消费者更清楚自己提供的服务特性。 服务消费者端设置超时时间，如果在消费者端设置了超时时间，以消费者端为主，即优先级更高。因为服务调用方设置超时时间控制性更灵活。如果消费方超时，服务端线程不会定制，会产生警告。 21.服务调用超时问题怎么解决？dubbo在调用服务不成功时，默认是会重试两次的。 22.Dubbo在安全机制方面是如何解决？Dubbo通过Token令牌防止用户绕过注册中心直连，然后在注册中心上管理授权。Dubbo还提供服务黑白名单，来控制服务所允许的调用方。 23.dubbo 和 dubbox 之间的区别？dubbox 基于 dubbo 上做了一些扩展，如加了服务可 restful 调用，更新了开源组件等。 24.除了Dubbo还有哪些分布式框架？大家熟知的就是Spring cloud，当然国外也有类似的多个框架。 25.Dubbo和Spring Cloud的关系？Dubbo是 SOA 时代的产物，它的关注点主要在于服务的调用，流量分发、流量监控和熔断。而 Spring Cloud诞生于微服务架构时代，考虑的是微服务治理的方方面面，另外由于依托了 Spirng、Spirng Boot的优势之上，两个框架在开始目标就不一致，Dubbo 定位服务治理、Spirng Cloud 是一个生态。 26.dubbo和spring cloud的区别？最大的区别：Dubbo底层是使用Netty这样的NIO框架，是基于TCP协议传输的，配合以Hession序列化完成RPC通信。而SpringCloud是基于Http协议+Rest接口调用远程过程的通信，相对来说，Http请求会有更大的报文，占的带宽也会更多。但是REST相比RPC更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更为合适，至于注重通信速度还是方便灵活性，具体情况具体考虑。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>Dubbo面试题总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发面试题整理]]></title>
    <url>%2F2018%2F08%2F27%2F%E9%9D%A2%E8%AF%95%2F%E5%B9%B6%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[并发面试题整理 [toc] 1、并发编程三要素?123456（1）原子性原子性指的是一个或者多个操作，要么全部执行并且在执行的过程中不被其他操作打断，要么就全部都不执行。（2）可见性可见性指多个线程操作一个共享变量时，其中一个线程对变量进行修改后，其他线程可以立即看到修改的结果。（3）有序性有序性，即程序的执行顺序按照代码的先后顺序来执行。 2、实现可见性的方法有哪些？1synchronized 或者 Lock：保证同一个时刻只有一个线程获取锁执行代码，锁释放之前把最新的值刷新到主内存，实现可见性。 3、多线程的价值？12345678（1）发挥多核 CPU 的优势多线程，可以真正发挥出多核 CPU 的优势来，达到充分利用 CPU 的目的，采用多线程的方式去同时完成几件事情而不互相干扰。（2）防止阻塞从程序运行效率的角度来看，单核 CPU 不但不会发挥出多线程的优势，反而会因为在单核 CPU 上运行多线程导致线程上下文的切换，而降低程序整体的效率。但是单核 CPU 我们还是要应用多线程，就是为了防止阻塞。试想，如果单核 CPU 使用单线程，那么只要这个线程阻塞了，比方说远程读取某个数据吧，对端迟迟未返回又没有设置超时时间，那么你的整个程序在数据返回回来之前就停止运行了。多线程可以防止这个问题，多条线程同时运行，哪怕一条线程的代码执行读取数据阻塞，也不会影响其它任务的执行。（3）便于建模这是另外一个没有这么明显的优点了。假设有一个大的任务 A，单线程编程，那么就要考虑很多，建立整个程序模型比较麻烦。但是如果把这个大的任务 A 分解成几个小任务，任务 B、任务 C、任务 D，分别建立程序模型，并通过多线程分别运行这几个任务，那就简单很多了。 4、创建线程的有哪些方式？1234567（1）继承 Thread 类创建线程类（2）通过 Runnable 接口创建线程类（3）通过 Callable 和 Future 创建线程（4）通过线程池创建 5、创建线程的三种方式的对比？1234567891011121314151617（1）采用实现 Runnable、Callable 接口的方式创建多线程。 优势是： 线程类只是实现了 Runnable 接口或 Callable 接口，还可以继承其他类。在这种方式下，多个线程可以共享同一个 target 对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将 CPU、代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。 劣势是： 编程稍微复杂，如果要访问当前线程，则必须使用 Thread.currentThread()方法。（2）使用继承 Thread 类的方式创建多线程 优势是： 编写简单，如果需要访问当前线程，则无需使用 Thread.currentThread()方法，直接使用 this 即可获得当前线程。 劣势是： 线程类已经继承了 Thread 类，所以不能再继承其他父类。（3）Runnable 和 Callable 的区别 1、Callable 规定（重写）的方法是 call()，Runnable 规定（重写）的方法是 run()。 2、Callable 的任务执行后可返回值，而 Runnable 的任务是不能返回值的。 3、Call 方法可以抛出异常，run 方法不可以。 4、运行 Callable 任务可以拿到一个 Future 对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过 Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。 6、线程的状态流转图线程的生命周期及五种基本状态： 7、Java 线程具有五中基本状态12345678910111213141516171819（1）新建状态（New）： 当线程对象对创建后，即进入了新建状态，如：Thread t= new MyThread()； （2）就绪状态（Runnable）： 当调用线程对象的 start()方法（t.start();），线程即进入就绪状态。处于就绪状态的线程，只是说明此线程已经做好了准备，随时等待 CPU 调度执行，并不是说执行了t.start()此线程立即就会执行；（3）运行状态（Running）： 当 CPU 开始调度处于就绪状态的线程时，此时线程才得以真正执行，即进入到运行状态。注：就 绪状态是进入到运行状态的唯一入口，也就是说，线程要想进入运行状态执行，首先必须处于就绪状态中；（4）阻塞状态（Blocked）： 处于运行状态中的线程由于某种原因，暂时放弃对 CPU的使用权，停止执行，此时进入阻塞状态，直到其进入到就绪状态，才 有机会再次被 CPU 调用以进入到运行状态。 根据阻塞产生的原因不同，阻塞状态又可以分为三种： 1）等待阻塞：运行状态中的线程执行 wait()方法，使本线程进入到等待阻塞状态； 2）同步阻塞：线程在获取 synchronized 同步锁失败(因为锁被其它线程所占用)，它会进入同步阻塞状态； 3）其他阻塞：通过调用线程的 sleep()或 join()或发出了 I/O 请求时，线程会进入到阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者 I/O 处理完毕时，线程重新转入就绪状态。 （5）死亡状态（Dead）： 线程执行完了或者因异常退出了 run()方法，该线程结束生命周期。 8、什么是线程池？有哪几种创建方式？123线程池就是提前创建若干个线程，如果有任务需要处理，线程池里的线程就会处理任务，处理完之后线程并不会被销毁，而是等待下一个任务。由于创建和销毁线程都是消耗系统资源的，所以当你想要频繁的创建和销毁线程的时候就可以考虑使用线程池来提升系统的性能。java 提供了一个 java.util.concurrent.Executor 接口的实现用于创建线程池。 9、四种线程池的创建：1234567（1）newCachedThreadPool 创建一个可缓存线程池（2）newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数。（3）newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。（4）newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务。 10、线程池的优点？12345（1）重用存在的线程，减少对象创建销毁的开销。（2）可有效的控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。（3）提供定时执行、定期执行、单线程、并发数控制等功能。 11、常用的并发工具类有哪些？1234567（1）CountDownLatch（2）CyclicBarrier（3）Semaphore（4）Exchanger 12、CyclicBarrier 和 CountDownLatch 的区别1234567（1）CountDownLatch 简单的说就是一个线程等待，直到他所等待的其他线程都执行完成并且调用 countDown()方法发出通知后，当前线程才可以继续执行。（2）cyclicBarrier 是所有线程都进行等待，直到所有线程都准备好进入 await()方法之后，所有线程同时开始执行！（3）CountDownLatch 的计数器只能使用一次。而 CyclicBarrier 的计数器可以使用 reset() 方法重置。所以 CyclicBarrier 能处理更为复杂的业务场景，比如如果计算发生错误，可以重置计数器，并让线程们重新执行一次。（4）CyclicBarrier 还提供其他有用的方法，比如 getNumberWaiting 方法可以获得 CyclicBarrier 阻塞的线程数量。isBroken 方法用来知道阻塞的线程是否被中断。如果被中断返回 true，否则返回 false。 13、synchronized 的作用？1在 Java 中，synchronized 关键字是用来控制线程同步的，就是在多线程的环境下，控制 synchronized 代码段不被多个线程同时执行。synchronized 既可以加在一段代码上，也可以加在方法上。 14、volatile 关键字的作用1对于可见性，Java 提供了 volatile 关键字来保证可见性。当一个共享变量被 volatile 修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。从实践角度而言，volatile 的一个重要作用就是和 CAS 结合，保证了原子性，详细的可以参见 java.util.concurrent.atomic 包下的类，比如 AtomicInteger。 15、什么是 CAS1234567CAS 是 compare and swap 的缩写，即我们所说的比较交换。cas 是一种基于锁的操作，而且是乐观锁。在 java 中锁分为乐观锁和悲观锁。悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加 version 来获取数据，性能较悲观锁有很大的提高。CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和 A 的值是一样的，那么就将内存里面的值更新成 B。CAS是通过无限循环来获取数据的，若果在第一轮循环中，a 线程获取地址里面的值被b 线程修改了，那么 a 线程需要自旋，到下次循环才有可能机会执行。java.util.concurrent.atomic 包下的类大多是使用 CAS 操作来实现的(AtomicInteger,AtomicBoolean,AtomicLong)。 16、CAS 的问题12345678（1）CAS 容易造成 ABA 问题 一个线程 a 将数值改成了 b，接着又改成了 a，此时 CAS 认为是没有变化，其实是已经变化过了，而这个问题的解决方案可以使用版本号标识，每操作一次version 加 1。在 java5 中，已经提供了 AtomicStampedReference 来解决问题。（2）不能保证代码块的原子性 CAS 机制所保证的知识一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证 3 个变量共同进行原子性的更新，就不得不使用 synchronized 了。（3）CAS 造成 CPU 利用率增加 之前说过了 CAS 里面是一个循环判断的过程，如果线程一直没有获取到状态，cpu资源会一直被占用。 17、什么是 Future？12345在并发编程中，我们经常用到非阻塞的模型，在之前的多线程的三种实现中，不管是继承 thread 类还是实现 runnable 接口，都无法保证获取到之前的执行结果。通过实现 Callback 接口，并用 Future 可以来接收多线程的执行结果。 Future 表示一个可能还没有完成的异步任务的结果，针对这个结果可以添加Callback 以便在任务执行成功或失败后作出相应的操作。 18、什么是 AQS123AQS 是 AbustactQueuedSynchronizer 的简称，它是一个 Java 提高的底层同步工具类，用一个 int 类型的变量表示同步状态，并提供了一系列的 CAS 操作来管理这个同步状态。AQS 是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的 ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask 等等皆是基于AQS 的。 19、AQS 支持两种同步方式：123（1）独占式（2）共享式 这样方便使用者实现不同类型的同步组件，独占式如 ReentrantLock，共享式如Semaphore，CountDownLatch，组 合 式 的 如 ReentrantReadWriteLock。总之，AQS 为使用提供了底层支撑，如何组装实现，使用者可以自由发挥。 20、ReadWriteLock 是什么1首先明确一下，不是说 ReentrantLock 不好，只是 ReentrantLock 某些时候有局限。如果使用 ReentrantLock，可能本身是为了防止线程 A 在写数据、线程 B 在读数据造成的数据不一致，但这样，如果线程 C 在读数据、线程 D 也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。因为这个，才诞生了读写锁 ReadWriteLock。ReadWriteLock 是一个读写锁接口，ReentrantReadWriteLock 是 ReadWriteLock 接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。 21、FutureTask 是什么1这个其实前面有提到过，FutureTask 表示一个异步运算的任务。FutureTask 里面可以传入一个 Callable 的具体实现类，可以对这个异步运算的任务的结果进行等待获取、判断是否已经完成、取消任务等操作。当然，由于 FutureTask 也是Runnable 接口的实现类，所以 FutureTask 也可以放入线程池中。 22、synchronized 和 ReentrantLock 的区别1234567synchronized 是和 if、else、for、while 一样的关键字，ReentrantLock 是类，这是二者的本质区别。既然 ReentrantLock 是类，那么它就提供了比synchronized 更多更灵活的特性，可以被继承、可以有方法、可以有各种各样的类变量，ReentrantLock 比 synchronized 的扩展性体现在几点上：（1）ReentrantLock 可以对获取锁的等待时间进行设置，这样就避免了死锁（2）ReentrantLock 可以获取各种锁的信息（3）ReentrantLock 可以灵活地实现多路通知 另外，二者的锁机制其实也是不一样的。ReentrantLock 底层调用的是 Unsafe 的park 方法加锁，synchronized 操作的应该是对象头中 mark word，这点我不能确定。 23、什么是乐观锁和悲观锁12345（1）乐观锁： 就像它的名字一样，对于并发间操作产生的线程安全问题持乐观状态，乐观锁认为竞争不总是会发生，因此它不需要持有锁，将比较-替换这两个动作作为一个原子操作尝试去修改内存中的变量，如果失败则表示发生冲突，那么就应该有相应的重试逻辑。（2）悲观锁： 还是像它的名字一样，对于并发间操作产生的线程安全问题持悲观状态，悲观锁认为竞争总是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像 synchronized，不管三七二十一，直接上了锁就操作资源了。 24、线程 B 怎么知道线程 A 修改了变量1234567（1）volatile 修饰变量（2）synchronized 修饰修改变量的方法（3）wait/notify（4）while 轮询 25、synchronized、volatile、CAS 比较123（1）synchronized 是悲观锁，属于抢占式，会引起其他线程阻塞。（2）volatile 提供多线程共享变量可见性和禁止指令重排序优化。（3）CAS 是基于冲突检测的乐观锁（非阻塞） 26、sleep 方法和 wait 方法有什么区别?1这个问题常问，sleep 方法和 wait 方法都可以用来放弃 CPU 一定的时间，不同点在于如果线程持有某个对象的监视器，sleep 方法不会放弃这个对象的监视器，wait 方法会放弃这个对象的监视器 27、ThreadLocal 是什么？有什么用？1ThreadLocal 是一个本地线程副本变量工具类。主要用于将私有线程和该线程存放的副本对象做一个映射，各个线程之间的变量互不干扰，在高并发场景下，可以实现无状态的调用，特别适用于各个线程依赖不通的变量值完成操作的场景。简单说 ThreadLocal 就是一种以空间换时间的做法，在每个 Thread 里面维护了一个以开地址法实现的 ThreadLocal.ThreadLocalMap，把数据进行隔离，数据不共享，自然就没有线程安全方面的问题了。 28、为什么 wait()方法和 notify()/notifyAll()方法要在同步块中被调用1这是 JDK 强制的，wait()方法和 notify()/notifyAll()方法在调用前都必须先获得对象的锁 29、多线程同步有哪几种方法？1Synchronized 关键字，Lock 锁实现，分布式锁等。 30、线程的调度策略1234567891011线程调度器选择优先级最高的线程运行，但是，如果发生以下情况，就会终止线程的运行：（1）线程体中调用了 yield 方法让出了对 cpu 的占用权利（2）线程体中调用了 sleep 方法使线程进入睡眠状态（3）线程由于 IO 操作受到阻塞（4）另外一个更高优先级线程出现（5）在支持时间片的系统中，该线程的时间片用完 31、ConcurrentHashMap 的并发度是什么1ConcurrentHashMap 的并发度就是 segment 的大小，默认为 16，这意味着最多同时可以有 16 条线程操作 ConcurrentHashMap，这也是ConcurrentHashMap 对 Hashtable 的最大优势，任何情况下，Hashtable 能同时有两条线程获取 Hashtable 中的数据 32、Linux 环境下如何查找哪个线程使用 CPU 最长123（1）获取项目的 pid，jps 或者 ps -ef | grep java（2）top -H -p pid，顺序不能改变 33、Java 死锁以及如何避免?123Java 中的死锁是一种编程情况，其中两个或多个线程被永久阻塞，Java 死锁情况出现至少两个线程和两个或更多资源。Java 发生死锁的根本原因是：在申请锁时发生了交叉闭环申请。 34、死锁的原因1234（1）是多个线程涉及到多个锁，这些锁存在着交叉，所以可能会导致了一个锁依赖的闭环。 例如：线程在获得了锁 A 并且没有释放的情况下去申请锁 B，这时，另一个线程已经获得了锁 B，在释放锁 B 之前又要先获得锁 A，因此闭环发生，陷入死锁循环。（2）默认的锁申请操作是阻塞的。 所以要避免死锁，就要在一遇到多个对象锁交叉的情况，就要仔细审查这几个对象的类中的所有方法，是否存在着导致锁依赖的环路的可能性。总之是尽量避免在一个同步方法中调用其它对象的延时方法和同步方法。 35、怎么唤醒一个阻塞的线程1如果线程是因为调用了 wait()、sleep()或 者 join()方法而导致的阻塞，可以中断线程，并且通过抛出 InterruptedException 来唤醒它；如果线程遇到了 IO 阻塞，无能为力，因为 IO 是操作系统实现的，Java 代码并没有办法直接接触到操作系统。 36、不可变对象对多线程有什么帮助1前面有提到过的一个问题，不可变对象保证了对象的内存可见性，对不可变对象的读取不需要进行额外的同步手段，提升了代码执行效率。 37、什么是多线程的上下文切换1多线程的上下文切换是指 CPU 控制权由一个已经正在运行的线程切换到另外一个就绪并等待获取 CPU 执行权的线程的过程。 38、如果你提交任务时，线程池队列已满，这时会发生什么1234这里区分一下：（1）如果使用的是无界队列 LinkedBlockingQueue，也就是无界队列的话，没关系，继续添加任务到阻塞队列中等待执行，因为 LinkedBlockingQueue 可以近乎认为是一个无穷大的队列，可以无限存放任务（2）如果使用的是有界队列比如 ArrayBlockingQueue，任务首先会被添加到ArrayBlockingQueue 中，ArrayBlockingQueue 满了，会根据maximumPoolSize 的值增加线程数量，如果增加了线程数量还是处理不过来，ArrayBlockingQueue 继续满，那么则会使用拒绝策略RejectedExecutionHandler 处理满了的任务，默认是 AbortPolicy 39、Java 中用到的线程调度算法是什么1抢占式。一个线程用完 CPU 之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。 40、什么是线程调度器(Thread Scheduler)和时间分片(TimeSlicing)？1线程调度器是一个操作系统服务，它负责为 Runnable 状态的线程分配 CPU 时间。一旦我们创建一个线程并启动它，它的执行便依赖于线程调度器的实现。时间分片是指将可用的 CPU 时间分配给可用的 Runnable 线程的过程。分配 CPU 时间可以基于线程优先级或者线程等待的时间。线程调度并不受到 Java 虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先级）。 41、什么是自旋1很多 synchronized 里面的代码只是一些很简单的代码，执行时间非常快，此时等待的线程都加锁可能是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态切换的问题。既然 synchronized 里面的代码执行得非常快，不妨让等待锁的线程不要被阻塞，而是在 synchronized 的边界做忙循环，这就是自旋。如果做了多次忙循环发现还没有获得锁，再阻塞，这样可能是一种更好的策略。 42、Java Concurrency API 中的 Lock 接口(Lock interface)是什么？对比同步它有什么优势？123456Lock 接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。它的优势有：（1）可以使锁更公平（2）可以使线程在等待锁的时候响应中断（3）可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间（4）可以在不同的范围，以不同的顺序获取和释放锁 43、单例模式的线程安全性1234老生常谈的问题了，首先要说的是单例模式的线程安全意味着：某个类的实例在多线程环境下只会被创建一次出来。单例模式有很多种的写法，我总结一下：（1）饿汉式单例模式的写法：线程安全（2）懒汉式单例模式的写法：非线程安全（3）双检锁单例模式的写法：线程安全 44、Semaphore 有什么作用1Semaphore 就是一个信号量，它的作用是限制某段代码块的并发数。Semaphore有一个构造函数，可以传入一个 int 型整数 n，表示某段代码最多只有 n 个线程可以访问，如果超出了 n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。由此可以看出如果 Semaphore 构造函数中传入的 int 型整数 n=1，相当于变成了一个 synchronized 了。 45、Executors 类是什么?1Executors 为 Executor，ExecutorService，ScheduledExecutorService，ThreadFactory 和 Callable 类提供了一些工具方法。Executors 可以用于方便的创建线程池 46、线程类的构造方法、静态块是被哪个线程调用的12345这是一个非常刁钻和狡猾的问题。请记住：线程类的构造方法、静态块是被 new这个线程类所在的线程所调用的，而 run 方法里面的代码才是被线程自身所调用的。如果说上面的说法让你感到困惑，那么我举个例子，假设 Thread2 中 new 了Thread1，main 函数中 new 了 Thread2，那么：（1）Thread2 的构造方法、静态块是 main 线程调用的，Thread2 的 run()方法是Thread2 自己调用的（2）Thread1 的构造方法、静态块是 Thread2 调用的，Thread1 的 run()方法是Thread1 自己调用的 47、同步方法和同步块，哪个是更好的选择?1同步块，这意味着同步块之外的代码是异步执行的，这比同步整个方法更提升代码的效率。请知道一条原则：同步的范围越小越好。 48、Java 线程数过多会造成什么异常？12345（1）线程的生命周期开销非常高（2）消耗过多的 CPU 资源 如果可运行的线程数量多于可用处理器的数量，那么有线程将会被闲置。大量空闲的线程会占用许多内存，给垃圾回收器带来压力，而且大量的线程在竞争 CPU资源时还将产生其他性能的开销。（3）降低稳定性 JVM 在可创建线程的数量上存在一个限制，这个限制值将随着平台的不同而不同，并且承受着多个因素制约，包括 JVM 的启动参数、Thread 构造函数中请求栈的大小，以及底层操作系统对线程的限制等。如果破坏了这些限制，那么可能抛出OutOfMemoryError 异常。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>并发面试总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[英文面试总结]]></title>
    <url>%2F2018%2F08%2F27%2F%E9%9D%A2%E8%AF%95%2F%E8%8B%B1%E6%96%87%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[英文面试总结 [TOC] 1. Could you tell me something about yourself？自我介绍1234567891011 Good morning, my name is Zhang Wang, and I am honored to have the opportunity to be interviewed. I want to answer any questions you have. I hope I can perform well today.I believe I can succeed. Now, I will briefly introduce myself. I&apos;m 25 years old. I was born in Shanxi Province, a city in central China.I graduated from Hebei University of Science and Technology with a major in software engineering.I participated in many campus activities and met many friends from different majors.I am a determined person and always willing to achieve higher goals. After graduation, I am honored to join the life of a programmer. Despite the difficulties, the sense of accomplishment after solving the problem is always so strong and exciting.Finally,I share a sentence that I like very much. In the future, you will thank yourself for working so hard now. This is my self-introduction, thank you interviewer 2. What is your long term career plan？ 职业规划12345 Recently, I like to read some technical books. I want to find a suitable company and stay in the company for a longer time. Because my university teacher suggested that I take the system architect certification. I plan to take the exam, and I am learning about the exam recently. Nothing more 3. What do you consider important when you looking for a job？ 这份工作你看重什么1Technical improvement, team atmosphere, and of course, salary 4. Why did you want to leave your last job? 为什么从上家离职1Well, I am hoping to get an offer of a better position. If opportunity knocks, I will take it. 5. What are your greatest strength? 你的优点是什么？123456 Have a strong thirst for knowledge, have a strong interest in software research and development, have a strong sense of responsibility, good learning ability, logical thinking ability, optimistic and cheerful personality, good at communication and teamwork, and have the courage to innovate and accept challenges 6. Why did you decide to apply for this particular position? 你为什么决定申请这个职位1234 As the saying goes, “well begun is half done”. Your company is a famous one in the industry and boasts a high reputation. I hope to choose your company at the beginning of my career. I can not only learn new things but set a solid foundation for my future career as well. 7. Why are you interested in this job? 这份工作对你有什么吸引？1It seems like a perfect fit. 8. How would you describe your personality with three words? 用3个词说一下自己1friendly、outgoing、active 9. Do you have any hobbies in your spare time? 空闲时间的爱好有哪些12 Yes, I do. In my free time, I would like to do some reading to technology more knowledge. I would also Watch station b as it&apos;s very funny and I can get some favorite things though it. 10. What are your limitations? 你的缺点是什么？1In pursuit of perfection, I always want to do my best. 11. Why did you want to work in HSBC?123456 As an industry leader, you have an excellent reputation. Your internationalism is also very appealing. I have also heard that you invest in your staff by taking good care of them and giving them excellent training. Furthermore, in such a large company, I hope that there may be prospects for career growth and advancement in the future. 12. Can you describe your work’s experience?12345678910 I have worked for Beijing Huaruan Guochuang Technology Co., Ltd. Because my parents work in Guangzhou, I chose to resign and come to Guangzhou last year.Hope to be closer to my parents. From November last year to August this year, I worked at Shenzhen Dapuxin Technology Co., Ltd. The company has a good team atmosphere with many teams. It is working on a large project and hopes to complete a huge industrial chain product, such as a central project, a quality management project, and so on. However, I don&apos;t think my personal ability has improved much because the company has complete tools. Of course, I also wrote some simple gadgets during my tenure The company uses the Dubbo &amp; Zookeeper architecture as a whole. I want to improve my own strength. After all, the saying goes well. So I chose to resign, hoping to change to another environment and continue to improve myself.]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>英文面试总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基础方面]]></title>
    <url>%2F2018%2F08%2F27%2F%E9%9D%A2%E8%AF%95%2FJava%E5%9F%BA%E7%A1%80%E6%96%B9%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[Java基础方面面试题整理1、作用域public,private,protected以及不写时的区别答：区别如下：作用域 当前类 同一package 子孙类 其他packagepublic √ √ √ √protected √ √ √ ×friendly √ √ × ×private √ × × ×不写时默认为friendly 2、Anonymous Inner Class (匿名内部类)是否可以extends(继承)其它类，是否可以implements(实现)interface(接口)答：匿名的内部类是没有名字的内部类。不能extends(继承) 其它类，但一个内部类可以作为一个接口，由另一个内部类实现]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>Java基础方面</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作总结]]></title>
    <url>%2F2018%2F02%2F01%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20180201%2F</url>
    <content type="text"><![CDATA[String、StringBuffer与StringBuilder之间区别 四种MySQL存储引擎 MySQL是行级锁还是表级锁 Insert是行锁还是表锁？ 拦截器与过滤器的区别 MyBatis添加记录，返回主键ID Java悲观锁与乐观锁 Java公平锁与非公平锁 ORACLE动态SQL存储过程 煮方便面谈 MyBatis调用带返回值的存储过程 Dubbo+Zookeeper中MyBatis-PLUS分页使用 请求头 jqGrid行编辑 SVN代码冲突 Java 数据校验 Dubbo以及两个实体List的合并 MyBatisPlus默认更新策略 Inner Join 与LEFT JOIN 多线程与线程池 数据排序 百万数据导出 ztree的两种数据格式]]></content>
      <categories>
        <category>目录</category>
      </categories>
      <tags>
        <tag>目录</tag>
      </tags>
  </entry>
</search>
