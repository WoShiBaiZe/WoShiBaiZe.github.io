<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ztree数据格式]]></title>
    <url>%2F2020%2F08%2F16%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200816%2F</url>
    <content type="text"><![CDATA[ztree数据格式 1.ztree官网 2.ztree的两种数据格式 标准的 JSON 数据需要嵌套表示节点的父子包含关系 123456var nodes = [ &#123;name: "父节点1", children: [ &#123;name: "子节点1"&#125;, &#123;name: "子节点2"&#125; ]&#125;]; 简单模式的 JSON 数据需要使用 id / pId 表示节点的父子包含关系 12345var nodes = [ &#123;id:1, pId:0, name: "父节点1"&#125;, &#123;id:11, pId:1, name: "子节点1"&#125;, &#123;id:12, pId:1, name: "子节点2"&#125;]; 3.Java后台实现 3.1 标准的JSON数据格式- 省市区联动 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117//controller@PostMapping(value = "/getCity")@ApiOperation(httpMethod = "POST",value = "查看地址")public R&lt;List&lt;TreeNode&gt;&gt; getCity()&#123; logger.info("getCity - 获取地址"); List&lt;TreeNode&gt; treeNodeList = addressService.getCity(); return new R&lt;&gt;(treeNodeList);&#125;//service@Override@Cacheable(cacheNames = "",keyGenerator = "")public List&lt;TreeNode&gt; getCity()&#123; List&lt;Address&gt; address = addressMapper.selectList(new EntityWrapper&lt;&gt;()); List&lt;TreeNode&gt; treeNodeList = buildGroupTree(addresses); return treeNodeList;&#125;//utilsprivate List&lt;TreeNode&gt; bulidGroupList(List&lt;Address&gt; addressesList)&#123; List&lt;TreeNode&gt; list = Lists.newArrayList(); TreeNode node; for(Address group : addressesList)&#123; node = new TreeNode(); node.setId(group.getId()); node.setPid(group.getPid); node.setNodeCode(group.getAdCode()); node.setNodeName(group.getName()); list.add(node); &#125; return RecursionTreeUtil.getChildTreeNodes(list,xxxxxL);&#125;public class RecursionTreeUtil&#123; public static List&lt;TreeNode&gt; getChildTreeNodes(List&lt;TreeNode&gt; list,Long parentId)&#123; List&lt;TreeNode&gt; returnList = new ArrayList&lt;&gt;(); for(TreeNode treeNode : list)&#123; if(treeNode.getPid() == null)&#123; continue; &#125; if(Objects.equals(treeNode.getPid(),parentId))&#123; recursion(list,treeNode); returnList.add(treeNode); &#125; &#125; &#125;&#125;private static void recursionFn(List&lt;TreeNode&gt; list,TreeNode node)&#123; List&lt;TreeNode&gt; childList = getChildlist(list,node); if(PublicUtil.isEmpty(childList))&#123; return; &#125; node.setChildren(childList); for(TreeNode tChild : childList)&#123; recursionFn(list, tChild); &#125;&#125;public class PublicUtil &#123; public static boolean isEmpty(Object pObj) &#123; if (pObj == null) &#123; return true; &#125; if (pObj == "") &#123; return true; &#125; if (pObj instanceof String) &#123; return ((String) pObj).length() == 0; &#125; else if (pObj instanceof Collection) &#123; return ((Collection) pObj).isEmpty(); &#125; else if (pObj instanceof Map) &#123; return ((Map) pObj).size() == 0; &#125; return false; &#125; public static boolean isNotEmpty(Object pObj) &#123; if (pObj == null) &#123; return false; &#125; if (pObj == "") &#123; return false; &#125; if (pObj instanceof String) &#123; return ((String) pObj).length() != 0; &#125; else if (pObj instanceof Collection) &#123; return !((Collection) pObj).isEmpty(); &#125; else if (pObj instanceof Map) &#123; return ((Map) pObj).size() != 0; &#125; return true; &#125; public static boolean isEquals(Integer i1,Integer i2) &#123; if(i1 == null &amp;&amp; i2 == null)&#123; return true ; &#125; if(i1 != null &amp;&amp; i2 != null)&#123; return i1.equals(i2); &#125; return false; &#125;&#125;//iDaoList&lt;T&gt; selectList(@Param("ew") Wrapper&lt;T&gt; wrapper);//entity@Datapublic class TreeNode implements Serializable&#123; private String nodeCode; private String nodeName; private Long id; private Long pid; private List&lt;TreeNode&gt; childeren;&#125; 3.2 简单模式的 JSON 数据 123456789101112131415161718192021222324252627282930313233343536数据结构：var nodes = [ &#123;id:1, pId:0, name: "父节点1"&#125;, &#123;id:11, pId:1, name: "子节点1"&#125;, &#123;id:12, pId:1, name: "子节点2"&#125;];// 获取简单JSON数据public static List&lt;Map&lt;String, Object&gt;&gt; getStandardJSON() &#123; // 根据不同框架获取对应的List数据 List&lt;Map&lt;String, Object&gt;&gt; queryList = query.find(); List&lt;Map&lt;String, Object&gt;&gt; list = Lists.newArrayList(); treeList = getChild(queryList.get(0).get("id") , queryList , list ); return list;&#125;public static List&lt;Map&lt;String, Object&gt;&gt; getChild(String id, List&lt;Map&lt;String, Object&gt;&gt; allList, List&lt;Map&lt;String, Object&gt;&gt; simpleList) &#123; // 子节点 List&lt;Map&lt;String, Object&gt;&gt; childList = Lists.newArrayList(); for (Map&lt;String, Object&gt; map : allList) &#123; // 遍历所有节点，将父节点id与传过来的id比较 if (!ParamValidUtils.isEmpty(map.get("parent_id"))) &#123; if (map.get("parent_id").toString().equals(id)) &#123; simpleList.add(map); childList.add(map); &#125; &#125; &#125; // 把子节点的子节点再循环一遍 for (Map&lt;String, Object&gt; map : childList) &#123; getChild(map.get("id").toString(), allList, simpleList); &#125; // 递归退出条件 if (childList.size() == 0) &#123; return simpleList; &#125; return simpleList;]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百万数据导出]]></title>
    <url>%2F2020%2F08%2F14%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200814%2F</url>
    <content type="text"><![CDATA[百万数据导出 背景：因为客户需要5年系统维护，我们根据现有数据增长量，预测客户数据可能达到100w左右，同时，根据用户要求，可以导出数据库所有数据，现有的开发测试数据仅有9w左右，而且网上一些不负责任的博客，经过尝试，都不符合要求，导出的表有20多列字段，出现各种问题，所以最终自己实现。实现结果还算满意，需求符合了，在规定时间内返回结果了，但是，还是有很多值得提升的点，因为一些个人原因，只能后续 闲暇时候再研究了，应该不会再遇到这种导出100w左右的需求了，事情也不能说的太绝对了，特此记录一下。最终50w数据3.9分钟，100w数据13分钟。 1.导数据 1因为本身数据库中没有那么多数据，又要根据业务需要，所以我们没有采用批量生成方法，而是把现有数据重复导入，关闭主键ID，使用ID可以重复，使用navicat 将数据导出到excel中，再次导入，重复操作，最终数据达到100多w。注：不要使用生成sql，一条条插入，会怀疑人生，同事亲身试验，卡到爆 2.整理导出功能思路 1相信大家都做过导出功能，我们一开始设置每次也就只有1w条左右，没有发现问题，那时数据也没有那么多，只有几千条，但是，数据一多就会发现问题，第一：导出OOM，第二：效率低下，导出功能实现其实也很简单，就是查询，写入excel（这是我们的需求） 3.写查询 1更改现有查询sql，并且将查询数量从原先的1w改为100w，有意思的事情就发生了，有请求超时问题，超出存放范围溢出问题等等，最后我使用了多线程分段查询解决了查询慢的问题，但是，数据要合并，每次查询哪个线程快慢无法决定，所以使用了CopyOnWriteArrayList，写时复制底层使用了lock锁，读数据时候可以多线程，但是，写的时候保证每次只有一个线程在写，废话太多了，直接上代码吧 1234567891011121314151617181920212223242526final CountDownLatch latch = new CountDownLatch(10);CopyOnWriteArrayList&lt;&gt; arr = new CopyOnWriteArrayList&lt;&gt;();for(int i=1;i&lt;=10;i++)&#123; Page&lt;XX&gt; page = new Page&lt;&gt;(i,pageSize/10); new Thread(()-&gt;&#123; Date xxx =null; try &#123; if(StringUtils.isEmpty(xx) == false)&#123; xxx = DateUtils.formatDate(xx); &#125; //调用查询接口 arr.add(service.select(page,xxx....)); &#125;catch(Exception e)&#123; e.printStack(); &#125; latch.countDown(); System.out.println("剩下" + latch.getCount()+"个未完成"); &#125;).start();&#125; //等待线程收集齐数据try &#123; latch.await();&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; 4.写入Excel 1使用POI，只要注意OOM内存溢出问题就可以了，这里省略，使用XSSFWorkbook就可以了 5.优化思考 1任务虽然完成了，对于测试过程中也发现一些问题，查询慢，查询返回不回结果的问题解决了，但是，最大的问题又出现了，写入excel特别慢，因为只是使用了一个sheet存放100w数据，我现在的优化想法是使用多线程查询出的结果，直接用多线程再次写入每个sheet，同时进行，不阻塞数据，应该会有很大效率提升，因为暂时没有需求，加之近期又主动离职，暂时只能这样了，后续有实现，再次记录]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据排序]]></title>
    <url>%2F2020%2F08%2F13%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200813%2F</url>
    <content type="text"><![CDATA[排序（指定字段升序排列后返回） 123list.sort((s1, s2) -&gt; &#123; return s1.getSumaryDate().compareTo(s2.getSumaryDate());&#125;); 降序-字符串反转排序 12345678910111213141516171819202122232425// 方法1public static String reverse1(String str)&#123; return new StringBuffer(str).reverse().toString();&#125; // 方法2public static String reverse3(String s)&#123; char[] array = s.toCharArray(); String reverse = ""; for (int i = array.length - 1; i &gt;= 0; i--)&#123; reverse += array[i]; &#125; return reverse; &#125; //方法3 public static String reverse2(String s)&#123; int length = s.length(); String reverse = ""; for (int i = 0; i &lt; length; i++)&#123; //在新字符串前面添加读取字符，实现翻转 reverse = s.charAt(i) + reverse; &#125; return reverse; &#125; 降序-List反转 1234567891011121314151617181920212223242526272829303132333435363738394041//方法一：使用Collections.reverse(list)方法反转//方法二：自己迭代list实现反转import java.util.ArrayList;import java.util.Collections;import java.util.List;public class Test &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; list.add(i + " "); &#125; Test test = new Test(); test.print(list); //反转 test.reverseList1(list); test.reverseList2(list); test.print(list); &#125; public void reverseList1(List&lt;String&gt; list) &#123; Collections.reverse(list); &#125; public void reverseList2(List&lt;String&gt; list) &#123; List&lt;String&gt; tmpList = new ArrayList&lt;&gt;(); for (int i = list.size() - 1; i &gt;= 0; i--) &#123; tmpList.add(list.get(i)); &#125; list.clear(); list.addAll(tmpList); &#125; public void print(List&lt;String&gt; list) &#123; for (int i = 0; i &lt; list.size(); i++) &#123; System.out.print((list.get(i))); &#125; System.out.println(); &#125;&#125; 除此之外还有JDK8新特性Stream流 sql语句排序，order by … desc/asc等]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[excel宏-sheet合并]]></title>
    <url>%2F2020%2F08%2F13%2F%E5%85%B6%E5%AE%83%2Fexcel%E5%AE%8F-sheet%E5%90%88%E5%B9%B6%2F</url>
    <content type="text"><![CDATA[和同事合作写产品文档，但是写完后发现两个人没法合并，然后百度查到excel宏可以解决这个问题，以下是宏合并脚本 123456789101112131415161718192021222324Sub CombineWorkbooks()Dim FilesToOpen, ftDim x As IntegerApplication.ScreenUpdating = FalseOn Error GoTo errhandlerFilesToOpen = Application.GetOpenFilename _(FileFilter:=&quot;Micrsofe Excel文件(*.xls), *.xls&quot;, _MultiSelect:=True, Title:=&quot;要合并的文件&quot;)If TypeName(FilesToOpen) = &quot;boolean&quot; ThenMsgBox &quot;没有选定文件&quot;&apos;GoTo errhandlerEnd Ifx = 1While x &lt;= UBound(FilesToOpen)Set wk = Workbooks.Open(Filename:=FilesToOpen(x))wk.Sheets().Move after:=ThisWorkbook.Sheets _(ThisWorkbook.Sheets.Count)x = x + 1WendMsgBox &quot;合并成功完成！&quot;errhandler:&apos;MsgBox Err.Description&apos;Resume errhandlerEnd Sub]]></content>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webService学习]]></title>
    <url>%2F2020%2F08%2F13%2F%E5%85%B6%E5%AE%83%2Fwebservice%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[webService学习 1.webService 概述 webservice 跨平台 跨编程语言 远程调用技术 服务端 (服务的提供者) java webservice 客户端 (服务的消费者) java 调用webservice 2.webService 三个要素 2.1 SOAP（Simple Object Access protocol） 简单对象的访问协议 webservice 底层传输协议 SOAP = HTTP 协议 + XML（W3C 标准规范） 格式数据 2.2 WSDL (web service description language) webserivce的服务使用说明书 2.3 UUDI 是一种目录服务（地址: 注册UUDI 目录）—–&gt;商业化道路 资源共享促进全球经济合作 3.webService 第一个程序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748webService 服务端开发使用jdk开发webService 的方式 Java API for XML Web Services JAX-WS java 开发的webService 服务1.安装jdk 服务 在1.6版本之后 配置换进变量2.开发服务 服务必须存在接口 动态代理技术 //天气查询服务 @WebService //注解 修饰范围 在类上 作用：用来标识这个类|接口是一个webService接口|类 public interface WeatherWebService&#123; public String queryWeatherByCity(String cityName); &#125; 3.开发服务实现类 @WebService WeatherServiceImpl implements WeatherWebService&#123; public String queryWeatherByCity(String cityName)&#123; return &quot;天气不好，注意身体。。。。。&quot;; &#125; &#125; 4.发布服务 Endpoint.published(&quot;服务地址&quot;,服务实现类对象);5.测试是否发布成功 浏览器访问 服务地址?wsdl webService 客户端开发1.根据服务地址查看wsdl使用说明书 自下往上查看2.根据wsdl地址生成客户端调用代码 wsimport -s . -p com.xxx.client wsdl地址3.将生成客户端代码拷贝当前项目4.调用 创建服务视图对象 通过服务视图对象获取服务的核心类对象 服务核心对象的调用方法 第一种调用方式 基于服务视图对象的调用 WeatherServiceImpl weatherServiceImpl = new WeatherServiceImpl(); WeatherServiceImpl weatherServicePortType = weatherServiceImpl.getWeatherServiceImplPort(); String name = weatherServicePortType.queryWeratherByCity(&quot;北京&quot;);第二种调用方式 标准客户端调用方式 通过jdk提供的通用服务对象进行调用 参数1：wsdl地址 参数2：wsdl命名空间对象 QName QName = new QName(&quot;目标命名空间targetName&quot;,&quot;服务视图名&quot;); Service service = Service.create(new URL(&quot;url?wsdl&quot;),QName); WeatherServiceImpl portType = service.getPort(WeatherServiceImpl.class); String name = portType.queryWeatherByCity(&quot;天津&quot;); 4.ApacheCXF 4.1 使用CXF框架发布webservice 引入CXF jar包 123456&lt;!-- https://mvnrepository.com/artifact/org.apache.cxf/cxf-spring-boot-starter-jaxws --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-spring-boot-starter-jaxws&lt;/artifactId&gt; &lt;version&gt;3.2.8&lt;/version&gt;&lt;/dependency&gt; 开发服务接口类 @Webservice注解 配置]]></content>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程与线程池]]></title>
    <url>%2F2020%2F08%2F11%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200811%2F</url>
    <content type="text"><![CDATA[1.new Thread的弊端//平时我常用的写法-SonarLint经常提示使用线程池方式123new Thread(()-&gt;&#123; &#125;).start(); 1234567a. 每次new Thread新建对象性能差。b. 线程缺乏统一管理，可能无限制新建线程，相互之间竞争，及可能占用过多系统资源导致死机或oom。c. 缺乏更多功能，如定时执行、定期执行、线程中断。相比new Thread，Java提供的四种线程池的好处在于：a. 重用存在的线程，减少对象创建、消亡的开销，性能佳。b. 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。c. 提供定时执行、定期执行、单线程、并发数控制等功能。 2.Executors提供四种线程池1234newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。线程池的规模不存在限制。newFixedThreadPool 创建一个固定长度线程池，可控制线程最大并发数，超出的线程会在队列中等待。newScheduledThreadPool 创建一个固定长度线程池，支持定时及周期性任务执行。newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 (1). newCachedThreadPool 1234567891011121314151617ExecutorService cachedThreadPool = Executors.newCachedThreadPool();for (int i = 0; i &lt; 10; i++) &#123; final int index = i; try &#123; Thread.sleep(index * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; cachedThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(index); &#125; &#125;);&#125; 线程池为无限大，当执行第二个任务时第一个任务已经完成，会复用执行第一个任务的线程，而不用每次新建线程。 (2). newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。示例代码如下： 1234567891011121314151617ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3);for (int i = 0; i &lt; 10; i++) &#123; final int index = i; fixedThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;);&#125; (3) newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。延迟执行示例代码如下： 12345678ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5);scheduledThreadPool.schedule(new Runnable() &#123; @Override public void run() &#123; System.out.println("delay 3 seconds"); &#125;&#125;, 3, TimeUnit.SECONDS); 表示延迟3秒执行。定期执行示例代码如下：1234567scheduledThreadPool.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; System.out.println("delay 1 seconds, and excute every 3 seconds"); &#125;&#125;, 1, 3, TimeUnit.SECONDS); 表示延迟1秒后每3秒执行一次。ScheduledExecutorService比Timer更安全，功能更强大。 (4)、newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。示例代码如下： 1234567891011121314151617ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor();for (int i = 0; i &lt; 10; i++) &#123; final int index = i; singleThreadExecutor.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;);&#125; 结果依次输出，相当于顺序执行各个任务。 3.ExecutorService中submit和execute的区别以下这是submit 的源码：1234567891011121314151617181920212223242526272829303132public abstract class AbstractExecutorService implements ExecutorService &#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value); &#125; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask; &#125; //....&#125; 可以看出submit最终返回的是FutureTask对象，而execute:123public interface Executor &#123; void execute(Runnable command);&#125; 具体的实现在ThreadPoolExecutor类中1234567891011121314151617181920public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; 所以，submit内部调用execute，且submit有返回值，方便exception处理。submit Demo:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import java.util.ArrayList;import java.util.List;import java.util.Random;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;public class Main &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); List&lt;Future&lt;String&gt;&gt; resultList = new ArrayList&lt;Future&lt;String&gt;&gt;(); // 创建10个任务并执行 for (int i = 0; i &lt; 10; i++) &#123; // 使用ExecutorService执行Callable类型的任务，并将结果保存在future变量中 Future&lt;String&gt; future = executorService.submit(new TaskWithResult(i)); // 将任务执行结果存储到List中 resultList.add(future); &#125; executorService.shutdown(); // 遍历任务的结果 for (Future&lt;String&gt; fs : resultList) &#123; try &#123; System.out.println(fs.get()); // 打印各个线程（任务）执行的结果 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; executorService.shutdownNow(); e.printStackTrace(); return; &#125; &#125; &#125;&#125;class TaskWithResult implements Callable&lt;String&gt; &#123; private int id; public TaskWithResult(int id) &#123; this.id = id; &#125; /** * 任务的具体过程，一旦任务传给ExecutorService的submit方法，则该方法自动在一个线程上执行。 * * @return * @throws Exception */ public String call() throws Exception &#123; System.out.println("call()方法被自动调用,干活！！！ " + Thread.currentThread().getName()); if (new Random().nextBoolean()) throw new TaskException("Meet error in task." + Thread.currentThread().getName()); // 一个模拟耗时的操作 for (int i =9; i &gt; 0; i--) ; return "call()方法被自动调用，任务的结果是：" + id + " " + Thread.currentThread().getName(); &#125;&#125;class TaskException extends Exception &#123; public TaskException(String message) &#123; super(message); &#125;&#125; Runnable和Callable的区别是，(1)Callable规定的方法是call(),Runnable规定的方法是run().(2)Callable的任务执行后可返回值，而Runnable的任务是不能返回值得(3)call方法可以抛出异常，run方法不可以(4)运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的学习环境-K8S]]></title>
    <url>%2F2020%2F08%2F10%2F%E6%88%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%2F%E6%88%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83-K8S%2F</url>
    <content type="text"><![CDATA[Kubernetes（K8S） 因为前几天电脑坏了，自己的环境都没有了，打算重新装一下K8S，记录一下，因为明天还要加班，争取今天晚上搞定 1.本机硬件：24G内存＋i7-5代，为了不影响开发，打算搭建1主3从外加一个数据卷 2.系统使用Ubuntu Server X64 18.04LTS 长期支持版 3.节点规划: | 主机名 | IP | 角色 | 系统 | CPU/内存 | 磁盘 || —————— | ————— | —— | ——————- | ——– | —- || kubernetes-master | 192.168.xxx.110 | Master | Ubuntu Server 18.04 | 2 核 3G | 20G || kubernetes-node-01 | 192.168.xxx.120 | Node | Ubuntu Server 18.04 | 2 核 3G | 20G || kubernetes-node-02 | 192.168.xxx.121 | Node | Ubuntu Server 18.04 | 2 核 3G | 20G || kubernetes-node-03 | 192.168.xxx.122 | Node | Ubuntu Server 18.04 | 2 核 3G | 20G || kubernetes-volumes | 192.168.xxx.140 | NFS | Ubuntu Server 18.04 | 2 核 3G | 20G | 1.基础准备 关闭交换空间 1swapoff -a 避免开机启动交换空间 12# 注释 swap 开头的行vi /etc/fstab 关闭防火墙 1ufw disable 配置DNS 12# 取消 DNS 行注释，并增加 DNS 配置如：114.114.114.114，修改后重启下计算机vi /etc/systemd/resolved.conf 安装 Docker 12sudo apt-get updatesudo apt install docker.io 配置 Docker 建议使用阿里云 通过修改 daemon 配置文件 /etc/docker/daemon.json 来使用加速器 1234567891011&#123; "exec-opts": [""], "log-driver": "", "log-opts": &#123; "max-size": "" &#125;, "registry-mirrors": [ ], "storage-driver": ""&#125; 重启 Docker 12systemctl daemon-reloadsystemctl restart docker 安装 Kubernetes 必备工具 安装三个 Kubernetes 必备工具，分别为 kubeadm，kubelet，kubectl 12345678910111213# 安装系统工具apt-get update &amp;&amp; apt-get install -y apt-transport-https# 安装 GPG 证书curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -# 写入软件源；注意：我们用系统代号为 bionic，但目前阿里云不支持，所以沿用 16.04 的 xenialcat &lt;&lt; EOF &gt;/etc/apt/sources.list.d/kubernetes.listdeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOF# 安装apt-get update &amp;&amp; apt-get install -y kubelet kubeadm kubectl 同步时间 设置时区 1dpkg-reconfigure tzdata 时间同步 12345678# 安装 ntpdateapt-get install ntpdate# 设置系统时间与网络时间同步（cn.pool.ntp.org 位于中国的公共 NTP 服务器）ntpdate cn.pool.ntp.org# 将系统时间写入硬件时间hwclock --systohc 确认时间 1234date# 输出如下（自行对照与系统时间是否一致）Sun Feb 23 12:05:17 CST 2020 修改cloud.cfg 主要作用是防止重启后主机名还原 1234vi /etc/cloud/cloud.cfg# 该配置默认为 false，修改为 true 即可preserve_hostname: true 单独节点配置 注意： 为 Master 和 Node 节点单独配置对应的 IP 和 主机名 配置IP 编辑 vi /etc/netplan/50-cloud-init.yaml 配置文件，修改内容如下 12345678network: ethernets: ens33: addresses: [192.168.xxx.110/24] gateway4: 192.168.xxx.2 nameservers: addresses: [192.168.xxx.2] version: 2 使用 netplan apply 命令让配置生效 配置主机名 1234567# 修改主机名hostnamectl set-hostname kubernetes-master# 配置 hostscat &gt;&gt; /etc/hosts &lt;&lt; EOF192.168.xxx.110 kubernetes-masterEOF 2.安装集群 创建并修改配置 12# 导出配置文件kubeadm config print init-defaults --kubeconfig ClusterConfiguration &gt; kubeadm.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243apiVersion: kubeadm.k8s.io/v1beta2bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: # 修改为主节点 IP advertiseAddress: 192.168.81.110 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: kubernetes-master taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta2certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcd# 国内不能访问 Google，修改为阿里云imageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfiguration# 修改版本号kubernetesVersion: v1.17.3networking: dnsDomain: cluster.local # 配置 POD 所在网段为我们虚拟机不重叠的网段（这里用的是 Flannel 默认网段） podSubnet: "10.244.0.0/16" serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125; 查看所需镜像 12345678910kubeadm config images list --config kubeadm.yml# 输出如下registry.aliyuncs.com/google_containers/kube-apiserver:v1.17.3registry.aliyuncs.com/google_containers/kube-controller-manager:v1.17.3registry.aliyuncs.com/google_containers/kube-scheduler:v1.17.3registry.aliyuncs.com/google_containers/kube-proxy:v1.17.3registry.aliyuncs.com/google_containers/pause:3.1registry.aliyuncs.com/google_containers/etcd:3.4.3-0registry.aliyuncs.com/google_containers/coredns:1.6.5 拉取所需镜像 12345678910kubeadm config images pull --config kubeadm.yml# 输出如下[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.17.3[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.17.3[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.17.3[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.17.3[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.1[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.4.3-0[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:1.6.5 安装主节点 执行以下命令初始化主节点，该命令指定了初始化时需要使用的配置文件，其中添加 --upload-certs 参数可以在后续执行加入节点时自动分发证书文件。追加的 tee kubeadm-init.log 用以输出日志。 注意： 如果安装 kubernetes 版本和下载的镜像版本不统一则会出现 timed out waiting for the condition 错误。中途失败或是想修改配置可以使用 kubeadm reset 命令重置配置，再做初始化操作即可。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273kubeadm init --config=kubeadm.yml --upload-certs | tee kubeadm-init.log# 输出如下[init] Using Kubernetes version: v1.17.3[preflight] Running pre-flight checks[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Starting the kubelet[certs] Using certificateDir folder "/etc/kubernetes/pki"[certs] Generating "ca" certificate and key[certs] Generating "apiserver" certificate and key[certs] apiserver serving cert is signed for DNS names [kubernetes-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.81.110][certs] Generating "apiserver-kubelet-client" certificate and key[certs] Generating "front-proxy-ca" certificate and key[certs] Generating "front-proxy-client" certificate and key[certs] Generating "etcd/ca" certificate and key[certs] Generating "etcd/server" certificate and key[certs] etcd/server serving cert is signed for DNS names [kubernetes-master localhost] and IPs [192.168.81.110 127.0.0.1 ::1][certs] Generating "etcd/peer" certificate and key[certs] etcd/peer serving cert is signed for DNS names [kubernetes-master localhost] and IPs [192.168.81.110 127.0.0.1 ::1][certs] Generating "etcd/healthcheck-client" certificate and key[certs] Generating "apiserver-etcd-client" certificate and key[certs] Generating "sa" key and public key[kubeconfig] Using kubeconfig folder "/etc/kubernetes"[kubeconfig] Writing "admin.conf" kubeconfig file[kubeconfig] Writing "kubelet.conf" kubeconfig file[kubeconfig] Writing "controller-manager.conf" kubeconfig file[kubeconfig] Writing "scheduler.conf" kubeconfig file[control-plane] Using manifest folder "/etc/kubernetes/manifests"[control-plane] Creating static Pod manifest for "kube-apiserver"W0223 12:38:57.210893 9130 manifests.go:214] the default kube-apiserver authorization-mode is "Node,RBAC"; using "Node,RBAC"[control-plane] Creating static Pod manifest for "kube-controller-manager"[control-plane] Creating static Pod manifest for "kube-scheduler"W0223 12:38:57.214165 9130 manifests.go:214] the default kube-apiserver authorization-mode is "Node,RBAC"; using "Node,RBAC"[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s[apiclient] All control plane components are healthy after 19.005825 seconds[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace[kubelet] Creating a ConfigMap "kubelet-config-1.17" in namespace kube-system with the configuration for the kubelets in the cluster[upload-certs] Storing the certificates in Secret "kubeadm-certs" in the "kube-system" Namespace[upload-certs] Using certificate key:91f1d04e74abd60fbadf2afaae656a5c5bfc3761e5a4a69d6727e429c997165c[mark-control-plane] Marking the node kubernetes-master as control-plane by adding the label "node-role.kubernetes.io/master=''"[mark-control-plane] Marking the node kubernetes-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule][bootstrap-token] Using token: abcdef.0123456789abcdef[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.xxx.110:6443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:3eac1be34c9e324279ebd843087e7dd002b3102c7d14313aec490cd73b4138ad 配置Kubectl 12345mkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/config# 非 ROOT 用户执行chown $(id -u):$(id -g) $HOME/.kube/config 验证是否成功 12345kubectl get node# 输出如下NAME STATUS ROLES AGE VERSIONkubernetes-master NotReady master 115s v1.17.3 安装从节点 将 Node 节点加入到集群中很简单，只需要在 Node 服务器上安装 kubeadm，kubectl，kubelet 三个工具，然后使用 kubeadm join 命令加入即可 123456789101112kubeadm join 192.168.xxx.110:6443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:3eac1be34c9e324279ebd843087e7dd002b3102c7d14313aec490cd73b4138ad # 输出如下[preflight] Running pre-flight checks[preflight] Reading configuration from the cluster...[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.17" ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Starting the kubelet[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... 验证是否成功 回到 Master 主节点查看是否安装成功 注意： 如果 Node 节点加入 Master 时配置有问题可以在 Node 节点上使用 kubeadm reset 重置配置再使用 kubeadm join 命令重新加入即可。希望在 master 节点删除 node ，可以使用 kubeadm delete nodes &lt;NAME&gt; 删除。 12345678kubectl get nodes# 输出如下NAME STATUS ROLES AGE VERSIONkubernetes-master NotReady master 17m v1.17.3kubernetes-node1 NotReady &lt;none&gt; 24s v1.17.3kubernetes-node2 NotReady &lt;none&gt; 15s v1.17.3kubernetes-node3 NotReady &lt;none&gt; 7s v1.17.3 查看Pods状态 coredns 尚未运行，此时我们还需要安装网络插件 1234567891011121314watch kubectl get pods -n kube-system -o wide# 输出如下NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-9d85f5447-czrdk 0/1 Pending 0 19m &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;coredns-9d85f5447-zsf6f 0/1 Pending 0 19m &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;etcd-kubernetes-master 1/1 Running 0 20m 192.168.81.110 kubernetes-master &lt;none&gt; &lt;none&gt;kube-apiserver-kubernetes-master 1/1 Running 0 20m 192.168.81.110 kubernetes-master &lt;none&gt; &lt;none&gt;kube-controller-manager-kubernetes-master 1/1 Running 0 20m 192.168.81.110 kubernetes-master &lt;none&gt; &lt;none&gt;kube-proxy-jf9jg 1/1 Running 0 3m19s 192.168.81.122 kubernetes-node3 &lt;none&gt; &lt;none&gt;kube-proxy-t2rz5 1/1 Running 0 3m27s 192.168.81.121 kubernetes-node2 &lt;none&gt; &lt;none&gt;kube-proxy-vszhp 1/1 Running 0 3m36s 192.168.81.120 kubernetes-node1 &lt;none&gt; &lt;none&gt;kube-proxy-zpjk2 1/1 Running 0 19m 192.168.81.110 kubernetes-master &lt;none&gt; &lt;none&gt;kube-scheduler-kubernetes-master 1/1 Running 0 20m 192.168.81.110 kubernetes-master &lt;none&gt; &lt;none&gt; kubeadm init 的执行过程 init： 指定版本进行初始化操作 preflight： 初始化前的检查和下载所需要的 Docker 镜像文件 kubelet-start： 生成 kubelet 的配置文件 var/lib/kubelet/config.yaml，没有这个文件 kubelet 无法启动，所以初始化之前的 kubelet 实际上启动不会成功 certificates： 生成 Kubernetes 使用的证书，存放在 /etc/kubernetes/pki 目录中 kubeconfig： 生成 KubeConfig 文件，存放在 /etc/kubernetes 目录中，组件之间通信需要使用对应文件 control-plane： 使用 /etc/kubernetes/manifest 目录下的 YAML 文件，安装 Master 组件 etcd： 使用 /etc/kubernetes/manifest/etcd.yaml 安装 Etcd 服务 wait-control-plane： 等待 control-plan 部署的 Master 组件启动 apiclient： 检查 Master 组件服务状态。 uploadconfig： 更新配置 kubelet： 使用 configMap 配置 kubelet patchnode： 更新 CNI 信息到 Node 上，通过注释的方式记录 mark-control-plane： 为当前节点打标签，打了角色 Master，和不可调度标签，这样默认就不会使用 Master 节点来运行 Pod bootstrap-token： 生成 token 记录下来，后边使用 kubeadm join 往集群中添加节点时会用到 addons： 安装附加组件 CoreDNS 和 kube-proxy 3.网络插件 下载Calico 配置文件并修改 123456wget https://docs.projectcalico.org/manifests/calico.yamlvi calico.yaml修改第 611 行，将 192.168.0.0/16 修改为 10.244.0.0/16，可以通过如下命令快速查找显示行号：:set number查找字符：/要查找的字符，输入小写 n 下一个匹配项，输入大写 N 上一个匹配项 安装网络插件 Calico 参考官方文档安装：https://docs.projectcalico.org/getting-started/kubernetes/quickstart 1234567891011121314151617181920212223242526kubectl apply -f calico.yaml# 输出如下configmap/calico-config createdcustomresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org createdclusterrole.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrole.rbac.authorization.k8s.io/calico-node createdclusterrolebinding.rbac.authorization.k8s.io/calico-node createddaemonset.apps/calico-node createdserviceaccount/calico-node createddeployment.apps/calico-kube-controllers createdserviceaccount/calico-kube-controllers created 验证是否成功 查看 Calico 网络插件处于 Running 状态即表示安装成功 12345678910111213141516171819watch kubectl get pods --all-namespaces# 输出如下NAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-77c4b7448-vzsb7 1/1 Running 0 3m52skube-system calico-node-5gr6m 1/1 Running 0 3m53skube-system calico-node-5pwj6 1/1 Running 0 3m53skube-system calico-node-drp46 1/1 Running 0 3m53skube-system calico-node-npjpx 1/1 Running 0 3m53skube-system coredns-9d85f5447-czrdk 1/1 Running 0 32mkube-system coredns-9d85f5447-zsf6f 1/1 Running 0 32mkube-system etcd-kubernetes-master 1/1 Running 0 33mkube-system kube-apiserver-kubernetes-master 1/1 Running 0 33mkube-system kube-controller-manager-kubernetes-master 1/1 Running 0 33mkube-system kube-proxy-jf9jg 1/1 Running 0 16mkube-system kube-proxy-t2rz5 1/1 Running 0 16mkube-system kube-proxy-vszhp 1/1 Running 0 16mkube-system kube-proxy-zpjk2 1/1 Running 0 32mkube-system kube-scheduler-kubernetes-master 1/1 Running 0 33m 查看节点状态处于Ready 即表示安装成功 12345678kubectl get nodes# 输出如下NAME STATUS ROLES AGE VERSIONkubernetes-master Ready master 33m v1.17.3kubernetes-node1 Ready &lt;none&gt; 17m v1.17.3kubernetes-node2 Ready &lt;none&gt; 16m v1.17.3kubernetes-node3 Ready &lt;none&gt; 16m v1.17.3]]></content>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的学习环境-容器服务]]></title>
    <url>%2F2020%2F08%2F05%2F%E6%88%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%2F%E6%88%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83-%E5%AE%B9%E5%99%A8%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[容器服务 MySQL 12345678910111213141516171819version: '3.1'services: db: image: mysql:8.0.20 restart: always container_name: mysql environment: - TZ=Asia/Shanghai - MYSQL_ROOT_PASSWORD=123456 command: --default-authentication-plugin=mysql_native_password --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci --explicit_defaults_for_timestamp=true --lower_case_table_names=1 ports: - 3306:3306 volumes: - ./data:/var/lib/mysql GitLab 12345678910111213141516171819202122version: '3.1'services: web: image: 'twang2218/gitlab-ce-zh:11.1.4' restart: always hostname: 'gitlab.funtl.com' container_name: 'gitlab' environment: TZ: 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG: | external_url 'http://gitlab.funtl.com' gitlab_rails['gitlab_shell_ssh_port'] = 2222 unicorn['port'] = 8888 nginx['listen_port'] = 80 ports: - '80:80' - '443:443' - '2222:22' volumes: - ./config:/etc/gitlab - ./data:/var/opt/gitlab - ./logs:/var/log/gitlab Nexus 1234567891011121314mkdir /usr/local/docker/nexus/data &amp;&amp; chown -R 200 /usr/local/docker/nexus/dataversion: '3.5'services: nexus: restart: always image: sonatype/nexus3:3.23.0 container_name: nexus environment: INSTALL4J_ADD_VM_PARAMS: -XX:ActiveProcessorCount=4 ports: - 80:8081 volumes: - ./data:/nexus-data Jenkins 123456789101112131415version: '3.5'services: jenkins: restart: always image: jenkins/jenkins:lts container_name: jenkins environment: TZ: Asia/Shanghai ports: - 80:8080 - 50000:50000 volumes: - data:/var/jenkins_homevolumes: data:]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的学习环境-Docker]]></title>
    <url>%2F2020%2F08%2F03%2F%E6%88%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%2F%E6%88%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83-Docker%2F</url>
    <content type="text"><![CDATA[Docker 1.Linux安装(略) 以下为shell配置脚本 功能说明在注释中 适用于Centos7 config.sh 1234567891011121314##### 用户配置区 开始 ###### 1.安装 ntpdate 命令# 2.配置 阿里云镜像# 3.关闭防火墙# 4.重启系统##### 用户配置区 结束 ######!/bin/bashyum install -y vimyum install -y ntpdatentpdate -b ntp1.aliyun.comsystemctl stop firewalldsystemctl disable firewalldsed -ri s/SELINUX=enforcing/SELINUX=disabled/g /etc/selinux/configreboot ​ Confluence.sh 12345678910111213141516171819202122232425262728293031##### 用户配置区 开始 ###### confluence 构建企业WIKI及工单系统##### 用户配置区 结束 ######!/bin/bashecho "开始安装JDK1.8"yum -y install java-1.8.0-openjdk-1.8.0.191.b12-1.el7_6.x86_64 java -versionecho "java安装完成"echo -e "\n"echo "开始安装mariadb"yum -y install mariadb-server mariadbsystemctl start mariadbsystemctl enable mariadbecho "此处有bug，只能输入123456，如果不想设置，请按ctrl+c暂停脚本"echo "进入数据库后，复制下面命令"echo "create database jira default character set utf8 collate utf8_bin;"echo "exit"read -p "请输入mariadb密码:" passwordmysqladmin -u root password $passwordmysql -uroot -p$passwordecho "数据库设置完成"echo -e "\n"echo "开始下载conflunece8.0.2-x64版本，如果需要更改请自行更改"yum -y install wgetwget https://www.atlassian.com/software/jira/downloads/binary/atlassian-jira-software-8.0.2-x64.binchmod 755 atlassian-jira-software-8.0.2-x64.bin./atlassian-jira-software-8.0.2-x64.bino1iy initserver.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/env bash## Author: baize# Date: 2019/05/25# Usage:system# turn off firewalld and selinux.systemctl disable firewalld &amp;&amp; systemctl stop firewalldSTATUS=$(getenforce)if [ $STATUS == "Disabled" ];then printf "SELINUX is closed.\n"else sed -ri s/SELINUX=enforcing/SELINUX=disabled/g /etc/selinux/config setenforce 0fi# init yumrepo and install always software tools. mkdir /etc/yum.repos.d/repobak mv /etc/yum.repos.d/* /etc/yum.repos.d/repobak/ curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repoif [ $? -ne 0 ];then printf "Please check your network!!!\n" exitelse curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo if [ $? -ne 0 ];then printf "Please check your network!!!\n" exit else sed -rie '/aliyuncs*/d' /etc/yum.repos.d/CentOS-Base.repo yum clean all &amp;&amp; yum makecache fast fifi yum -y install vim net-tools wget ntpdate ShellCheck cmake make lftp yum -y groupinstall "Development Tools"# time upload rsync. ntpdate -b ntp1.aliyun.com# sshd majorization. sed -ri s/"#UseDNS yes"/"UseDNS no"/g /etc/ssh/sshd_config systemctl restart sshd Sys_Check.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200#!/bin/bash# auth:baize# func:sys info check# date:2019/05/07[ $(id -u) -gt 0 ] &amp;&amp; echo "请用root用户执行此脚本！" &amp;&amp; exit 1sysversion=$(rpm -q centos-release|cut -d- -f3)line="-------------------------------------------------"[ -d logs ] || mkdir logssys_check_file="logs/$(ip a show dev ens33|grep -w inet|awk '&#123;print $2&#125;'|awk -F '/' '&#123;print $1&#125;')-`date +%Y%m%d`.txt"# 获取系统cpu信息function get_cpu_info() &#123; Physical_CPUs=$(grep "physical id" /proc/cpuinfo| sort | uniq | wc -l) Virt_CPUs=$(grep "processor" /proc/cpuinfo | wc -l) CPU_Kernels=$(grep "cores" /proc/cpuinfo|uniq| awk -F ': ' '&#123;print $2&#125;') CPU_Type=$(grep "model name" /proc/cpuinfo | awk -F ': ' '&#123;print $2&#125;' | sort | uniq) CPU_Arch=$(uname -m)cat &lt;&lt;EOFCPU信息:物理CPU个数:$Physical_CPUs逻辑CPU个数:$Virt_CPUs每CPU核心数:$CPU_KernelsCPU型号:$CPU_TypeCPU架构:$CPU_ArchEOF&#125;# 获取系统内存信息function get_mem_info() &#123; check_mem=$(free -m) MemTotal=$(grep MemTotal /proc/meminfo| awk '&#123;print $2&#125;') #KB MemFree=$(grep MemFree /proc/meminfo| awk '&#123;print $2&#125;') #KB let MemUsed=MemTotal-MemFree MemPercent=$(awk "BEGIN &#123;if($MemTotal==0)&#123;printf 100&#125;else&#123;printf \"%.2f\",$MemUsed*100/$MemTotal&#125;&#125;") report_MemTotal="$((MemTotal/1024))""MB" #内存总容量(MB) report_MemFree="$((MemFree/1024))""MB" #内存剩余(MB) report_MemUsedPercent="$(awk "BEGIN &#123;if($MemTotal==0)&#123;printf 100&#125;else&#123;printf \"%.2f\",$MemUsed*100/$MemTotal&#125;&#125;")""%" #内存使用率%cat &lt;&lt;EOF内存信息：$&#123;check_mem&#125;EOF&#125;# 获取系统网络信息function get_net_info() &#123; pri_ipadd=$(ip a show dev ens33|grep -w inet|awk '&#123;print $2&#125;'|awk -F '/' '&#123;print $1&#125;') pub_ipadd=$(curl ifconfig.me -s) gateway=$(ip route | grep default | awk '&#123;print $3&#125;') mac_info=$(ip link| egrep -v "lo"|grep link|awk '&#123;print $2&#125;') dns_config=$(egrep -v "^$|^#" /etc/resolv.conf) route_info=$(route -n)cat &lt;&lt;EOFIP信息:系统公网地址:$&#123;pub_ipadd&#125;系统私网地址:$&#123;pri_ipadd&#125;网关地址:$&#123;gateway&#125;MAC地址:$&#123;mac_info&#125;路由信息:$&#123;route_info&#125;DNS 信息:$&#123;dns_config&#125;EOF&#125;# 获取系统磁盘信息function get_disk_info() &#123; disk_info=$(fdisk -l|grep "Disk /dev"|cut -d, -f1) disk_use=$(df -hTP|awk '$2!="tmpfs"&#123;print&#125;') disk_inode=$(df -hiP|awk '$1!="tmpfs"&#123;print&#125;')cat &lt;&lt;EOF磁盘信息:$&#123;disk_info&#125;磁盘使用:$&#123;disk_use&#125;inode信息:$&#123;disk_inode&#125;EOF&#125;# 获取系统信息function get_systatus_info() &#123; sys_os=$(uname -o) sys_release=$(cat /etc/redhat-release) sys_kernel=$(uname -r) sys_hostname=$(hostname) sys_selinux=$(getenforce) sys_lang=$(echo $LANG) sys_lastreboot=$(who -b | awk '&#123;print $3,$4&#125;') sys_runtime=$(uptime |awk '&#123;print $3,$4&#125;'|cut -d, -f1) sys_time=$(date) sys_load=$(uptime |cut -d: -f5)cat &lt;&lt;EOF系统信息:系统: $&#123;sys_os&#125;发行版本: $&#123;sys_release&#125;系统内核: $&#123;sys_kernel&#125;主机名: $&#123;sys_hostname&#125;selinux状态: $&#123;sys_selinux&#125;系统语言: $&#123;sys_lang&#125;系统当前时间: $&#123;sys_time&#125;系统最后重启时间: $&#123;sys_lastreboot&#125;系统运行时间: $&#123;sys_runtime&#125;系统负载: $&#123;sys_load&#125;EOF&#125;# 获取服务信息function get_service_info() &#123; port_listen=$(netstat -lntup|grep -v "Active Internet") kernel_config=$(sysctl -p 2&gt;/dev/null) if [ $&#123;sysversion&#125; -gt 6 ];then service_config=$(systemctl list-unit-files --type=service --state=enabled|grep "enabled") run_service=$(systemctl list-units --type=service --state=running |grep ".service") else service_config=$(/sbin/chkconfig | grep -E ":on|:启用" |column -t) run_service=$(/sbin/service --status-all|grep -E "running") ficat &lt;&lt;EOF服务启动配置:$&#123;service_config&#125;$&#123;line&#125;运行的服务:$&#123;run_service&#125;$&#123;line&#125;监听端口:$&#123;port_listen&#125;$&#123;line&#125;内核参考配置:$&#123;kernel_config&#125;EOF&#125;function get_sys_user() &#123; login_user=$(awk -F: '&#123;if ($NF=="/bin/bash") print $0&#125;' /etc/passwd) ssh_config=$(egrep -v "^#|^$" /etc/ssh/sshd_config) sudo_config=$(egrep -v "^#|^$" /etc/sudoers |grep -v "^Defaults") host_config=$(egrep -v "^#|^$" /etc/hosts) crond_config=$(for cronuser in /var/spool/cron/* ;do ls $&#123;cronuser&#125; 2&gt;/dev/null|cut -d/ -f5;egrep -v "^$|^#" $&#123;cronuser&#125; 2&gt;/dev/null;echo "";done)cat &lt;&lt;EOF系统登录用户:$&#123;login_user&#125;$&#123;line&#125;ssh 配置信息:$&#123;ssh_config&#125;$&#123;line&#125;sudo 配置用户:$&#123;sudo_config&#125;$&#123;line&#125;定时任务配置:$&#123;crond_config&#125;$&#123;line&#125;hosts 信息:$&#123;host_config&#125;EOF&#125;function process_top_info() &#123; top_title=$(top -b n1|head -7|tail -1) cpu_top10=$(top b -n1 | head -17 | tail -11) mem_top10=$(top -b n1|head -17|tail -10|sort -k10 -r)cat &lt;&lt;EOFCPU占用top10:$&#123;top_title&#125;$&#123;cpu_top10&#125;内存占用top10:$&#123;top_title&#125;$&#123;mem_top10&#125;EOF&#125;function sys_check() &#123; get_cpu_info echo $&#123;line&#125; get_mem_info echo $&#123;line&#125; get_net_info echo $&#123;line&#125; get_disk_info echo $&#123;line&#125; get_systatus_info echo $&#123;line&#125; get_service_info echo $&#123;line&#125; get_sys_user echo $&#123;line&#125; process_top_info&#125;sys_check &gt; $&#123;sys_check_file&#125; 2.Docker.sh 脚本安装(Ubuntu) 123456789101112131415161718192021222324252627#!/bin/bash############################## 1.安装Dokcer ## 2.安装DockerCompose ##############################echo "docker安装"apt-get remove docker docker-engine docker.io containerd runcapt-get updateapt-get -y install apt-transport-https ca-certificates curl software-properties-commoncurl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"apt-get update &amp;&amp; apt-get install -y docker-cedocker versiontee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; "registry-mirrors": [ "https://registry.docker-cn.com" ]&#125;EOFservice docker restartdocker infoecho -e "\n"echo "docker compose安装"curl -L https://github.com/docker/compose/releases/download/1.24.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-composedocker-compose version 3.Gitlab.sh 脚本安装(Ubuntu) 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/bin/bash############################## 1.编写docker-compose文件 ## 2.运行docker-compose up ###############################===注意：==================##=========需要修改ip地址====#dir=/usr/local/docker/gitlabfunction run_mkcurrent_dir()&#123;my_dir="$dir"if [ ! -d "$my_dir" ]; then echo "创建文件夹" mkdir $my_direlse echo "文件夹已存在"fi&#125;run_mkcurrent_dir;tee /usr/local/docker/gitlab/docker-compose.yml &lt;&lt;-'EOF'version: '3'services: web: image: 'twang2218/gitlab-ce-zh' restart: always hostname: '192.168.75.145' environment: TZ: 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG: | external_url 'http://192.168.75.145' gitlab_rails['gitlab_shell_ssh_port'] = 2222 unicorn['port'] = 8888 nginx['listen_port'] = 80 ports: - '80:80' - '443:443' - '2222:22' volumes: - ./config:/etc/gitlab - ./data:/var/opt/gitlab - ./logs:/var/log/gitlabEOFcd /usr/local/docker/gitlab/docker-compose up 4.Nexus.sh 脚本安装(Ubuntu) 1234567891011121314151617181920212223242526272829303132#!/bin/bash############################## 1.编写docker-compose文件## 2.运行docker-compose up ##############################dir=/usr/local/docker/nexusfunction run_mkcurrent_dir()&#123;my_dir="$dir"if [ ! -d "$my_dir" ]; then echo "创建文件夹" mkdir $my_direlse echo "文件夹已存在"fi&#125;run_mkcurrent_dir;tee /usr/local/docker/nexus/docker-compose.yml &lt;&lt;-'EOF'version: '3.1'services: nexus: restart: always image: sonatype/nexus3 container_name: nexus ports: - 8081:8081 volumes: - ./data:/nexus-dataEOFcd /usr/local/docker/nexus/docker-compose upchmod 777 /usr/local/docker/nexus/data]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Inner Join与LEFT JOIN]]></title>
    <url>%2F2020%2F08%2F03%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200803%2F</url>
    <content type="text"><![CDATA[inner join与left join的区别 INNER JOIN 产生的结果是AB的交集 SELECT * FROM TableA INNER JOIN TableB ON TableA.id = TableB.rec_id LEFT (OUTER) JOIN 产生表A的完全集，而表B中匹配的则有值，没有匹配的则以null值取代. SELECT * FROM TableA LEFT OUTER JOIN TableB ON TableA.id = TableB.rec_id; 3.RIGHT（OUTER） JOIN 产生表B的完全集，而表A中匹配的则有值，没有匹配的则以null值取代 ​ SELECT * FROM TableA RIGHT OUTER JOIN TableB ON TAbleA.id = TableB.rec_id ​ FULL (OUTER) JOIN 产生A和B的并集，对于没有匹配的记录，以null值做为值 SELECT * FROM TableA FULL OUTER JOIN TableB ON TableA .name = TableB.name 可以通过is null将 没有匹配的值找出来； SELECT * FROM TableA FULL OUTER JOIN TableB ON TableA.name = TableB.name WHERE TableA.id is null OR TableB.id is null]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MybatisPlus默认更新策略]]></title>
    <url>%2F2020%2F07%2F22%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200722%2F</url>
    <content type="text"><![CDATA[问题实际项目中，难免更新的时候,有可能会把已有的值更新成空字符串或者null,但是当你使用updateById()方法的时候，会发现根本不生效。这其实是MyBatis-Plus对字段的验证策略导致的，MyBatis-Plus默认进行了不是全量更新的策略 解决方案 1234567field-strategy字段更新插入策略属性说明： IGNORED(0): "忽略判断", 所有字段都更新和插入 NOT_NULL(1): "非 NULL 判断", 只更新和插入非NULL值 NOT_EMPTY(2): "非空判断", 只更新和插入非NULL值且非空字符串 DEFAULT：默认NOT_NULL]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认识JUC]]></title>
    <url>%2F2020%2F07%2F08%2FJUC%2FJUC%2F</url>
    <content type="text"><![CDATA[JUC (java.until.concurrent) 1.1 进程/线程 1.2 并发/并行 三个包 java.util.concurrent java.util.concurrent.atomic java.util.concurrent.locks 锁 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102class Ticket //资源类 = 实例变量 + 实例方法&#123; private int number = 30; // List list = new ArrayList(); //Lock接口 ReentrantLock可重入锁 Lock lock = new ReentrantLock(); //同步方法 //public synchronized void sale() public void sale() &#123; // synchronized(this) 同步代码块 // 快捷键 trylock 回车 lock.lock(); try&#123; if(number &gt; 0) &#123; //快捷键 mycurr 回车 System.out.println(Thread.currentThread().getName() + "\t卖出第:"+(number--)+"\t 还剩下:" + number); &#125; &#125;catch(Exception e)&#123; e.printStackTrace(); &#125;finally&#123; lock.unlock(); &#125; &#125;&#125;/** * 1.三个售票员 卖出 30张票 * 如何编写企业级的多线程代码 * 固定的变成套路＋模板是什么？ * * 在高内聚低耦合的前提下，线程 操作 资源类 */public class SaleTicketDemo01&#123; public static void main(String[] args) //主线程，一切程序的入口 &#123; Ticket ticket = new Ticket(); //Thread t1 = new Thread(); //Thread t2 = new Thread(); //Thread t3 = new Thread(); //Thread(Runnable target, String name) Allocates a new Thread object new Thread(()-&gt;&#123;for(int i = 1; i&lt;=40;i++ ) ticket.sale();&#125;,"A").start(); new Thread(()-&gt;&#123;for(int i = 1; i&lt;=40;i++ ) ticket.sale();&#125;,"B").start(); new Thread(()-&gt;&#123;for(int i = 1; i&lt;=40;i++ ) ticket.sale();&#125;,"C").start(); //函数式接口 //@FunctionalInterface //public interface Runnable&#123; // public abstract void run(); //&#125; //匿名内部类方法 /* new Thread(new Runable() &#123; @Override public void run() &#123; for(int i = 1; i &lt;=40; i++) &#123; //Thread.state 多线程状态 //1.新建状态 NEW //2.运行状态 RUNABLE //3.阻塞状态 BLOCK //4.死等待 WAITING //5.时间限制等待 TIME_WAITING //6.TERMINATED ticket.sale(); &#125; &#125; &#125;,"A").start(); new Thread(new Runable() &#123; @Override public void run() &#123; for(int i = 1; i &lt;=40; i++) &#123; ticket.sale(); &#125; &#125; &#125;,"B").start(); new Thread(new Runable() &#123; @Override public void run() &#123; for(int i = 1; i &lt;=40; i++) &#123; ticket.sale(); &#125; &#125; &#125;,"C").start(); */ &#125;&#125; 3.ArrayList线程不安全 123456789101112131415161718192021222324252627282930313233343536373839/** * 1.故障现象 * java.util.ConcurrentModificationException * 2.导致原因 多线程争抢资源没有加索 * 3.解决方法 * 3.1 new Vector(); * 3.2 Collections.synchronizedList(new ArrayList&lt;&gt;); * 3.3 new CopyOnWriteArrayList(); * 4.优化建议(同样的错误不犯第2次) * * */public class NotSafe&#123; public static void main(String[] args) &#123; //Vector线程安全，重锁 synchronized修饰 List&lt;String&gt; list = new CopyOnWriteArrayList();//Collections.synchronizedList(new ArrayList&lt;&gt;);//new Vector(); //new ArrayList(); /* list.add("a"); list.add("a"); list.add("a"); //4大函数 //Predicate&lt;T&gt; 断言型 有参数，有返回值 返回值为boolean类型 boolean test(T t) //Functaion&lt;T,R&gt; 函数型接口，有参数，有返回值 R apply(T t) //Supplier&lt;T&gt; 供给型函数接口，没有参数，有返回值 T get(); //Consumer&lt;T&gt; 消费型接口 有参数，无返回值 void accept(T t) list.forEach(System.out::println); */ for(int i=0;i&lt;=3;i++) &#123; new Thread(()-&gt;&#123; list.add(UUID.randomUUID().toString().substring(0,8)); System.out.println(list); &#125;,String.valueOf(i)).start(); &#125; &#125;&#125; 123456789101112131415161718192021/** * CopyOnWriteArrayList add方法底层 * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */ public boolean add(E e) &#123; final ReentrantLock lock = this.lock; //可重用锁 lock.lock(); //加锁 try &#123; Object[] elements = getArray(); //获取原数组 int len = elements.length; //获取原数组长度 Object[] newElements = Arrays.copyOf(elements, len + 1); //复制新的数组，长度加1 newElements[len] = e; //新的数据加入新的数组中 setArray(newElements); //将数据加入新的数组中 return true; // 返回正确 &#125; finally &#123; lock.unlock(); &#125; &#125; 12345678910111213141516171819202122/** * HashSet线程不安全，底层使用HashMap */ public class NotSafeDemo &#123; public static void main(String[] args) &#123; setNotSafe(); &#125; public static void setNoteSafe() &#123; set&lt;String&gt; set = new CopyOnWriteArraySet&lt;&gt;(); for(int i = 1; i&lt;=30;i++) &#123; new Thread(()-&gt;&#123; set.add(UUID.randomUUID().toString().substring(0,8)); System.out.println(set); &#125;,String.valueOf(i)).start(); &#125; &#125; &#125; 123456789101112131415161718/** * Map线程不安全 */public class NotSafeDemo1&#123; public static void main(String[] args) &#123; //HashMap线程不安全 Map&lt;String,String&gt; map = new ConcurrentHashMap&lt;&gt;(); for(int i=0;i&lt;=30;i++) &#123; new Thread(()-&gt;&#123; map.put(Thread.currentThread().getName(),UUID.randomUUID().toString().substring(0,8)); System.out.println(map); &#125;,String.valueOf(i)).start(); &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485class Phone&#123; //8.5 public static synchronized void sentEmail() thrwos Exception &#123; //8.2 //Thread.sleep(4000); TimeUnit.SECONDS.sleep(4); System.out.println("*********sendEmail"); &#125; //8.5 //public static synchronized void sendSMS() throws Exception //8.6 public synchronized void sendSMS() throws Exception &#123; System.out.println("*********sendSMS"); &#125; public void sayHello() throws Exception &#123; System.out.println("*********sayHello"); &#125;&#125;/** * 8 lock * 8.1 标准访问 请问先打印邮件还是短信 邮件 * 8.2 暂停4秒钟再邮件方法，请问先打印邮件还是短信 邮件 * 8.3 新增普通sayHello方法，请问先打印邮件还是sayHello sayHello * 8.4 2部手机 请问先打印邮件还是短信 短信 * 8.5 2个静态同步方法，同一部手机 请问先打印邮件还是短信 邮件 * 8.6 2个静态同步方法，2部手机 请问先打印邮件还是短信 邮件 * 8.7 1个静态同步方法，1个普通同步方法，同一部手机 短信 * 8.8 1个静态同步方法，1个普通同步方法，2部手机 短信 * * * 一个对象里面如果有多个synchronized方法，某一个时刻内，只要一个线程去调用其中的一个synchronized方法了， *其它的线程都只能等待，换句话说，某一个时刻内，只能有唯一一个线程去访问这些synchronized方法 * *锁的是当前对象this，被锁定后，其它的线程都不能进入到当前对象的其它的synchronized方法 * *加个普通方法后发现和同步锁无关 * *换成两个对象后，不是同一把锁了，情况立刻变化。 * *synchronized实现同步的基础：Java中的每一个对象都可以作为锁。 *具体表现为以下3种形式。 *对于普通同步方法，锁是当前实例对象,锁的是当前对象this， *对于同步方法块，锁是Synchonized括号里配置的对象。 * *对于静态同步方法，锁是当前类的Class对象。 */public class Lock8&#123; public static void main(String[] args) throws InterruptedException &#123; Phone phone = new Phone(); Phone phone2 = new Phone(); new Thread(()-&gt;&#123; try&#123; phone.sendEmail(); &#125;catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;,"A").start(); Thread.sleep(100); new Thread(()-&gt;&#123; try&#123; //8.3 //phone.sendSMS(); //phone.sayHello(); //8.4 //phone2.sendSMS(); //8.5 //phone.sendSMS(); //8.6 phone2.sendSMS(); &#125;catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;,"B").start(); &#125;&#125;]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>JUC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo以及两个实体List的合并]]></title>
    <url>%2F2020%2F06%2F17%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200617%2F</url>
    <content type="text"><![CDATA[Dubbo以及两个实体List的合并 工作中有导出功能，导出需要和页面展示的内容一致，但是，导出的数据Float型自动转成了Double型，日期多.0，很是奇怪，同事自己写的sql没有这些问题，因为公司框架中封装了mybatis-plus，我的页面有很多字段，为了方便开发，使用了mybatis-plus，出现这些问题，于是Debug代码，发现在service层，没有查询出的数据格式，与页面相同，但是到了controller层就变得Double，.0等问题了，回想了一下执行流程发现，自己写的sql，会通过实体类，实体类中有实现序列化，所以没有问题，而自己使用mybatis-plus的方法，直接封装了结果，中间没有序列化，导致数据传输错误，以上是我认为的，后续还要验证，究竟是什么原因导致的自动变成了Double 因为还有一个需求，通过两次查询结果，合并成一个结果返回前端，数据需要将相同的合并，不同的保留，起初的写法只是双重for循环＋if判断，可以把相同的数据合并，并保留外层数据的不同值，但是，内层循环的不同数据就丢失了。后面想到相同添加，同时删除内层数据，最后再加上内层剩余数据就可以完成了，实现过程中出现了异常，最后换了一个方式。将一个list的匹配字段放入hashmap中当key，剩下实体当value，另一个list遍历，添加，最后实现了 失败的方法 123456789101112131415//第一个实体类集合List&lt;Entity&gt; entity = mapper.select();//第二个实体类集合List&lt;Entity&gt; entity1 = mapper.select();for(Entity en : entity)&#123; for(Entity en2 : entity1)&#123; if(en.getxxx().equals(en2.getxx))&#123; en.setxx(en2.setxxx); &#125; &#125;&#125;例如： 第一个实体结果：1，2，3，4，5，6，7 第二个实体结果：1，2，4，5，6，7，8 上面的写法只会拿到：1，2，3，4，5，6，7， 丢失第8个数字 成功的方法 1234567891011121314151617181920212223242526272829303132//第一个实体类集合List&lt;Entity&gt; entity = mapper.select();//第二个实体类集合List&lt;Entity&gt; entity1 = mapper.select();//创建一个HashMap，key放判断是否相同的字段，Value放整个数据Map&lt;String, Entity&gt; target = new HashMap&lt;String, Entity&gt;();//判断是否为空if (CollectionUtils.isNotEmpty(entity) &amp;&amp; CollectionUtils.isNotEmpty(entity1)) &#123;//遍历第一个实体类集合，放入map中for (Entity ent : entity) &#123; target.put(ent.getXXX(), ent);&#125;//遍历第二个集合for (Entity en : entity1) &#123; //获取第一个实体类中的key值 String a = en.getA(); //如果第一个实体类集合中包含第二个实体类集合中的值if (target.containsKey(a)) &#123; //获取第一个实体类的所有值 Entity temp = target.get(a); //设置自己想要添加的数据 temp.setXxxx(en.getXXX()); //重新将数据放回 target.put(a, temp);&#125; else &#123; //不同时候将第二个实体类中，与第一个实体类不想同的数据放入Map中 target.put(a, en); &#125; &#125;&#125;这个方法会拿到：1，2，3，4，5，6，7，8]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认识JVM]]></title>
    <url>%2F2020%2F06%2F13%2FJDK%E6%96%B0%E7%89%B9%E6%80%A7%2F%E8%AE%A4%E8%AF%86JVM%2F</url>
    <content type="text"><![CDATA[认识 JVM [TOC] 一、什么是JVM​ 虚拟机，是Java的运行环境，是一种能够运行.class字节码文件的机器 JVM 基本结构 1.类加载器 ： 用来加载磁盘.class的JVM内存 2.运行时数据区(内存结构)： 内存结构，不同的数据存储到不同的区域 3.执行引擎：运行代码，输出执行结果 4.本地方法接口 5.本地方法库 类加载过程 1.加载：将磁盘中的.class文件读取到内存中 2.连接： 1.验证：验证.class文件是否正确性 2.准备：给类的静态变量分配内存，并且给默认值(数据类型默认值) 3.解析：将关联的类也装载到内存(A类，A类用B类，所以这步将B类也载入) 3.初始化 给静态变量赋予真正的值。(涉及到类的初始化：父类的静态变量，父类的静态代码块，子类静态变量，子类静态代码块，父类变量，父类代码块，父类构造函数，子类变量，子类代码块，子类构造函数) 4.使用 5.卸载 类加载器 启动类加载器（C语言实现） 用来加载jre核心类库（rt.jar，charsets.jar…） 扩展类加载器（Java） jre的扩展类库（ext目录） 系统类加载器（Java） 自定义的类 类加载机制：类加载的原理 全盘负责委托机制 A类，B类，A类中引用B类 A类是自定义的类，所以Jvm会使用系统类加载器，去加载A类，那么会使用哪个加载器去加载B类呢？？？判断有没有去手动指定类加载器去加载B类，如果没有手动指定类加载器，将使用A类的加载器去加载B类，如果手动指定了加载器，将使用指定的加载器去加载B类，会使用当前类加载器去加载关联类 双亲委派机制 启动类加载器 3.查看A类是否被加载，否：判断是否该自己加载 4.不该自己加载，向下询问 扩展类加载器 2.查看A类是否被加载，否：向上询问 5.判断是否该自己加载，否：向下询问 系统类加载器 1.查看A类是否被加载，否：向上询问 6.自己加载 JVM内存 Java虚拟机（1.7） 程序计数器： 线程私有的（每个线程都有自己的程序计数器）。是一个个指针，代码运行，执行命令，而每个命令都有行号。使用程序技术来记录命令执行到多少行了 Java虚拟机栈： 线程私有的（每个线程都有一个自己的Java虚拟机栈）。一个方法运行，就会给这个方法创建一个栈帧，栈帧入栈执行代码，执行完毕之后出栈(弹栈) 本地方法栈： 线程私有的（每个线程都有一个自己的本地方法栈）。和Java虚拟机栈类似，Java虚拟机栈加载的是普通方法。本地方法栈加载的是native修饰的方法 堆 线程共享的（所有线程共享一份），存放对象的，new的对象都存储这个区域 方法区 线程共享的（所有线程共享一份），存放.class的信息，类的信息，方法的定义，常量池，静态变量等。 Java虚拟机（1.8） 没有方法区，放到本地内存 元数据区（元空间） 存储.class信息，类的信息，方法的定义，静态变量等。而常量池放到堆里存储 二、什么是垃圾 什么是GC？ 内存空间有限，程序运行时如何把不需要使用的对象(垃圾对象）清除而释放资源，这就是GC的功能 GC的操作区域 Java 虚拟机栈，本地方法栈，程序计数器是不需要GC，因为1这个都是线程私有的，线程私有的就会随着线程的产生而产生，随着线程的结束而销毁 堆和方法区需要GC，需要GC来及时清理运行过程中产生的垃圾 GC的操作对象是什么 垃圾对象 三、如何发现垃圾 引用计数 给每个对象定义一个变量，存储引用数，就是通过引用计数是否为0来判断是否清理 可达性分析 会记录对象的引用链。如果一个对象没有引用链，就证明这个对象没有被使用，那么就会销毁 GC 的运行时机 1.手动调用 System.gc()可以触发GC操作 2.系统本身自己出发：内存不足时就会触发 GC做了什么？ 清理对象，整理内存 四、GC 算法 标记清除： 给每个对象存储一个标记位，记录对象的状态（死/活），两个阶段，第一是标记阶段：检查对象的状态，判断对象是否死亡。第二是清理阶段：将死亡对象清理掉 标记压缩 是标记清除算法的改进版。两个阶段，第一是标记阶段：检查对象的状态，判断对象是否死亡。第二是将所有存活的对象整理放到另外一处内空间，把剩余的对象全部清除掉 复制算法 会将内存平均分两块，每次只使用其中的一块，当这块内存存满了，将这个内存中，存活的对象复制到另外一块内存中，将刚才那块儿内存清空 分代收集算法 堆如果细分还可以分为新生代，老年代。在新生代中对象存活的时间短，所以采用的算法是复制算法，老年代中的对象存活率高，所以使用标记压缩或标记清除算法 五、Available collectors​]]></content>
      <categories>
        <category>JVM调优</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java数据校验]]></title>
    <url>%2F2020%2F06%2F06%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200606%2F</url>
    <content type="text"><![CDATA[Java数据校验 1.因为工作中有部分时间在写前端，没有怎么写后台，突然给到任务让写数据校验，就参考了一下以前的校验方式，感觉有些性能不好，而且作用不好，重新写一下校验 2.原来的校验方式：是通过查询所有数据，遍历数据，与输入数据进行比较，第一：性能不好，要查询所有数据，然后遍历。 第二：如果是自己本身数据没有改变，需要判断，代码感觉混乱，不容易维护 3.我的想法： 1.添加： 根据传入数据，使用mybatis-plus的selectCount方式查询数据有几条？ 123456789QueryWrapper&lt;XXX&gt; wrapper = new QueryWrapper&lt;XXX&gt;(); //mybatis-plus条件构造器wrapper.eq("IS_ENABLE", 1); //因为有伪删除，所以有这个字段if (StringUtils.isEmpty(XXX.getxxx()) == false) &#123; wrapper.eq("数据库字段", XXX.getxxx());&#125; //需要校验的数据Integer count = mapper.selectCount(wrapper);//查询条数if(count&gt;0)&#123; //数据库存在数据，重复，不可添加&#125; 2.编辑： 和添加相同的道理，但是多了一个自己本身校验 1234567891011121314151617181920 //首先使用 mybatis-plus的selectById方法，返回查询结果的实体类 XXX val = mapper.selectById(XXX.getId()); QueryWrapper&lt;XXX&gt; wrapper = new QueryWrapper&lt;XXX&gt;(); //mybatis-plus条件构造器 wrapper.eq("IS_ENABLE", 1); //因为有伪删除，所以有这个字段 if (StringUtils.isEmpty(XXX.getxxx()) == false) &#123; wrapper.eq("数据库字段", XXX.getxxx()); &#125; //需要校验的数据 Integer count = mapper.selectCount(wrapper);//查询条数 if(count&gt;1)&#123; //数据库存在数据，重复，不可添加 &#125; else if(count == 1)&#123; //此时说明数据库中有一个数据与现在相同，但是，不知道是是不是自己 if(val.getxxx().equals(xxx.getxxx()...))&#123; //不用操作，直接跳出，更新数据，此处通过id查询与传入数据相同，代表自己本身&#125; else &#123; //不可操作，数据已存在 retrun false; &#125; &#125; mapper.updateById(xxx);//更新数据 3.上传 思路和添加相同，总体就是判断count，大于0失败，数据存在]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVN版本冲突]]></title>
    <url>%2F2020%2F05%2F15%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200515%2F</url>
    <content type="text"><![CDATA[SVN版本冲突 这个冲突文件是同事写的代码，并不是我的，但是，我在更新代码的时候发生了代码冲突 解决步骤 1.选中冲突文件鼠标右键Edit conficts 2.虽然我没有修改但是，我还是选择了第三个，合并到本地目录，保存我的和服务器的，再次更新代码就可以了 出现界面，分为”Theirs”、”Mine”和”Merged”3部分，表示”别人修改的内容”、 ”我修改的内容”和”合并后的结果”3部分。我们是要将”别人修改的内容”和”我修改的内容”有取舍地合并起来，形成”合并后的结果”。 合并一般分为4种情况： 1.保留”我的修改”,舍弃”别人的修改”。鼠标右键点击Mine框的相应行，点击”Use this text block”。 2.舍弃”我的修改”,保留”别人的修改”。鼠标右键点击Theirs框的相应行，点击”Use this text block”。 3.同时保留”我的修改”和”别人的修改”，并将”我的修改” 放在前面。鼠标右键点击Mine框的相应行，点击”Use text block from mine before theirs”。 4.同时保留”我的修改”和”别人的修改”，并将”别人的修改”放在前面。鼠标右键点击Mine框的相应行，点击”Use text block from theirs before mine”。]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JqGrid行编辑]]></title>
    <url>%2F2020%2F05%2F14%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200514%2F</url>
    <content type="text"><![CDATA[JqGrid行编辑 ​ 1.jqGrid学习网站 jqGrid实例中文版 jqGrid官网 ​ 2.editRow 编辑行 //最后一行追加行 123456$("#productList").addRowData(rowid, josnData, "last");//调用方式jQuery("#grid_id").editRow(rowid, keys, oneditfunc, successfunc, url, extraparam, aftersavefunc,errorfunc, afterrestorefunc);//新版本调用方式jQuery("#grid_id").jqGrid('editRow',rowid, keys, oneditfunc, successfunc, url, extraparam, aftersavefunc,errorfunc, afterrestorefunc); editRow参数配置说明 grid_id ：已经构造过的jqGrid rowid：此数据行的id keys：设置为true可以使用 [Enter]保存数据或者[Esc] 取消编辑 oneditfunc：在行成功转为编辑模式下触发的事件，参数为此行数据id successfunc, url, extraparam, aftersavefunc,errorfunc 和 afterrestorefunc在下面的saveRow方法中介绍 拥有’not-editable-row’ 样式的行不可编辑，即使colModel中配置了某些列能编辑。 123456789101112131415//默认参数editparameters = &#123; "keys" : false, "oneditfunc" : null, "successfunc" : null, "url" : null, "extraparam" : &#123;&#125;, "aftersavefunc" : null, "errorfunc": null, "afterrestorefunc" : null, "restoreAfterError" : true, "mtype" : "POST"&#125; jQuery("#grid_id").jqGrid('editRow',rowid, parameters); //事件编辑行 123456onSelectRow: function (id) &#123; $("#productList").saveRow(id, false); $("#productList").jqGrid('restoreRow', id); $("#productList").jqGrid('editRow', id, true); lastrow = id;&#125; saveRow保存行 1$("#jqGrid").jqGrid('saveRow',rowKey); restoreRow还原数据行 1jQuery("#grid_id").restoreRow(rowid, afterrestorefunc); inlineNav： 给行编辑添加导航操作按钮 12jQuery("#grid_id").navGrid(pagerid, &#123;...&#125;);jQuery("#grid_id").inlineNav(pagerid, parameters); 12345 - delGridRow删除行​```javascript$(&quot;#jqGrid&quot;).delGridRow(rowKey);]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图书推荐]]></title>
    <url>%2F2020%2F04%2F29%2F%E5%9B%BE%E4%B9%A6%E6%8E%A8%E8%8D%90%2F%E5%9B%BE%E4%B9%A6%E6%8E%A8%E8%8D%90%2F</url>
    <content type="text"><![CDATA[高清下载 图书下载]]></content>
      <categories>
        <category>目录</category>
      </categories>
      <tags>
        <tag>图书推荐</tag>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK新特性]]></title>
    <url>%2F2020%2F04%2F26%2FJDK%E6%96%B0%E7%89%B9%E6%80%A7%2FJDK%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@FunctionalInterfaceinterface Foo&#123; //函数式接口有且只有一个方法 //public void sayHello(); public int add(int x,int y); //default 可以定义一个 public default int mul(int x,int y) &#123; retrun x * y; &#125; // static 可以定义多个 public static int div(int x, int y) &#123; retrun x/y; &#125;&#125;/** * 函数式接口可以使用 Lambda * 1.拷贝中括号,写死右箭头，落地大括号 * 2.@FunctionalInterface * 3.default * 4.static */public clas LambdaExpresssDemo&#123; public static void main(String[] args) &#123; /*Foo foo = new Foo() &#123; @Override public void sayHello() &#123; System.out.println("****** hello"); &#125; foo.sayHello(); &#125;*/ //Foo foo = () -&gt; &#123;System.out.println("****** hello");&#125;; //foo.sayHello(); Foo foo = (int x, int y)&#123;System.out.println("come in math");return x+y;&#125;; System.out.println(foo.add(3,5)); System.out.println(foo.mul(3,5)); System.out.println(Foo.div(10,2)) &#125;&#125; ​ Stream 是对集合(Collection)对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作，或者大批量数据操作。通常我们需要多行代码才能完成的操作，借助于Stream流式处理可以很简单的实现。 Stream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的Iterator。同时Stream提供串行和并行两种模式进行汇聚操作。比如你的Stream里面有很多数据，Stream可以开多个线程每个线程处理一部分。最后把结果汇总起来。 在开始之前我们先用一个图来整体的概况下Stream。如下所示： https://blog.csdn.net/wuyuxing24/article/details/96560995]]></content>
      <categories>
        <category>目录</category>
      </categories>
      <tags>
        <tag>目录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[请求头]]></title>
    <url>%2F2020%2F04%2F22%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200422%2F</url>
    <content type="text"><![CDATA[请求头 前端请求415错误 @RequestParam主要来是于URL，例如百度的地址 https://www.baidu.com/s?wd=前端415@RequestBody主要来自表单信息，通过POST的方式把表单的信息传到后台。@RequestHeader求请的表单头。一般用来放浏览器信息，cookies等信息。 @RequestParam对应的是URL的参数。@RequestBody对应的 是Form 的值@RequestHeader 对应是 Head的参数 1234567891011121314151617181920function f_c() &#123; var url = "http://localhost:8080/test/paramTest?OperateType=add"; var opt = &#123; attr1: "a", attr2: "b", &#125;; $.ajax(&#123; type: "POST", url: url, headers: &#123; token:'key' &#125;, data: JSON.stringify(opt), contentType: "application/json", success: function (data) &#123; alert(data) &#125;, error: function (data) &#123; alert("error"); &#125; &#125;); &#125; 原文链接：https://richy.blog.csdn.net/article/details/104571682]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo+Zookeeper中MyBatis-PLUS分页使用]]></title>
    <url>%2F2020%2F04%2F20%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200420%2F</url>
    <content type="text"><![CDATA[Dubbo+Zookeeper中MyBatis-PLUS分页使用 2020-04-20 所在项目组架构使用Dubbo+Zookeeper以及spingboot，mybatis，mybatis-plus，开发过程中，需要传递实体类并传递分页信息，以便根据实体类条件查询结果分页，查阅资料，都是在controller层，使用service接口调用mybatis-plus的page方法，但是，因为公司使用dubbo架构，会产生rpc调用，所以导致调用失败，MyBaits-Plus官网提示 ​ 选择在service层，服务提供者处，使用selectPage方法 ​ 2.实体类LocalDateTime 在项目中，序列化出现问题，导致异常（截取自网络）解决方法：更换数据类型 com.alibaba.dubbo.rpc.RpcException: Failed to invoke the method compositeQuery in the service com.wwwarehouse.xdw.resourcecenter.service.ImConsumeRealityService. Tried 3 times of the providers [192.168.72.158:20880] (1/1) from the registry 192.168.6.21:2181 on the consumer 192.168.72.158 using the dubbo version 2.8.4. Last error is: Failed to invoke remote method: compositeQuery, provider:]]></content>
      <categories>
        <category>工作总结</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA]]></title>
    <url>%2F2020%2F04%2F19%2F%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%2F1.IDEA%2F</url>
    <content type="text"><![CDATA[一、安装（略） 二、使用 关闭自动更新 安装插件 设置字体 设置版本控制]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis 调用 带返回值 的存储过程]]></title>
    <url>%2F2020%2F02%2F17%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200217%2F</url>
    <content type="text"><![CDATA[MyBatis 调用 带返回值 的存储过程 序 mybatis 调用oracle 存储过程，返回一个表。这样的景场用得比较少，我用了mybatis这么长时间，还第一次这么用。尝试过程也是比较痛苦，网上资料少不说，很多配置拿下来，也是跑不起来。。最后自己不停地跟据mybatis抛出来的错误调整代码，终于跑起来了。做一下笔记。 存储过程 存储过程比较长，只需要关注输入，输出参数就可以了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899CREATE OR REPLACE PROCEDURE P_QMS_GET_MIS_RPT(MIS_TYPE VARCHAR2, --1:3MIS 2:6MIS MIS_DATE VARCHAR2, --时间条件 OTHER_CONDITION VARCHAR2, --其它条件 DATE_TYPE NVARCHAR2, -- 1:年 2：月 3：周 GROUP_BY VARCHAR2, --维度 BRAND P_CUR OUT SYS_REFCURSOR ) AS V_SQL VARCHAR2(4000); V_CON VARCHAR2(500):=''; V_DATE DATE; V_STRAT_DATE date; V_END_DATE date; V_MIS_MONTH varchar2(50); V_START_DATE_STR VARCHAR2(100); V_END_DATE_STR VARCHAR2(100);BEGINV_DATE:=TO_DATE(MIS_DATE,'yyyy-MM-dd'); V_STRAT_DATE := Trunc(add_months(V_DATE, -3 * MIS_TYPE ), 'mm'); V_END_DATE := Last_Day(add_months(V_DATE, -1)); V_MIS_MONTH := to_char(Trunc(add_months(V_DATE, -1), 'mm'), 'yyyymm'); V_START_DATE_STR:= ' to_date('''|| to_char( V_STRAT_DATE,'yyyy-MM-dd') ||''',''yyyy-MM-dd'') '; V_END_DATE_STR := ' to_date('''|| to_char( V_END_DATE,'yyyy-MM-dd') ||''',''yyyy-MM-dd'') '; V_CON:=V_CON || ' and ACTIVE_START&gt;= ' || V_START_DATE_STR ; V_CON:=V_CON || ' and ACTIVE_START &lt; '|| V_END_DATE_STR || '+1'; V_CON:=V_CON|| ' '; V_SQL := ' with B as --市场不良数 (SELECT '|| GROUP_BY ||', sum(QTY) AS sc_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''10'' '|| V_CON ||' group by '|| GROUP_BY ||'), --销售数量 C as (SELECT '|| GROUP_BY ||', sum(QTY) AS s_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''40'' '|| V_CON ||' group by '|| GROUP_BY ||' ), --生产数量 D as (SELECT '|| GROUP_BY ||', sum(QTY) AS pro_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''30'' '|| V_CON ||' group by '|| GROUP_BY ||' ), --销售比率 E as (select d.'|| GROUP_BY ||', round(least(sum(c.s_qty) / sum(d.pro_qty), 1), 8) as rate, sum(c.s_qty) sale_qty, sum(d.pro_qty) pro_qty from D, c where 1 = 1 and d.'|| GROUP_BY ||' = c.'|| GROUP_BY ||' group by d.'|| GROUP_BY ||'), --交货数量 F as (SELECT '|| GROUP_BY ||', sum(QTY) AS part_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''20'' '|| V_CON ||' group by '|| GROUP_BY ||' ), --交货数量*销售比率获取 =索赔零件总数 G as (select F.BRAND, sum(F.part_qty * E.rate) as instrorage_qty from F, E where F.'|| GROUP_BY ||' = E.'|| GROUP_BY ||' group by F.'|| GROUP_BY ||'), --计算实绩值 H AS (select G.'|| GROUP_BY ||', B.sc_qty, instrorage_qty, round(B.sc_qty / instrorage_qty * 1000000, 1) as rate, round(B.sc_qty / instrorage_qty * 1000000, 10) rate_dec from G left join B on G.'|| GROUP_BY ||' = B.'|| GROUP_BY ||'), V AS (SELECT TARGET_VAL, BRAND AS TARGET_TYPE_NAME FROM T_QMS_DB_TARGET_VAL T WHERE T.BUSI_TYPE = ''10'' AND T.TARGET_DATE= '''||V_MIS_MONTH||''') SELECT '|| GROUP_BY ||' as SUMARY_NAME, rate_dec, '''||V_MIS_MONTH||''' as MIS_DATE, nvl((select target_val from V where H.'|| GROUP_BY ||' = V.target_type_name and rownum=1), 0) as target_val FROM H'; OPEN P_CUR FOR V_SQL;END; Mapper.xml 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;&lt;mapper namespace="com.xx.xx.xx.reportstatic.idal.mapper.MisRptMapper"&gt; &lt;resultMap id= "misPrcInputResult" type ="com.ly.mp.qms.reportstatic.entities.MisPrcInputResult" &gt; &lt;result column ="sumary_name" property="sumaryName" jdbcType="VARCHAR" /&gt; &lt;result column ="rate" property="rate" jdbcType="VARCHAR" /&gt; &lt;result column ="mis_date" property="misDate" jdbcType="VARCHAR" /&gt; &lt;result column ="target_val" property="targetVal" jdbcType="VARCHAR" /&gt; &lt;/resultMap &gt; &lt;select id="getMisRpt" statementType="CALLABLE" &gt; &#123;call p_qms_get_mis_rpt ( #&#123;misType,mode=IN,jdbcType=VARCHAR&#125;, &lt;!--注意要使用置jdbcType --&gt; #&#123;misDate,mode=IN,jdbcType=VARCHAR&#125;, #&#123;otherCondition,mode=IN,jdbcType=VARCHAR&#125;, #&#123;dateType,mode=IN,jdbcType=VARCHAR&#125;, #&#123;groupBy,mode=IN,jdbcType=VARCHAR&#125;, #&#123;result,mode=OUT,jdbcType=CURSOR, javaType=ResultSet,resultMap=misPrcInputResult&#125; )&#125; &lt;/select&gt;&lt;/mapper&gt; 这里主要注意1：输入参数的格式为 #{misType,mode=IN,jdbcType=VARCHAR}，需要设参数名称（misType），参数类型 （mode=IN)，参数数据类型（jdbcType=VARCHAR）为字符,网上找的资料都是没有设置 jdbcType=VARCHAR，但我的环境跑不起来。2：输出参数设置， #{result,mode=OUT,jdbcType=CURSOR, javaType=ResultSet,resultMap=misPrcInputResult。名称（result），参数类型为输出（mode=OUT），参数数据类型（jdbcType=CURSOR）为索引。输出的参数还需要另外设置javaType和resultMap。javaType=ResultSet 表示对应的java类型是一个列表，对应List；resultMap=misPrcInputResult 表示集合字段对应的印身是 misPrcInputResult。 Entity 123456789101112131415161718192021222324252627282930313233343536373839public class MisPrcInputResult implements java.io.Serializable &#123; private String sumaryName; private String rate; private String misDate; private String targetVal; public String getSumaryName() &#123; return sumaryName; &#125; public void setSumaryName(String sumaryName) &#123; this.sumaryName = sumaryName; &#125; public String getRate() &#123; return rate; &#125; public void setRate(String rate) &#123; this.rate = rate; &#125; public String getMisDate() &#123; return misDate; &#125; public void setMisDate(String misDate) &#123; this.misDate = misDate; &#125; public String getTargetVal() &#123; return targetVal; &#125; public void setTargetVal(String targetVal) &#123; this.targetVal = targetVal; &#125; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.sql.Date;import java.util.List;public class MisPrcInput implements java.io.Serializable &#123; private String misType; private String misDate; private String otherCondition; private String dateType; private String groupBy; private List&lt;MisPrcInputResult&gt; result; public String getMisType() &#123; return misType; &#125; public void setMisType(String misType) &#123; this.misType = misType; &#125; public String getMisDate() &#123; return misDate; &#125; public void setMisDate(String misDate) &#123; this.misDate = misDate; &#125; public String getOtherCondition() &#123; return otherCondition; &#125; public void setOtherCondition(String otherCondition) &#123; this.otherCondition = otherCondition; &#125; public String getDateType() &#123; return dateType; &#125; public void setDateType(String dateType) &#123; this.dateType = dateType; &#125; public String getGroupBy() &#123; return groupBy; &#125; public void setGroupBy(String groupBy) &#123; this.groupBy = groupBy; &#125; public List&lt;MisPrcInputResult&gt; getResult() &#123; return result; &#125; public void setResult(List&lt;MisPrcInputResult&gt; result) &#123; this.result = result; &#125;&#125; Mapper.java 1234public interface MisRptMapper extends BaseMapper&lt;MisCaculate&gt; &#123; public void getMisRpt(MisPrcInput inp );&#125; Biz 1234567891011121314151617181920@Autowired MisRptMapper misRptMapper; @Override public RestResult&lt;List&lt;MisPrcInputResult&gt;&gt; getMisPrc() throws ParseException &#123; MisPrcInput inp= new MisPrcInput(); inp.setDateType("1"); inp.setGroupBy("brand"); inp.setMisType("1"); inp.setMisDate("2018-02-1"); inp.setOtherCondition( " 1=1 "); inp.setResult(new ArrayList&lt;MisPrcInputResult&gt;()); RestResult&lt;List&lt;MisPrcInputResult&gt;&gt; result =new RestResult(); result.setResult(1); misRptMapper.getMisRpt( inp); result.setMsg("获取成功"); result.setData(inp.getResult()); return result; &#125; 接口跟Service层就不贴代码了。。 最终运行结果]]></content>
      <categories>
        <category>目录</category>
      </categories>
      <tags>
        <tag>目录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[煮方便面谈 CountDownLatch]]></title>
    <url>%2F2020%2F02%2F16%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200216%2F</url>
    <content type="text"><![CDATA[煮方便面谈 CountDownLatch CountDownLatch用法解释 CountDownLatch要是控制多线程操作时，等待多线程执行完后，再执行下去。举个例子，冲泡面，需要以下3个步骤A：装水到电锅，打开电源，等3分钟B：拆方便盒，放调味料C：倒开水到方便面盒。其中A跟B是可以同时进行的，C则需要依赖A，B完成了再执行。 代码参数 实始化：CountDownLatch latch = new CountDownLatch(3) ，表示 count初始化为2个。wait方法:表示等待count=0时，执行。countDown方法：count减1。 实例 上面说的冲泡面的生活例子。 代码实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.concurrent.CountDownLatch;public class ClassTestApplication &#123; public static void main(String[] args) &#123; final CountDownLatch latch = new CountDownLatch(2); //初始化，count=3 System.out.println("Count="+latch.getCount()); new Thread(() -&gt; &#123; System.out.println("开始煮开水。。。"); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("开水煮好了。。。"); latch.countDown(); //count = count -1; System.out.println("Count="+latch.getCount()); &#125;).start(); new Thread(() -&gt; &#123; System.out.println("拆方便面盒。。。"); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("方便面盒拆好了。。。"); latch.countDown(); //count = count -1; System.out.println("Count="+latch.getCount()); &#125;).start(); try &#123; latch.await(); System.out.println("水煮好了，面拆好了，充水到面盒。。。"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行结果如下：Count=2开始煮开水。。。拆方便面盒。。。方便面盒拆好了。。。Count=1开水煮好了。。。Count=0水煮好了，面拆好了，充水到面盒。。。]]></content>
      <categories>
        <category>目录</category>
      </categories>
      <tags>
        <tag>目录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORACLE动态SQL存储过程]]></title>
    <url>%2F2020%2F02%2F14%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200214%2F</url>
    <content type="text"><![CDATA[ORACLE动态SQL存储过程 引言 在工作中，经常会遇到拼写动态sql，虽然写法不是很优美，但却无法避免。如果在后台（java 或者C#）写非常简单，拼写完直接运行就可以了。但如果是在数据库里面拼呢？因为公司经常用到，我把它总结一下，用一个简单的例子来说明。 场景 写一个存储过程，支持动态的条件，并根据条件输出结果。 实现 12345678910111213141516171819202122232425262728CREATE OR REPLACE PROCEDURE P_TEST(V_C1 VARCHAR2, --条件1 V_C2 VARCHAR2, --条件2 P_CUR OUT SYS_REFCURSOR --用于输出的索引（输出表） ) AS V_SQL VARCHAR2(4000) := ' '; --用于构造要执行的动态SQL V_CON VARCHAR2(500) := ' where 1=1 '; --用于构造条件BEGIN V_SQL := ' WITH T AS (SELECT ''1'' AS C1 ,''1'' AS C2 FROM DUAL UNIONSELECT ''2'' AS C1 ,''2'' AS C2 FROM DUAL UNIONSELECT ''3'' AS C1 ,''3'' AS C2 FROM DUAL UNIONSELECT ''4'' AS C1 ,''4'' AS C2 FROM DUAL )SELECT * FROM T ';--构造条件 V_CON := V_CON || ' AND C1=''' || V_C1 || ''' '; V_CON := V_CON || ' AND C2=''' || V_C2 || ''' ';--构造动态SQL V_SQL := V_SQL || V_CON; DBMS_OUTPUT.put_line(V_SQL); ----输出，方便测试动态生成的SQL OPEN P_CUR FOR V_SQL;//关键，执行并输出结果END; 以上实现已经完成，我们在PL SQL运行一下看看结果。 实例分享 下面分再享个复杂一些的，以及写的写的过程。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176CREATE OR REPLACE PROCEDURE P_QMS_GET_MIS_RPT(MIS_TYPE VARCHAR2, --1:3MIS 2:6MIS V_DATE DATE, --时间条件 OTHER_CONDITION VARCHAR2, --其它条件 DATE_TYPE NVARCHAR2, -- 1:年 2：月 3：周 GROUP_BY VARCHAR2, --维度 BRAND P_CUR OUT SYS_REFCURSOR ) AS V_SQL VARCHAR2(4000); V_CON VARCHAR2(500):=''; V_STRAT_DATE date; V_END_DATE date; V_MIS_MONTH varchar2(50); V_START_DATE_STR VARCHAR2(100); V_END_DATE_STR VARCHAR2(100);BEGIN V_STRAT_DATE := Trunc(add_months(V_DATE, -3 * MIS_TYPE ), 'mm'); V_END_DATE := Last_Day(add_months(V_DATE, -1)); V_MIS_MONTH := to_char(Trunc(add_months(V_DATE, -1), 'mm'), 'yyyymm'); V_START_DATE_STR:= ' to_date('''|| to_char( V_STRAT_DATE,'yyyy-MM-dd') ||''',''yyyy-MM-dd'') '; V_END_DATE_STR := ' to_date('''|| to_char( V_END_DATE,'yyyy-MM-dd') ||''',''yyyy-MM-dd'') '; V_CON:=V_CON || ' and ACTIVE_START&gt;= ' || V_START_DATE_STR ; V_CON:=V_CON || ' and ACTIVE_START &lt; '|| V_END_DATE_STR || '+1'; V_CON:=V_CON|| ' '; V_SQL := ' with B as --市场不良数 (SELECT '|| GROUP_BY ||', sum(QTY) AS sc_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''10'' '|| V_CON ||' group by '|| GROUP_BY ||'), --销售数量 C as (SELECT '|| GROUP_BY ||', sum(QTY) AS s_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''40'' '|| V_CON ||' group by '|| GROUP_BY ||' ), --生产数量 D as (SELECT '|| GROUP_BY ||', sum(QTY) AS pro_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''30'' '|| V_CON ||' group by '|| GROUP_BY ||' ), --销售比率 E as (select d.'|| GROUP_BY ||', round(least(sum(c.s_qty) / sum(d.pro_qty), 1), 8) as rate, sum(c.s_qty) sale_qty, sum(d.pro_qty) pro_qty from D, c where 1 = 1 and d.'|| GROUP_BY ||' = c.'|| GROUP_BY ||' group by d.'|| GROUP_BY ||'), --交货数量 F as (SELECT '|| GROUP_BY ||', sum(QTY) AS part_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = ''20'' '|| V_CON ||' group by '|| GROUP_BY ||' ), --交货数量*销售比率获取 =索赔零件总数 G as (select F.BRAND, sum(F.part_qty * E.rate) as instrorage_qty from F, E where F.'|| GROUP_BY ||' = E.'|| GROUP_BY ||' group by F.'|| GROUP_BY ||'), --计算实绩值 H AS (select G.'|| GROUP_BY ||', B.sc_qty, instrorage_qty, round(B.sc_qty / instrorage_qty * 1000000, 1) as rate, round(B.sc_qty / instrorage_qty * 1000000, 10) rate_dec from G left join B on G.'|| GROUP_BY ||' = B.'|| GROUP_BY ||'), V AS (SELECT TARGET_VAL, BRAND AS TARGET_TYPE_NAME FROM T_QMS_DB_TARGET_VAL T WHERE T.BUSI_TYPE = ''10'' AND T.TARGET_DATE= '''||V_MIS_MONTH||''') SELECT sysdate, '|| GROUP_BY ||' as SUMARY_NAME, rate_dec, '''||V_MIS_MONTH||''' as MIS_MONTH, nvl((select target_val from V where H.'|| GROUP_BY ||' = V.target_type_name and rownum=1), 0) as target_val FROM H'; /* with B as --市场不良数 (SELECT BRAND, sum(QTY) AS sc_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = '10' and ACTIVE_START&gt;= V_STRAT_DATE and ACTIVE_START &lt; V_END_DATE+1 group by BRAND), --销售数量 C as (SELECT BRAND, sum(QTY) AS s_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = '40' and ACTIVE_START&gt;= V_STRAT_DATE and ACTIVE_START &lt; V_END_DATE+1 group by BRAND), --生产数量 D as (SELECT BRAND, sum(QTY) AS pro_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = '30' and ACTIVE_START&gt;= V_STRAT_DATE and ACTIVE_START &lt; V_END_DATE+1 group by BRAND), --销售比率 E as (select d.BRAND, round(least(sum(c.s_qty) / sum(d.pro_qty), 1), 8) as rate, sum(c.s_qty) sale_qty, sum(d.pro_qty) pro_qty from D, c where 1 = 1 and d.BRAND = c.BRAND group by d.BRAND), --交货数量 F as (SELECT BRAND, sum(QTY) AS part_qty FROM T_QMS_DB_COMMON_CACULATE cc where cc.CACULATE_TYPE = '20' and ACTIVE_START&gt;= V_STRAT_DATE and ACTIVE_START &lt; V_END_DATE+1 group by BRAND), --交货数量*销售比率获取 =索赔零件总数 G as (select F.BRAND, sum(F.part_qty * E.rate) as instrorage_qty from F, E where F.BRAND = E.BRAND group by F.BRAND), --计算实绩值 H AS (select G.BRAND, B.sc_qty, instrorage_qty, round(B.sc_qty / instrorage_qty * 1000000, 1) as rate, round(B.sc_qty / instrorage_qty * 1000000, 10) rate_dec from G left join B on G.BRAND = B.BRAND), V AS (SELECT TARGET_VAL, BRAND AS TARGET_TYPE_NAME FROM T_QMS_DB_TARGET_VAL T WHERE T.BUSI_TYPE = '10' AND T.TARGET_DATE= V_MIS_MONTH) SELECT sysdate, '10' AS CACULATE_TYPE, '统计因子，品牌3MIS' AS REMARK, BRAND, BRAND, rate_dec, V_MIS_MONTH, nvl((select target_val from V where H.BRAND = V.target_type_name and rownum=1), 0) as target_val, V_ASYNC_ID FROM H */ DBMS_OUTPUT.put_line(V_SQL); OPEN P_CUR FOR V_SQL;END; 经验分享 123456上面这个实例其实也不算复杂，但做这样的活，却是一件很头痛的事情。过程非常不好调整，特别是业务调整的时候，你想死的心都有。当然，实际使用能避免就避免吧。经过了多次经维护与编写，我总结了以下步骤。1：整理好逻辑，最好以文字的方式把它实现的逻辑写出来贴在备注里。因为SQL本身可读性就差。下次维护连自己都可能不认识了。2：根据第1步整理好的逻辑，写代SQL，变量部分先写死。保证能运行通过。3：整理并定义变量。4：拼写SQL主体，条件。用变量替换写死的代码。5：执行，输出。一般这个过程需要输出多次，先解决语法问题，再解决数据正确性问题。]]></content>
      <categories>
        <category>目录</category>
      </categories>
      <tags>
        <tag>目录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java公平锁与非公平锁]]></title>
    <url>%2F2020%2F02%2F10%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200210%2F</url>
    <content type="text"><![CDATA[Java公平锁与非公平锁 定义 当程序使用多线程里，难免有多线程争夺资源的情况。而资源只能被一个线程独占使用，至于资源怎么分配，就涉及到非公平锁与公平锁了。 非公平锁：非公平锁的资源的分配是随机的，看谁先抢到就给谁。可能会出现一个线程长期霸占资源，而另一线程长期得不到资源。公平锁：顾名思义，公平锁的资源是公平分配的，先来先得，后来排队。 实例 开20个线程进行计数，每个线程计算到10000，最后 非公平锁synchroized实现 12345678910111213141516171819202122232425import org.springframework.util.StopWatch;public class ClassTestApp4lication &#123; public static Integer i = new Integer(0); public static Object oj = new Object(); public static void main(String[] args) &#123; StopWatch watch = new StopWatch(); watch.start(); for (int ac = 0; ac &lt; 20; ac++) &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; for (int ac2 = 0; ac2 &lt; 10000; ac2++) &#123; synchronized (oj) &#123; System.out.println("线程ID:"+Thread.currentThread().getId());//输出当前线程ID，便于确认分配的机制 i = i + 1; &#125; &#125; &#125; &#125;; t1.start(); &#125; &#125;&#125; 因为输出的结果太长了，这里抽取部分输出结果，如下：线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:12线程ID:14线程ID:14线程ID:14线程ID:14线程ID:14线程ID:27线程ID:27线程ID:27线程ID:27 非公平锁ReentrantLock实现 用ReentrantLock实现，关键在于实例化ReentrantLock时传参为false。使用无参数重载也是非公平锁，如：public static ReentrantLock rlock=new ReentrantLock(false)或者 public static ReentrantLock rlock=new ReentrantLock()。代码如下： 12345678910111213141516171819202122232425262728import org.springframework.util.StopWatch;import java.util.concurrent.locks.ReentrantLock;public class ClassTest3Application &#123; public static ReentrantLock rlock=new ReentrantLock(false);//false表示非公平锁，或使用无参数重载。 public volatile static int i; public static void main(String[] args) &#123; StopWatch watch =new StopWatch(); watch.start(); for (int ac = 0; ac &lt; 20; ac++) &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; for (int ac2 = 0; ac2 &lt; 1000; ac2++) &#123; try &#123; rlock.lock(); System.out.println("线程ID:"+Thread.currentThread().getId()); i = i + 1; &#125; finally &#123; rlock.unlock(); &#125; &#125; &#125; &#125;; t1.start(); &#125; &#125;&#125; 同样这里也只贴出部分的输出，如下线程ID:12线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:17线程ID:28线程ID:28 公平锁ReentrantLock实现 用ReentrantLock实现，关键在于实例化ReentrantLock时传参为true。如：public static ReentrantLock rlock=new ReentrantLock(true) 12345678910111213141516171819202122232425262728import org.springframework.util.StopWatch;import java.util.concurrent.locks.ReentrantLock;public class ClassTest3Application &#123; public static ReentrantLock rlock=new ReentrantLock(true);//true 表示公平锁 public volatile static int i; public static void main(String[] args) &#123; StopWatch watch =new StopWatch(); watch.start(); for (int ac = 0; ac &lt; 20; ac++) &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; for (int ac2 = 0; ac2 &lt; 1000; ac2++) &#123; try &#123; rlock.lock(); System.out.println("线程ID:"+Thread.currentThread().getId()); i = i + 1; &#125; finally &#123; rlock.unlock(); &#125; &#125; &#125; &#125;; t1.start(); &#125; &#125;&#125; 同样这里也只贴出部分的输出，如下线程ID:12线程ID:13线程ID:14线程ID:15线程ID:16线程ID:17线程ID:12线程ID:18线程ID:19线程ID:13线程ID:20线程ID:14线程ID:21线程ID:15线程ID:22线程ID:16线程ID:23线程ID:17线程ID:24线程ID:12线程ID:25线程ID:18线程ID:26线程ID:19 性能测试 性能测试场景 开启20个线程，每个线程计数1000000次。计划耗时 测试结果 synchronized 非公平锁 | 测试序号 | 耗时(单位为秒) || ——– | ————– || 1 | 0.5398486 || 2 | 0.5319575 || 3 | 0.5299667 || 4 | 0.5496109 || 5 | 0.5520412 | ReentrantLock 非公平锁 | 测试序号 | 耗时(单位为秒) || ——– | ————– || 1 | 0.4283422 || 2 | 0.4390329 || 3 | 0.4378793 || 4 | 0.4409746 || 5 | 0.4377871 | ReentrantLock 公平锁 | 测试序号 | 耗时(单位为秒) || ——– | ————– || 1 | 209.9848296 | 这个比较久，我等了好几分钟，就只做一次测试吧。 结论 | | 性能 | 描述 || ———————- | —- | ——————————————————- || synchronized 非公平锁 | 很好 | 耗时在0.54秒样子 || ReentrantLock 非公平锁 | 最好 | 耗时在0.43秒样子 || ReentrantLock 公平锁 | 最差 | 耗时超过200秒，与非公平锁不是一样等级，公平是有代价的。 |]]></content>
      <categories>
        <category>目录</category>
      </categories>
      <tags>
        <tag>目录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java悲观锁与乐观锁]]></title>
    <url>%2F2020%2F02%2F09%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20200209%2F</url>
    <content type="text"><![CDATA[Java悲观锁与乐观锁 锁的目的 多线程编程如有共用资源的使用时，需要保证数据安全，资源需要同步处理。处理资源的手段可以有：互斥同步与非阻塞同步。实现分别对应：悲观锁与乐观锁。 实例 开20个线程进行计数，每个线程计算到10000。分别使用悲观锁与乐观锁来实现。 悲观锁实现 悲观锁是主要使用synchronized实现，通过锁住对应的对象，独占资源的方式。demo实现代码如下： 1234567891011121314151617181920212223242526272829303132import org.springframework.util.StopWatch;public class ClassTestApplication &#123; public static Integer i = new Integer(0); public static Object oj = new Object();//用于锁对象 public static void main(String[] args) &#123; StopWatch watch = new StopWatch(); watch.start(); for (int ac = 0; ac &lt; 20; ac++) &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; for (int ac2 = 0; ac2 &lt; 10000; ac2++) &#123; synchronized (oj) &#123;//锁只能锁对象，不能锁值类型,所以需要另外新建oj对象 i = i + 1; Thread.yield();//降低当前线程的优先级 &#125; &#125; System.out.println("i=" + i); //输出时耗 if (i == 200000) &#123; watch.stop(); System.out.println("耗时:" + watch.getTotalTimeSeconds()); &#125; &#125; &#125;; t1.start(); &#125; &#125;&#125; 输出结果如下：i=20480i=60223i=71641i=102771i=103641i=117543i=127194i=131049i=140436i=146951i=153894i=160899i=162207i=164290i=170482i=181676i=189241i=194425i=198873i=200000耗时:0.1261655 乐观锁实现 乐观锁主要通过CAS（Compare and swap）去现实。demo实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637import org.springframework.util.StopWatch;import java.util.concurrent.atomic.AtomicInteger;public class ClassTest2Application &#123; public static AtomicInteger j = new AtomicInteger(); public volatile static int i; public static void main(String[] args) &#123; StopWatch watch =new StopWatch(); watch.start(); for (int ac = 0; ac &lt; 20; ac++) &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; for (int ac2 = 0; ac2 &lt; 10000; ac2++) &#123; for (; ; ) &#123; //自旋 Integer current = i; Integer next = i + 1; if (j.compareAndSet(current, next)) &#123; //对比并赋值,注意需要新建一变量current，不能直接使用i i = next; Thread.yield();//降低当前线程的优先级 break; &#125; &#125; &#125; System.out.println("i=" + i); if(i==200000) &#123; watch.stop(); System.out.println("耗时:"+watch.getTotalTimeSeconds()); &#125; &#125; &#125;; t1.start(); &#125; &#125;&#125; 输出结果如下i=143289i=146323i=147099i=150204i=150598i=155177i=177143i=184003i=184685i=187439i=188419i=189595i=190235i=192196i=193054i=194514i=194798i=198438i=199530i=200000耗时:0.0482009 总结 这里只针对demo的场景做一下简单对比。 性能(好) 可读性（好） 复杂度（低） 乐观锁 悲观锁 悲观锁 PS：1： synchronize 实际是多种锁组合，根据使用的情况，从 无锁-&gt;偏向锁-&gt;轻量级锁-&gt;重量级锁 。2：因为测试的线程比较多，使用synchronize瞬间就升级为重量级锁。所以性能的对比还是可以的。]]></content>
      <categories>
        <category>目录</category>
      </categories>
      <tags>
        <tag>目录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo面试题整理]]></title>
    <url>%2F2018%2F08%2F27%2F%E9%9D%A2%E8%AF%95%2FDubbo%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[Dubbo面试题整理 [toc] 1.Dubbo是什么？​ Dubbo 是一个分布式、高性能、透明化的 RPC 服务框架，提供服务自动注册、自动发现等高效服务治理方案， 可以和 Spring 框架无缝集成。RPC 指的是远程调用协议，也就是说两个服务器交互数据。 2.Dubbo的由来？​ 互联网的快速发展，Web应用程序的规模不断扩大，一般会经历如下四个发展阶段。 单一应用架构 当网站流量很小时，只需一个应用，将所有功能都部署在一起即可。 垂直应用架构 当访问量逐渐增大，单一应用按照有业务线拆成多个应用，以提升效率。 此时，用于加速前端页面开发的 Web框架(MVC) 是关键。 分布式服务架构 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。 此时，用于提高业务复用及整合的分布式服务框架(RPC) 是关键。 流动计算架构 当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。 此时，用于提高机器利用率的 资源调度和治理中心(SOA) 是关键。 3.Dubbo的主要应用场景？​ 透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。 ​ 软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。 ​ 服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。 4.Dubbo的核心功能？主要就是如下3个核心功能： ​ Remoting：网络通信框架，提供对多种NIO框架抽象封装，包括“同步转异步”和“请求-响应”模式的信息交换方式。 ​ Cluster：服务框架，提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。 ​ Registry：服务注册，基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。 5.Dubbo的核心组件？ 6.Dubbo服务注册与发现的流程？ 流程说明： Provider(提供者)绑定指定端口并启动服务 指供者连接注册中心，并发本机IP、端口、应用信息和提供服务信息发送至注册中心存储 Consumer(消费者），连接注册中心 ，并发送应用信息、所求服务信息至注册中心 注册中心根据 消费 者所求服务信息匹配对应的提供者列表发送至Consumer 应用缓存。 Consumer 在发起远程调用时基于缓存的消费者列表择其一发起调用。 Provider 状态变更会实时通知注册中心、在由注册中心实时推送至Consumer 设计的原因： Consumer 与Provider 解偶，双方都可以横向增减节点数。 注册中心对本身可做对等集群，可动态增减节点，并且任意一台宕掉后，将自动切换到另一台 去中心化，双方不直接依懒注册中心，即使注册中心全部宕机短时间内也不会影响服务的调用 服务提供者无状态，任意一台宕掉后，不影响使用 7.Dubbo的架构设计？ Dubbo框架设计一共划分了10个层： 服务接口层（Service）：该层是与实际业务逻辑相关的，根据服务提供方和服务消费方的业务设计对应的接口和实现。 配置层（Config）：对外配置接口，以ServiceConfig和ReferenceConfig为中心。 服务代理层（Proxy）：服务接口透明代理，生成服务的客户端Stub和服务器端Skeleton。 服务注册层（Registry）：封装服务地址的注册与发现，以服务URL为中心。 集群层（Cluster）：封装多个提供者的路由及负载均衡，并桥接注册中心，以Invoker为中心。 监控层（Monitor）：RPC调用次数和调用时间监控。 远程调用层（Protocol）：封将RPC调用，以Invocation和Result为中心，扩展接口为Protocol、Invoker和Exporter。 信息交换层（Exchange）：封装请求响应模式，同步转异步，以Request和Response为中心。 网络传输层（Transport）：抽象mina和netty为统一接口，以Message为中心。 8.Dubbo的服务调用流程？ 9.Dubbo支持哪些协议，每种协议的应用场景，优缺点？ dubbo： 单一长连接和NIO异步通讯，适合大并发小数据量的服务调用，以及消费者远大于提供者。传输协议TCP，异步，Hessian序列化； rmi： 采用JDK标准的rmi协议实现，传输参数和返回参数对象需要实现Serializable接口，使用java标准序列化机制，使用阻塞式短连接，传输数据包大小混合，消费者和提供者个数差不多，可传文件，传输协议TCP。多个短连接，TCP协议传输，同步传输，适用常规的远程服务调用和rmi互操作。在依赖低版本的Common-Collections包，java序列化存在安全漏洞； webservice： 基于WebService的远程调用协议，集成CXF实现，提供和原生WebService的互操作。多个短连接，基于HTTP传输，同步传输，适用系统集成和跨语言调用； http： 基于Http表单提交的远程调用协议，使用Spring的HttpInvoke实现。多个短连接，传输协议HTTP，传入参数大小混合，提供者个数多于消费者，需要给应用程序和浏览器JS调用； hessian： 集成Hessian服务，基于HTTP通讯，采用Servlet暴露服务，Dubbo内嵌Jetty作为服务器时默认实现，提供与Hession服务互操作。多个短连接，同步HTTP传输，Hessian序列化，传入参数较大，提供者大于消费者，提供者压力较大，可传文件； memcache： 基于memcached实现的RPC协议 redis： 基于redis实现的RPC协议 10.dubbo推荐用什么协议？​ 默认使用dubbo协议 11.Dubbo有些哪些注册中心？ Multicast注册中心： Multicast注册中心不需要任何中心节点，只要广播地址，就能进行服务注册和发现。基于网络中组播传输实现； Zookeeper注册中心： 基于分布式协调系统Zookeeper实现，采用Zookeeper的watch机制实现数据变更； redis注册中心： 基于redis实现，采用key/Map存储，住key存储服务名和类型，Map中key存储服务URL，value服务过期时间。基于redis的发布/订阅模式通知数据变更； Simple注册中心 12.Dubbo的服务治理？ 过多的服务URL配置困难 负载均衡分配节点压力过大的情况下也需要部署集群 服务依赖混乱，启动顺序不清晰 过多服务导致性能指标分析难度较大，需要监控 13.Dubbo的注册中心集群挂掉，发布者和订阅者之间还能通信么？可以的，启动dubbo时，消费者会从zookeeper拉取注册的生产者的地址接口等数据，缓存在本地。每次调用时，按照本地存储的地址进行调用。 14.Dubbo与Spring的关系？Dubbo采用全Spring配置方式，透明化接入应用，对应用没有任何API侵入，只需用Spring加载Dubbo的配置即可，Dubbo基于Spring的Schema扩展进行加载。 15.Dubbo使用的是什么通信框架?默认使用NIO Netty框架 16.Dubbo集群提供了哪些负载均衡策略？ Random LoadBalance: 随机选取提供者策略，有利于动态调整提供者权重。截面碰撞率高，调用次数越多，分布越均匀； RoundRobin LoadBalance: 轮循选取提供者策略，平均分布，但是存在请求累积的问题； LeastActive LoadBalance: 最少活跃调用策略，解决慢提供者接收更少的请求； ConstantHash LoadBalance: 一致性Hash策略，使相同参数请求总是发到同一提供者，一台机器宕机，可以基于虚拟节点，分摊至其他提供者，避免引起提供者的剧烈变动； 缺省时为Random随机调用 17.Dubbo的集群容错方案有哪些？ Failover Cluster 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。 Failfast Cluster 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2″ 来设置最大并行数。 Broadcast Cluster 广播调用所有提供者，逐个调用，任意一台报错则报错 。通常用于通知所有提供者更新缓存或日志等本地资源信息。 18.Dubbo的默认集群容错方案？Failover Cluster 19.Dubbo支持哪些序列化方式？默认使用Hessian序列化，还有Duddo、FastJson、Java自带序列化。 20.Dubbo超时时间怎样设置？Dubbo超时时间设置有两种方式： 服务提供者端设置超时时间，在Dubbo的用户文档中，推荐如果能在服务端多配置就尽量多配置，因为服务提供者比消费者更清楚自己提供的服务特性。 服务消费者端设置超时时间，如果在消费者端设置了超时时间，以消费者端为主，即优先级更高。因为服务调用方设置超时时间控制性更灵活。如果消费方超时，服务端线程不会定制，会产生警告。 21.服务调用超时问题怎么解决？dubbo在调用服务不成功时，默认是会重试两次的。 22.Dubbo在安全机制方面是如何解决？Dubbo通过Token令牌防止用户绕过注册中心直连，然后在注册中心上管理授权。Dubbo还提供服务黑白名单，来控制服务所允许的调用方。 23.dubbo 和 dubbox 之间的区别？dubbox 基于 dubbo 上做了一些扩展，如加了服务可 restful 调用，更新了开源组件等。 24.除了Dubbo还有哪些分布式框架？大家熟知的就是Spring cloud，当然国外也有类似的多个框架。 25.Dubbo和Spring Cloud的关系？Dubbo是 SOA 时代的产物，它的关注点主要在于服务的调用，流量分发、流量监控和熔断。而 Spring Cloud诞生于微服务架构时代，考虑的是微服务治理的方方面面，另外由于依托了 Spirng、Spirng Boot的优势之上，两个框架在开始目标就不一致，Dubbo 定位服务治理、Spirng Cloud 是一个生态。 26.dubbo和spring cloud的区别？最大的区别：Dubbo底层是使用Netty这样的NIO框架，是基于TCP协议传输的，配合以Hession序列化完成RPC通信。而SpringCloud是基于Http协议+Rest接口调用远程过程的通信，相对来说，Http请求会有更大的报文，占的带宽也会更多。但是REST相比RPC更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更为合适，至于注重通信速度还是方便灵活性，具体情况具体考虑。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>Dubbo面试题总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发面试题整理]]></title>
    <url>%2F2018%2F08%2F27%2F%E9%9D%A2%E8%AF%95%2F%E5%B9%B6%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[并发面试题整理 [toc] 1、并发编程三要素?123456（1）原子性原子性指的是一个或者多个操作，要么全部执行并且在执行的过程中不被其他操作打断，要么就全部都不执行。（2）可见性可见性指多个线程操作一个共享变量时，其中一个线程对变量进行修改后，其他线程可以立即看到修改的结果。（3）有序性有序性，即程序的执行顺序按照代码的先后顺序来执行。 2、实现可见性的方法有哪些？1synchronized 或者 Lock：保证同一个时刻只有一个线程获取锁执行代码，锁释放之前把最新的值刷新到主内存，实现可见性。 3、多线程的价值？12345678（1）发挥多核 CPU 的优势多线程，可以真正发挥出多核 CPU 的优势来，达到充分利用 CPU 的目的，采用多线程的方式去同时完成几件事情而不互相干扰。（2）防止阻塞从程序运行效率的角度来看，单核 CPU 不但不会发挥出多线程的优势，反而会因为在单核 CPU 上运行多线程导致线程上下文的切换，而降低程序整体的效率。但是单核 CPU 我们还是要应用多线程，就是为了防止阻塞。试想，如果单核 CPU 使用单线程，那么只要这个线程阻塞了，比方说远程读取某个数据吧，对端迟迟未返回又没有设置超时时间，那么你的整个程序在数据返回回来之前就停止运行了。多线程可以防止这个问题，多条线程同时运行，哪怕一条线程的代码执行读取数据阻塞，也不会影响其它任务的执行。（3）便于建模这是另外一个没有这么明显的优点了。假设有一个大的任务 A，单线程编程，那么就要考虑很多，建立整个程序模型比较麻烦。但是如果把这个大的任务 A 分解成几个小任务，任务 B、任务 C、任务 D，分别建立程序模型，并通过多线程分别运行这几个任务，那就简单很多了。 4、创建线程的有哪些方式？1234567（1）继承 Thread 类创建线程类（2）通过 Runnable 接口创建线程类（3）通过 Callable 和 Future 创建线程（4）通过线程池创建 5、创建线程的三种方式的对比？1234567891011121314151617（1）采用实现 Runnable、Callable 接口的方式创建多线程。 优势是： 线程类只是实现了 Runnable 接口或 Callable 接口，还可以继承其他类。在这种方式下，多个线程可以共享同一个 target 对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将 CPU、代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。 劣势是： 编程稍微复杂，如果要访问当前线程，则必须使用 Thread.currentThread()方法。（2）使用继承 Thread 类的方式创建多线程 优势是： 编写简单，如果需要访问当前线程，则无需使用 Thread.currentThread()方法，直接使用 this 即可获得当前线程。 劣势是： 线程类已经继承了 Thread 类，所以不能再继承其他父类。（3）Runnable 和 Callable 的区别 1、Callable 规定（重写）的方法是 call()，Runnable 规定（重写）的方法是 run()。 2、Callable 的任务执行后可返回值，而 Runnable 的任务是不能返回值的。 3、Call 方法可以抛出异常，run 方法不可以。 4、运行 Callable 任务可以拿到一个 Future 对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过 Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。 6、线程的状态流转图线程的生命周期及五种基本状态： 7、Java 线程具有五中基本状态12345678910111213141516171819（1）新建状态（New）： 当线程对象对创建后，即进入了新建状态，如：Thread t= new MyThread()； （2）就绪状态（Runnable）： 当调用线程对象的 start()方法（t.start();），线程即进入就绪状态。处于就绪状态的线程，只是说明此线程已经做好了准备，随时等待 CPU 调度执行，并不是说执行了t.start()此线程立即就会执行；（3）运行状态（Running）： 当 CPU 开始调度处于就绪状态的线程时，此时线程才得以真正执行，即进入到运行状态。注：就 绪状态是进入到运行状态的唯一入口，也就是说，线程要想进入运行状态执行，首先必须处于就绪状态中；（4）阻塞状态（Blocked）： 处于运行状态中的线程由于某种原因，暂时放弃对 CPU的使用权，停止执行，此时进入阻塞状态，直到其进入到就绪状态，才 有机会再次被 CPU 调用以进入到运行状态。 根据阻塞产生的原因不同，阻塞状态又可以分为三种： 1）等待阻塞：运行状态中的线程执行 wait()方法，使本线程进入到等待阻塞状态； 2）同步阻塞：线程在获取 synchronized 同步锁失败(因为锁被其它线程所占用)，它会进入同步阻塞状态； 3）其他阻塞：通过调用线程的 sleep()或 join()或发出了 I/O 请求时，线程会进入到阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者 I/O 处理完毕时，线程重新转入就绪状态。 （5）死亡状态（Dead）： 线程执行完了或者因异常退出了 run()方法，该线程结束生命周期。 8、什么是线程池？有哪几种创建方式？123线程池就是提前创建若干个线程，如果有任务需要处理，线程池里的线程就会处理任务，处理完之后线程并不会被销毁，而是等待下一个任务。由于创建和销毁线程都是消耗系统资源的，所以当你想要频繁的创建和销毁线程的时候就可以考虑使用线程池来提升系统的性能。java 提供了一个 java.util.concurrent.Executor 接口的实现用于创建线程池。 9、四种线程池的创建：1234567（1）newCachedThreadPool 创建一个可缓存线程池（2）newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数。（3）newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。（4）newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务。 10、线程池的优点？12345（1）重用存在的线程，减少对象创建销毁的开销。（2）可有效的控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。（3）提供定时执行、定期执行、单线程、并发数控制等功能。 11、常用的并发工具类有哪些？1234567（1）CountDownLatch（2）CyclicBarrier（3）Semaphore（4）Exchanger 12、CyclicBarrier 和 CountDownLatch 的区别1234567（1）CountDownLatch 简单的说就是一个线程等待，直到他所等待的其他线程都执行完成并且调用 countDown()方法发出通知后，当前线程才可以继续执行。（2）cyclicBarrier 是所有线程都进行等待，直到所有线程都准备好进入 await()方法之后，所有线程同时开始执行！（3）CountDownLatch 的计数器只能使用一次。而 CyclicBarrier 的计数器可以使用 reset() 方法重置。所以 CyclicBarrier 能处理更为复杂的业务场景，比如如果计算发生错误，可以重置计数器，并让线程们重新执行一次。（4）CyclicBarrier 还提供其他有用的方法，比如 getNumberWaiting 方法可以获得 CyclicBarrier 阻塞的线程数量。isBroken 方法用来知道阻塞的线程是否被中断。如果被中断返回 true，否则返回 false。 13、synchronized 的作用？1在 Java 中，synchronized 关键字是用来控制线程同步的，就是在多线程的环境下，控制 synchronized 代码段不被多个线程同时执行。synchronized 既可以加在一段代码上，也可以加在方法上。 14、volatile 关键字的作用1对于可见性，Java 提供了 volatile 关键字来保证可见性。当一个共享变量被 volatile 修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。从实践角度而言，volatile 的一个重要作用就是和 CAS 结合，保证了原子性，详细的可以参见 java.util.concurrent.atomic 包下的类，比如 AtomicInteger。 15、什么是 CAS1234567CAS 是 compare and swap 的缩写，即我们所说的比较交换。cas 是一种基于锁的操作，而且是乐观锁。在 java 中锁分为乐观锁和悲观锁。悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加 version 来获取数据，性能较悲观锁有很大的提高。CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和 A 的值是一样的，那么就将内存里面的值更新成 B。CAS是通过无限循环来获取数据的，若果在第一轮循环中，a 线程获取地址里面的值被b 线程修改了，那么 a 线程需要自旋，到下次循环才有可能机会执行。java.util.concurrent.atomic 包下的类大多是使用 CAS 操作来实现的(AtomicInteger,AtomicBoolean,AtomicLong)。 16、CAS 的问题12345678（1）CAS 容易造成 ABA 问题 一个线程 a 将数值改成了 b，接着又改成了 a，此时 CAS 认为是没有变化，其实是已经变化过了，而这个问题的解决方案可以使用版本号标识，每操作一次version 加 1。在 java5 中，已经提供了 AtomicStampedReference 来解决问题。（2）不能保证代码块的原子性 CAS 机制所保证的知识一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证 3 个变量共同进行原子性的更新，就不得不使用 synchronized 了。（3）CAS 造成 CPU 利用率增加 之前说过了 CAS 里面是一个循环判断的过程，如果线程一直没有获取到状态，cpu资源会一直被占用。 17、什么是 Future？12345在并发编程中，我们经常用到非阻塞的模型，在之前的多线程的三种实现中，不管是继承 thread 类还是实现 runnable 接口，都无法保证获取到之前的执行结果。通过实现 Callback 接口，并用 Future 可以来接收多线程的执行结果。 Future 表示一个可能还没有完成的异步任务的结果，针对这个结果可以添加Callback 以便在任务执行成功或失败后作出相应的操作。 18、什么是 AQS123AQS 是 AbustactQueuedSynchronizer 的简称，它是一个 Java 提高的底层同步工具类，用一个 int 类型的变量表示同步状态，并提供了一系列的 CAS 操作来管理这个同步状态。AQS 是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的 ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask 等等皆是基于AQS 的。 19、AQS 支持两种同步方式：123（1）独占式（2）共享式 这样方便使用者实现不同类型的同步组件，独占式如 ReentrantLock，共享式如Semaphore，CountDownLatch，组 合 式 的 如 ReentrantReadWriteLock。总之，AQS 为使用提供了底层支撑，如何组装实现，使用者可以自由发挥。 20、ReadWriteLock 是什么1首先明确一下，不是说 ReentrantLock 不好，只是 ReentrantLock 某些时候有局限。如果使用 ReentrantLock，可能本身是为了防止线程 A 在写数据、线程 B 在读数据造成的数据不一致，但这样，如果线程 C 在读数据、线程 D 也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。因为这个，才诞生了读写锁 ReadWriteLock。ReadWriteLock 是一个读写锁接口，ReentrantReadWriteLock 是 ReadWriteLock 接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。 21、FutureTask 是什么1这个其实前面有提到过，FutureTask 表示一个异步运算的任务。FutureTask 里面可以传入一个 Callable 的具体实现类，可以对这个异步运算的任务的结果进行等待获取、判断是否已经完成、取消任务等操作。当然，由于 FutureTask 也是Runnable 接口的实现类，所以 FutureTask 也可以放入线程池中。 22、synchronized 和 ReentrantLock 的区别1234567synchronized 是和 if、else、for、while 一样的关键字，ReentrantLock 是类，这是二者的本质区别。既然 ReentrantLock 是类，那么它就提供了比synchronized 更多更灵活的特性，可以被继承、可以有方法、可以有各种各样的类变量，ReentrantLock 比 synchronized 的扩展性体现在几点上：（1）ReentrantLock 可以对获取锁的等待时间进行设置，这样就避免了死锁（2）ReentrantLock 可以获取各种锁的信息（3）ReentrantLock 可以灵活地实现多路通知 另外，二者的锁机制其实也是不一样的。ReentrantLock 底层调用的是 Unsafe 的park 方法加锁，synchronized 操作的应该是对象头中 mark word，这点我不能确定。 23、什么是乐观锁和悲观锁12345（1）乐观锁： 就像它的名字一样，对于并发间操作产生的线程安全问题持乐观状态，乐观锁认为竞争不总是会发生，因此它不需要持有锁，将比较-替换这两个动作作为一个原子操作尝试去修改内存中的变量，如果失败则表示发生冲突，那么就应该有相应的重试逻辑。（2）悲观锁： 还是像它的名字一样，对于并发间操作产生的线程安全问题持悲观状态，悲观锁认为竞争总是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像 synchronized，不管三七二十一，直接上了锁就操作资源了。 24、线程 B 怎么知道线程 A 修改了变量1234567（1）volatile 修饰变量（2）synchronized 修饰修改变量的方法（3）wait/notify（4）while 轮询 25、synchronized、volatile、CAS 比较123（1）synchronized 是悲观锁，属于抢占式，会引起其他线程阻塞。（2）volatile 提供多线程共享变量可见性和禁止指令重排序优化。（3）CAS 是基于冲突检测的乐观锁（非阻塞） 26、sleep 方法和 wait 方法有什么区别?1这个问题常问，sleep 方法和 wait 方法都可以用来放弃 CPU 一定的时间，不同点在于如果线程持有某个对象的监视器，sleep 方法不会放弃这个对象的监视器，wait 方法会放弃这个对象的监视器 27、ThreadLocal 是什么？有什么用？1ThreadLocal 是一个本地线程副本变量工具类。主要用于将私有线程和该线程存放的副本对象做一个映射，各个线程之间的变量互不干扰，在高并发场景下，可以实现无状态的调用，特别适用于各个线程依赖不通的变量值完成操作的场景。简单说 ThreadLocal 就是一种以空间换时间的做法，在每个 Thread 里面维护了一个以开地址法实现的 ThreadLocal.ThreadLocalMap，把数据进行隔离，数据不共享，自然就没有线程安全方面的问题了。 28、为什么 wait()方法和 notify()/notifyAll()方法要在同步块中被调用1这是 JDK 强制的，wait()方法和 notify()/notifyAll()方法在调用前都必须先获得对象的锁 29、多线程同步有哪几种方法？1Synchronized 关键字，Lock 锁实现，分布式锁等。 30、线程的调度策略1234567891011线程调度器选择优先级最高的线程运行，但是，如果发生以下情况，就会终止线程的运行：（1）线程体中调用了 yield 方法让出了对 cpu 的占用权利（2）线程体中调用了 sleep 方法使线程进入睡眠状态（3）线程由于 IO 操作受到阻塞（4）另外一个更高优先级线程出现（5）在支持时间片的系统中，该线程的时间片用完 31、ConcurrentHashMap 的并发度是什么1ConcurrentHashMap 的并发度就是 segment 的大小，默认为 16，这意味着最多同时可以有 16 条线程操作 ConcurrentHashMap，这也是ConcurrentHashMap 对 Hashtable 的最大优势，任何情况下，Hashtable 能同时有两条线程获取 Hashtable 中的数据 32、Linux 环境下如何查找哪个线程使用 CPU 最长123（1）获取项目的 pid，jps 或者 ps -ef | grep java（2）top -H -p pid，顺序不能改变 33、Java 死锁以及如何避免?123Java 中的死锁是一种编程情况，其中两个或多个线程被永久阻塞，Java 死锁情况出现至少两个线程和两个或更多资源。Java 发生死锁的根本原因是：在申请锁时发生了交叉闭环申请。 34、死锁的原因1234（1）是多个线程涉及到多个锁，这些锁存在着交叉，所以可能会导致了一个锁依赖的闭环。 例如：线程在获得了锁 A 并且没有释放的情况下去申请锁 B，这时，另一个线程已经获得了锁 B，在释放锁 B 之前又要先获得锁 A，因此闭环发生，陷入死锁循环。（2）默认的锁申请操作是阻塞的。 所以要避免死锁，就要在一遇到多个对象锁交叉的情况，就要仔细审查这几个对象的类中的所有方法，是否存在着导致锁依赖的环路的可能性。总之是尽量避免在一个同步方法中调用其它对象的延时方法和同步方法。 35、怎么唤醒一个阻塞的线程1如果线程是因为调用了 wait()、sleep()或 者 join()方法而导致的阻塞，可以中断线程，并且通过抛出 InterruptedException 来唤醒它；如果线程遇到了 IO 阻塞，无能为力，因为 IO 是操作系统实现的，Java 代码并没有办法直接接触到操作系统。 36、不可变对象对多线程有什么帮助1前面有提到过的一个问题，不可变对象保证了对象的内存可见性，对不可变对象的读取不需要进行额外的同步手段，提升了代码执行效率。 37、什么是多线程的上下文切换1多线程的上下文切换是指 CPU 控制权由一个已经正在运行的线程切换到另外一个就绪并等待获取 CPU 执行权的线程的过程。 38、如果你提交任务时，线程池队列已满，这时会发生什么1234这里区分一下：（1）如果使用的是无界队列 LinkedBlockingQueue，也就是无界队列的话，没关系，继续添加任务到阻塞队列中等待执行，因为 LinkedBlockingQueue 可以近乎认为是一个无穷大的队列，可以无限存放任务（2）如果使用的是有界队列比如 ArrayBlockingQueue，任务首先会被添加到ArrayBlockingQueue 中，ArrayBlockingQueue 满了，会根据maximumPoolSize 的值增加线程数量，如果增加了线程数量还是处理不过来，ArrayBlockingQueue 继续满，那么则会使用拒绝策略RejectedExecutionHandler 处理满了的任务，默认是 AbortPolicy 39、Java 中用到的线程调度算法是什么1抢占式。一个线程用完 CPU 之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。 40、什么是线程调度器(Thread Scheduler)和时间分片(TimeSlicing)？1线程调度器是一个操作系统服务，它负责为 Runnable 状态的线程分配 CPU 时间。一旦我们创建一个线程并启动它，它的执行便依赖于线程调度器的实现。时间分片是指将可用的 CPU 时间分配给可用的 Runnable 线程的过程。分配 CPU 时间可以基于线程优先级或者线程等待的时间。线程调度并不受到 Java 虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先级）。 41、什么是自旋1很多 synchronized 里面的代码只是一些很简单的代码，执行时间非常快，此时等待的线程都加锁可能是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态切换的问题。既然 synchronized 里面的代码执行得非常快，不妨让等待锁的线程不要被阻塞，而是在 synchronized 的边界做忙循环，这就是自旋。如果做了多次忙循环发现还没有获得锁，再阻塞，这样可能是一种更好的策略。 42、Java Concurrency API 中的 Lock 接口(Lock interface)是什么？对比同步它有什么优势？123456Lock 接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。它的优势有：（1）可以使锁更公平（2）可以使线程在等待锁的时候响应中断（3）可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间（4）可以在不同的范围，以不同的顺序获取和释放锁 43、单例模式的线程安全性1234老生常谈的问题了，首先要说的是单例模式的线程安全意味着：某个类的实例在多线程环境下只会被创建一次出来。单例模式有很多种的写法，我总结一下：（1）饿汉式单例模式的写法：线程安全（2）懒汉式单例模式的写法：非线程安全（3）双检锁单例模式的写法：线程安全 44、Semaphore 有什么作用1Semaphore 就是一个信号量，它的作用是限制某段代码块的并发数。Semaphore有一个构造函数，可以传入一个 int 型整数 n，表示某段代码最多只有 n 个线程可以访问，如果超出了 n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。由此可以看出如果 Semaphore 构造函数中传入的 int 型整数 n=1，相当于变成了一个 synchronized 了。 45、Executors 类是什么?1Executors 为 Executor，ExecutorService，ScheduledExecutorService，ThreadFactory 和 Callable 类提供了一些工具方法。Executors 可以用于方便的创建线程池 46、线程类的构造方法、静态块是被哪个线程调用的12345这是一个非常刁钻和狡猾的问题。请记住：线程类的构造方法、静态块是被 new这个线程类所在的线程所调用的，而 run 方法里面的代码才是被线程自身所调用的。如果说上面的说法让你感到困惑，那么我举个例子，假设 Thread2 中 new 了Thread1，main 函数中 new 了 Thread2，那么：（1）Thread2 的构造方法、静态块是 main 线程调用的，Thread2 的 run()方法是Thread2 自己调用的（2）Thread1 的构造方法、静态块是 Thread2 调用的，Thread1 的 run()方法是Thread1 自己调用的 47、同步方法和同步块，哪个是更好的选择?1同步块，这意味着同步块之外的代码是异步执行的，这比同步整个方法更提升代码的效率。请知道一条原则：同步的范围越小越好。 48、Java 线程数过多会造成什么异常？12345（1）线程的生命周期开销非常高（2）消耗过多的 CPU 资源 如果可运行的线程数量多于可用处理器的数量，那么有线程将会被闲置。大量空闲的线程会占用许多内存，给垃圾回收器带来压力，而且大量的线程在竞争 CPU资源时还将产生其他性能的开销。（3）降低稳定性 JVM 在可创建线程的数量上存在一个限制，这个限制值将随着平台的不同而不同，并且承受着多个因素制约，包括 JVM 的启动参数、Thread 构造函数中请求栈的大小，以及底层操作系统对线程的限制等。如果破坏了这些限制，那么可能抛出OutOfMemoryError 异常。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>并发面试总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作总结]]></title>
    <url>%2F2018%2F02%2F01%2F%E6%AF%8F%E6%97%A5%E6%80%BB%E7%BB%93%2F20180201%2F</url>
    <content type="text"><![CDATA[1、Java悲观锁与乐观锁 2、Java公平锁与非公平锁 3、ORACLE动态SQL存储过程 4、煮方便面谈 5、MyBatis调用带返回值的存储过程 6、Dubbo+Zookeeper中MyBatis-PLUS分页使用 7、请求头 8、jqGrid行编辑 9、SVN代码冲突 10、Java 数据校验 11、Dubbo以及两个实体List的合并 12、MyBatisPlus默认更新策略 13、Inner Join 与LEFT JOIN 14、多线程与线程池 15、数据排序 16、 百万数据导出 17、ztree的两种数据格式]]></content>
      <categories>
        <category>目录</category>
      </categories>
      <tags>
        <tag>目录</tag>
      </tags>
  </entry>
</search>
